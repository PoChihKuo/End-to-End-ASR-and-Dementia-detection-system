{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "extra-hartford",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "departmental-potential",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
    "# os.environ['CUDA_VISIBLE_DEVICES']='0,1'\n",
    "os.environ['CUDA_LAUNCH_BLOCKING']='1'\n",
    "import torch\n",
    "# torch.cuda.set_device(0)\n",
    "print(torch.cuda.current_device())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "steady-incident",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "senior-barbados",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "stuck-julian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "swedish-residence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cudaSetDevice(0)\n",
    "#dataset transcript要在dataset資好夾調\n",
    "#cuda 在basesolver init調\n",
    "#dataset要在data.py設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "attractive-class",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='1'\n",
    "# os.environ['CUDA_VISIBLE_DEVICES']='0,1'\n",
    "os.environ['CUDA_LAUNCH_BLOCKING']='1'\n",
    "import torch\n",
    "# torch.cuda.set_device(0)\n",
    "print(torch.cuda.current_device())\n",
    "#! python\n",
    "# -*- coding: utf-8 -*-\n",
    "# Author: kun\n",
    "# @Time: 2019-10-29 20:29\n",
    "\n",
    "import yaml\n",
    "import torch\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "class Para(object):\n",
    "    a=1\n",
    "\n",
    "def force_cudnn_initialization():\n",
    "    s = 32\n",
    "    dev = torch.device('cuda:0')\n",
    "    torch.nn.functional.conv2d(torch.zeros(s, s, s, s, device=dev), torch.zeros(s, s, s, s, device=dev))\n",
    "    \n",
    "#force_cudnn_initialization()\n",
    "def main():\n",
    "    # For reproducibility, comment these may speed up training\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    # Arguments\n",
    "#     parser = argparse.ArgumentParser(description='Training E2E asr.')\n",
    "#     parser.add_argument('--config', type=str, help='Path to experiment config.')\n",
    "#     parser.add_argument('--name', default=None, type=str, help='Name for logging.')\n",
    "#     parser.add_argument('--logdir', default='log/', type=str,\n",
    "#                         help='Logging path.', required=False)\n",
    "#     parser.add_argument('--ckpdir', default='ckpt/', type=str,\n",
    "#                         help='Checkpoint path.', required=False)\n",
    "#     parser.add_argument('--outdir', default='result/', type=str,\n",
    "#                         help='Decode output path.', required=False)\n",
    "#     parser.add_argument('--load', default=None, type=str,\n",
    "#                         help='Load pre-trained model (for training only)', required=False)\n",
    "#     parser.add_argument('--seed', default=0, type=int,\n",
    "#                         help='Random seed for reproducable results.', required=False)\n",
    "#     parser.add_argument('--cudnn-ctc', action='store_true',\n",
    "#                         help='Switches CTC backend from torch to cudnn')\n",
    "#     parser.add_argument('--njobs', default=32, type=int,\n",
    "#                         help='Number of threads for dataloader/decoding.', required=False)\n",
    "#     parser.add_argument('--cpu', action='store_true', help='Disable GPU training.')\n",
    "#     parser.add_argument('--no-pin', action='store_true',\n",
    "#                         help='Disable pin-memory for dataloader')\n",
    "#     parser.add_argument('--test', action='store_true', help='Test the model.')\n",
    "#     parser.add_argument('--no-msg', action='store_true', help='Hide all messages.')\n",
    "#     parser.add_argument('--lm', action='store_true',\n",
    "#                         help='Option for training RNNLM.')\n",
    "#     # Following features in development.\n",
    "#     parser.add_argument('--amp', action='store_true', help='Option to enable AMP.')\n",
    "#     parser.add_argument('--reserve-gpu', default=0, type=float,\n",
    "#                         help='Option to reserve GPU ram for training.')\n",
    "#     parser.add_argument('--jit', action='store_true',\n",
    "#                         help='Option for enabling jit in pytorch. (feature in development)')\n",
    "#     ###\n",
    "#     paras = parser.parse_args()\n",
    "    paras = Para()\n",
    "#     paras.config = './config/aishell_asr_example_lstm4atthead1-test.yaml'\n",
    "#     paras.name = None\n",
    "#     paras.logdir = 'log/'\n",
    "#     paras.ckpdir = 'ckpt/'\n",
    "#     paras.outdir = 'result/'\n",
    "#     paras.load = None\n",
    "#     paras.seed = 0\n",
    "#     paras.cudnn_ctc = False\n",
    "#     paras.cpu = False\n",
    "#     paras.no_pin = False\n",
    "#     paras.test = True\n",
    "#     paras.no_msg = False\n",
    "#     paras.lm = False\n",
    "#     paras.amp = False\n",
    "#     paras.reserve_gpu = 0\n",
    "#     paras.jit = False\n",
    "    setattr(paras, 'config', './config/cv11Lu_asr_lstm4atthead_allvocab-biclass2.yaml')\n",
    "    setattr(paras, 'name', None)\n",
    "    setattr(paras, 'logdir', 'log/')\n",
    "    setattr(paras, 'ckpdir', '/mnt/usb/jason3/LAS_ckpt')\n",
    "    setattr(paras, 'outdir', 'result/')\n",
    "    setattr(paras, 'load', './ckpt/mozillacv11_asr_stm4atthead_sd0/best_att.pth')#'./ckpt/cv11Lu_asr_lstm4atthead_allvocab_sd0/best_att-VAG01.pth')\n",
    "    setattr(paras, 'seed', 0)\n",
    "    setattr(paras, 'cudnn_ctc', False)\n",
    "    setattr(paras, 'njobs',8)\n",
    "    setattr(paras, 'cpu', False)\n",
    "    setattr(paras, 'no_pin', False)\n",
    "    setattr(paras, 'test', False)\n",
    "    setattr(paras, 'no_msg', False)\n",
    "    setattr(paras, 'lm', False)\n",
    "    setattr(paras, 'amp', False)\n",
    "    setattr(paras, 'reserve_gpu', 9)\n",
    "    setattr(paras, 'jit', False)\n",
    "    setattr(paras, 'gpu', not paras.cpu)\n",
    "    setattr(paras, 'pin_memory', not paras.no_pin)\n",
    "    setattr(paras, 'verbose', not paras.no_msg)\n",
    "    setattr(paras, 'finetune', False)\n",
    "    setattr(paras, 'binaryClass', True)\n",
    "    force_cudnn_initialization()\n",
    "\n",
    "    config = yaml.load(open(paras.config, 'r'), Loader=yaml.FullLoader)\n",
    "\n",
    "    np.random.seed(paras.seed)\n",
    "    torch.manual_seed(paras.seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(paras.seed)\n",
    "\n",
    "    # Hack to preserve GPU ram just incase OOM later on server\n",
    "    if paras.gpu and paras.reserve_gpu > 0:\n",
    "        buff = torch.randn(int(paras.reserve_gpu * 1e9 // 4)).cuda()\n",
    "        del buff\n",
    "\n",
    "    if paras.lm:\n",
    "        # Train RNNLM\n",
    "        from train_lm import Solver\n",
    "\n",
    "        mode = 'train'\n",
    "    else:\n",
    "        if paras.test:\n",
    "            # Test ASR\n",
    "            assert paras.load is None, 'Load option is mutually exclusive to --test'\n",
    "            from test_asr import Solver\n",
    "\n",
    "            mode = 'test'\n",
    "        elif paras.finetune:\n",
    "            assert paras.load is not None\n",
    "            from finetune_asr import Solver\n",
    "            mode = 'train'\n",
    "        elif paras.binaryClass:\n",
    "            assert paras.load is not None\n",
    "            from train_binaryclass2_5folds import Solver\n",
    "            mode = 'train'\n",
    "        else:\n",
    "            # Train ASR\n",
    "            from train_asr import Solver\n",
    "\n",
    "            mode = 'train'\n",
    "\n",
    "    print(\"\\nUsing {} mode\\n\".format(mode))\n",
    "    for idx in range(2,5):\n",
    "        paras.config = f'./config/cv11Lu_asr_lstm4atthead_allvocab-biclass2-5fold-{idx+1}.yaml'\n",
    "#         setattr(paras, 'load', f'./ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-5fold-{idx+1}_sd0/latest10knew_1VGG_4LSTM.pth')\n",
    "\n",
    "        config = yaml.load(open(paras.config, 'r'), Loader=yaml.FullLoader)\n",
    "        solver = Solver(config, paras, mode)\n",
    "\n",
    "        solver.load_data()\n",
    "    #     solver.print_model()\n",
    "        solver.set_model()\n",
    "        solver.exec()\n",
    "        del solver\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "focal-attribute",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using train mode\n",
      "\n",
      "[INFO] Exp. name : cv11Lu_asr_lstm4atthead_allvocab-biclass2-5fold-3_sd0                                   \n",
      "[INFO] Loading data... large dataset may took a while.                                                     \n",
      "Load data for training/validation, store tokenizer and input/output shape\n",
      "Prepare dataloader for training/validation\n",
      "Interface for creating all kinds of dataset\n",
      "import VAGDataset as Dataset\n",
      "[VAGDataset] path: /home/jupyter-jason5/data_process, split: ['CTT5-3-2']\n",
      "Mozillacv11Dataset CTT5-3-2 found wav data: 17\n",
      "text len: 17\n",
      "remove None, then wav data: 17, text len: 17\n",
      "[VAGDataset] path: /home/jupyter-jason5/data_process, split: ['CTT5-1-2', 'CTT5-2-2', 'CTT5-5-2', 'CTT5-4-2']\n",
      "Mozillacv11Dataset CTT5-1-2 found wav data: 19\n",
      "Mozillacv11Dataset CTT5-2-2 found wav data: 18\n",
      "Mozillacv11Dataset CTT5-5-2 found wav data: 17\n",
      "Mozillacv11Dataset CTT5-4-2 found wav data: 17\n",
      "text len: 71\n",
      "remove None, then wav data: 71, text len: 71\n",
      "[INFO] Data spec. | Corpus = vag (from /home/jupyter-jason5/data_process)                                  \n",
      "[INFO]            | Train sets = ['CTT5-1-2', 'CTT5-2-2', 'CTT5-5-2', 'CTT5-4-2']\t| Number of utts = 71    \n",
      "[INFO]            | Dev sets = ['CTT5-3-2']\t| Number of utts = 17                                          \n",
      "[INFO]            | Batch size = 1\t\t| Bucketing = True                                                     \n",
      "[INFO] I/O spec.  | Audio feature = fbank\t| feature dim = 120                                              \n",
      "Setup ASR model and optimizer \n",
      "[INFO] Model spec.| Encoder's downsampling rate of time axis is 4.                                         \n",
      "[INFO]            | VCC Extractor w/ time downsampling rate = 4 in encoder enabled.                        \n",
      "# Losses\n",
      "# Note: zero_infinity=False is unstable?\n",
      "# Optimizer\n",
      "[INFO] Optim.spec.| Algo. = Adadelta\t| Lr = 1.0\t (Scheduler = fixed)| Scheduled sampling = False           \n",
      "# Enable AMP if needed\n",
      "[INFO] Load ckpt from ./ckpt/mozillacv11_asr_stm4atthead_sd0/best_att.pth, restarting at step 1000000 )    \n",
      "encoder.layers.4.layer.weight_ih_l0_reverse\n",
      "encoder.layers.4.layer.weight_hh_l0_reverse\n",
      "encoder.layers.4.layer.bias_ih_l0_reverse\n",
      "encoder.layers.4.layer.bias_hh_l0_reverse\n",
      "fc.weight\n",
      "fc.bias\n",
      "Training End-to-end ASR system\n",
      "[INFO] Total training steps 1.0K.                                                                          \n",
      "self.tr_set: 71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-jason5/LAS_Mandarin_PyTorch-master/core/module.py:51: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  feat_len = feat_len // 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(48.2243, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(47.4430, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(47.3664, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(46.8617, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(46.8406, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(46.7437, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(46.3374, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(46.1490, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(45.9392, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(45.7007, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(45.4587, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(45.0544, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(44.9896, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(44.4362, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(44.4024, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(43.8631, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(43.1034, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(41.9165, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(43.0062, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(42.2692, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(42.1266, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(41.7017, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(40.6304, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(41.0786, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(40.2347, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(40.4828, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(40.2117, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(39.3809, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(38.9242, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(39.0584, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(38.6417, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(38.3508, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(37.8054, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(37.2739, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(37.7263, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(35.5377, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(36.7985, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(36.1234, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(35.3901, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(36.0790, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(33.4461, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(35.2396, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(34.6796, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(33.4229, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(33.8678, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(33.5067, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(32.9828, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(31.8708, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(32.1741, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(32.3189, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(31.7823, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(31.2181, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(30.3525, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(29.8001, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(29.1951, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(29.6801, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(29.0791, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(29.1040, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(29.5865, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(28.6693, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(26.8499, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(28.0065, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(27.6249, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(26.9379, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(25.9171, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(25.5964, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(24.6478, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(25.1787, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(25.2257, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(25.0722, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(24.6975, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(24.6096, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(22.4344, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(22.8994, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(20.9932, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(22.1613, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(22.0964, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(20.2000, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(21.9548, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(20.2539, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(19.2057, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(19.3481, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(18.6857, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(18.6817, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(19.3509, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(16.2617, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(16.8153, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(18.6473, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(16.5536, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(16.0432, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(14.4866, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(15.0146, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(14.5699, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(13.2005, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(14.0704, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(13.1049, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(13.3466, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(11.9942, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(12.7432, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(12.0523, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(10.8452, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(10.4954, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(10.8306, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(10.6720, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(10.2763, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(6.8642, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(9.1261, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(9.3761, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(7.9371, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(5.9732, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7.9305, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(6.7803, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(7.2352, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(5.8022, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(5.3050, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(6.1316, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(5.7743, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(5.1361, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(4.6521, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(5.3469, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(4.0435, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(4.2239, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(3.8407, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(3.6753, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(3.8019, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(3.4717, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(2.7571, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(2.8870, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(2.8557, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(2.8544, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(2.0260, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(2.8137, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(1.9565, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(1.9170, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(2.1851, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(1.8885, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(1.7422, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(1.7351, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(1.4649, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(1.3344, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(1.2772, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(1.3087, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(1.2505, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(1.5782, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(0.8917, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(1.2237, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(1.0768, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(1.3392, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(0.9798, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(0.9844, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(0.8398, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(0.9037, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(0.9245, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(0.7561, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(0.6217, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(0.8426, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(0.6648, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(0.5771, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(0.4937, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(0.6995, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(0.5174, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(0.4533, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(0.4867, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(0.3992, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(0.4375, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(0.3153, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(0.4863, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(0.4435, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(0.3089, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(0.3927, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(0.4191, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(0.2817, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(0.3345, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(0.3489, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(0.3724, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(0.2693, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(0.2648, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(0.2191, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(0.2424, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(0.2022, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(0.2122, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(0.2080, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(0.1817, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(0.2117, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(0.2379, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(0.1690, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(0.1730, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(0.1635, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(0.1482, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(0.1816, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(0.1317, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(0.1314, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(0.1362, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(0.1059, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(0.1272, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "14001\n",
      "[INFO] Exp. name : cv11Lu_asr_lstm4atthead_allvocab-biclass2-5fold-4_sd0                                   \n",
      "[INFO] Loading data... large dataset may took a while.                                                     \n",
      "Load data for training/validation, store tokenizer and input/output shape\n",
      "Prepare dataloader for training/validation\n",
      "Interface for creating all kinds of dataset\n",
      "import VAGDataset as Dataset\n",
      "[VAGDataset] path: /home/jupyter-jason5/data_process, split: ['CTT5-4-2']\n",
      "Mozillacv11Dataset CTT5-4-2 found wav data: 17\n",
      "text len: 17\n",
      "remove None, then wav data: 17, text len: 17\n",
      "[VAGDataset] path: /home/jupyter-jason5/data_process, split: ['CTT5-1-2', 'CTT5-2-2', 'CTT5-3-2', 'CTT5-5-2']\n",
      "Mozillacv11Dataset CTT5-1-2 found wav data: 19\n",
      "Mozillacv11Dataset CTT5-2-2 found wav data: 18\n",
      "Mozillacv11Dataset CTT5-3-2 found wav data: 17\n",
      "Mozillacv11Dataset CTT5-5-2 found wav data: 17\n",
      "text len: 71\n",
      "remove None, then wav data: 71, text len: 71\n",
      "[INFO] Data spec. | Corpus = vag (from /home/jupyter-jason5/data_process)                                  \n",
      "[INFO]            | Train sets = ['CTT5-1-2', 'CTT5-2-2', 'CTT5-3-2', 'CTT5-5-2']\t| Number of utts = 71    \n",
      "[INFO]            | Dev sets = ['CTT5-4-2']\t| Number of utts = 17                                          \n",
      "[INFO]            | Batch size = 1\t\t| Bucketing = True                                                     \n",
      "[INFO] I/O spec.  | Audio feature = fbank\t| feature dim = 120                                              \n",
      "Setup ASR model and optimizer \n",
      "[INFO] Model spec.| Encoder's downsampling rate of time axis is 4.                                         \n",
      "[INFO]            | VCC Extractor w/ time downsampling rate = 4 in encoder enabled.                        \n",
      "# Losses\n",
      "# Note: zero_infinity=False is unstable?\n",
      "# Optimizer\n",
      "[INFO] Optim.spec.| Algo. = Adadelta\t| Lr = 1.0\t (Scheduler = fixed)| Scheduled sampling = False           \n",
      "# Enable AMP if needed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Load ckpt from ./ckpt/mozillacv11_asr_stm4atthead_sd0/best_att.pth, restarting at step 1000000 )    \n",
      "encoder.layers.4.layer.weight_ih_l0_reverse\n",
      "encoder.layers.4.layer.weight_hh_l0_reverse\n",
      "encoder.layers.4.layer.bias_ih_l0_reverse\n",
      "encoder.layers.4.layer.bias_hh_l0_reverse\n",
      "fc.weight\n",
      "fc.bias\n",
      "Training End-to-end ASR system\n",
      "[INFO] Total training steps 1.0K.                                                                          \n",
      "self.tr_set: 71\n",
      "tensor(48.5335, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(47.2614, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(47.3978, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(47.1623, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(46.5702, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(46.4024, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(46.0027, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(45.3722, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(45.3028, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(44.8354, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(43.5083, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(43.8273, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(43.2671, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(42.8802, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(41.1040, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(41.1373, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(40.8127, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(38.3815, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(39.1796, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(39.7872, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(38.8036, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(37.9646, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(38.4868, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(37.2789, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(38.3385, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(36.7797, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(37.2859, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(36.2055, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(36.3082, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(37.3220, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(35.5019, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(35.7761, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(35.9946, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(36.1690, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(33.6748, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(35.1814, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(33.6595, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(34.4422, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(33.2451, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(33.9117, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(33.7669, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(32.0619, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(32.3216, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(32.8666, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(33.1425, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(32.8228, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(31.8960, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(31.6975, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(30.5013, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(30.2996, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(31.5746, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(30.3620, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(28.1970, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(29.2308, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(29.8404, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(26.5695, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(29.2214, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(28.3597, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(28.6820, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(27.2757, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(28.0564, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(27.1514, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(26.9260, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(25.0964, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(25.1175, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(22.5932, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(25.7600, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(24.7248, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(24.7890, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(24.5436, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(23.9468, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(23.8183, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(23.3374, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(22.7946, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(20.5397, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(23.2392, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(20.2133, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(21.2223, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(21.6948, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(21.8521, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(20.6659, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(20.3495, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(20.1549, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(18.3831, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(18.1133, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(19.0506, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(18.2594, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(17.2645, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(17.3707, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(17.2325, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(16.8278, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(17.4968, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(14.6466, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(14.6492, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(15.8064, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(14.9025, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(13.3739, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(16.1396, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(13.9460, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(13.0421, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(13.4372, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(13.5219, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(12.0707, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(12.7614, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(11.3248, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(12.7649, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(12.1857, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(10.7892, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(11.7385, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(10.1834, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(10.9168, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(10.4329, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(9.9349, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(10.5414, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(10.5115, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(8.6887, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(8.5669, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(9.3468, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(7.2631, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(8.3051, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(8.2578, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(7.6506, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(7.1229, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(7.0078, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(7.4400, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(7.6120, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(8.2774, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(7.5007, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(6.3243, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(7.0353, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(6.4921, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(6.0047, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(6.1377, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(6.0397, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(5.9798, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(5.1482, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(4.8908, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(5.5623, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(5.2341, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(3.5829, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(4.8916, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(5.0445, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(3.3541, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(4.3800, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(3.4695, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(2.8134, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(3.0610, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(3.9679, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(3.0046, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(4.1710, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(2.9886, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(3.3568, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(2.8751, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(3.4051, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(2.5194, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(3.3054, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(2.8418, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(2.4959, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(2.5845, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(2.9905, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(2.0252, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(2.1607, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(2.0466, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(1.9258, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(2.3709, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(1.9289, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(2.0862, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(1.9928, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(1.6419, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(1.4140, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(1.4692, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(1.8273, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(1.7136, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(1.2585, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(1.7970, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(1.4886, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(1.2351, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(0.9987, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(1.1576, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(1.0829, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(1.1301, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(1.1125, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(0.9140, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(0.9567, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(1.0538, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(0.6111, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(1.0280, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(0.7370, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(0.8927, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(0.8620, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(0.8299, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(0.6567, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(0.7091, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(0.8158, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(0.4902, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "14001\n",
      "[INFO] Exp. name : cv11Lu_asr_lstm4atthead_allvocab-biclass2-5fold-5_sd0                                   \n",
      "[INFO] Loading data... large dataset may took a while.                                                     \n",
      "Load data for training/validation, store tokenizer and input/output shape\n",
      "Prepare dataloader for training/validation\n",
      "Interface for creating all kinds of dataset\n",
      "import VAGDataset as Dataset\n",
      "[VAGDataset] path: /home/jupyter-jason5/data_process, split: ['CTT5-5-2']\n",
      "Mozillacv11Dataset CTT5-5-2 found wav data: 17\n",
      "text len: 17\n",
      "remove None, then wav data: 17, text len: 17\n",
      "[VAGDataset] path: /home/jupyter-jason5/data_process, split: ['CTT5-1-2', 'CTT5-2-2', 'CTT5-3-2', 'CTT5-4-2']\n",
      "Mozillacv11Dataset CTT5-1-2 found wav data: 19\n",
      "Mozillacv11Dataset CTT5-2-2 found wav data: 18\n",
      "Mozillacv11Dataset CTT5-3-2 found wav data: 17\n",
      "Mozillacv11Dataset CTT5-4-2 found wav data: 17\n",
      "text len: 71\n",
      "remove None, then wav data: 71, text len: 71\n",
      "[INFO] Data spec. | Corpus = vag (from /home/jupyter-jason5/data_process)                                  \n",
      "[INFO]            | Train sets = ['CTT5-1-2', 'CTT5-2-2', 'CTT5-3-2', 'CTT5-4-2']\t| Number of utts = 71    \n",
      "[INFO]            | Dev sets = ['CTT5-5-2']\t| Number of utts = 17                                          \n",
      "[INFO]            | Batch size = 1\t\t| Bucketing = True                                                     \n",
      "[INFO] I/O spec.  | Audio feature = fbank\t| feature dim = 120                                              \n",
      "Setup ASR model and optimizer \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Model spec.| Encoder's downsampling rate of time axis is 4.                                         \n",
      "[INFO]            | VCC Extractor w/ time downsampling rate = 4 in encoder enabled.                        \n",
      "# Losses\n",
      "# Note: zero_infinity=False is unstable?\n",
      "# Optimizer\n",
      "[INFO] Optim.spec.| Algo. = Adadelta\t| Lr = 1.0\t (Scheduler = fixed)| Scheduled sampling = False           \n",
      "# Enable AMP if needed\n",
      "[INFO] Load ckpt from ./ckpt/mozillacv11_asr_stm4atthead_sd0/best_att.pth, restarting at step 1000000 )    \n",
      "encoder.layers.4.layer.weight_ih_l0_reverse\n",
      "encoder.layers.4.layer.weight_hh_l0_reverse\n",
      "encoder.layers.4.layer.bias_ih_l0_reverse\n",
      "encoder.layers.4.layer.bias_hh_l0_reverse\n",
      "fc.weight\n",
      "fc.bias\n",
      "Training End-to-end ASR system\n",
      "[INFO] Total training steps 1.0K.                                                                          \n",
      "self.tr_set: 71\n",
      "tensor(48.2667, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(47.7431, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(47.2933, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(47.0784, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(47.1852, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(46.7514, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(46.7097, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(46.2379, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(46.1534, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(46.0434, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(46.0634, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(45.4417, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(45.6778, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(45.1391, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(44.8983, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(44.4215, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(44.0368, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(43.8927, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(43.4715, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(43.6444, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(43.1364, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(42.9353, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(43.0034, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(42.5946, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(42.9273, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(42.7030, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(42.0921, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(42.3052, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(41.7324, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(41.8493, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(41.9446, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(40.5941, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(39.8625, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(41.2200, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(41.0946, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(40.8453, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(40.5414, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(40.2355, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(40.7367, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(37.1620, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(40.6979, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(39.6734, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(39.1536, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(39.2324, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(37.0255, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(38.9453, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(36.4001, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(38.4302, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(36.7903, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(37.1376, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(34.5802, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(37.3085, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(36.4114, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(36.2148, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(35.4257, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(35.5260, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(33.2518, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(35.0403, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(34.8595, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(32.0129, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(32.6463, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(31.9231, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(33.3550, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(31.2538, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(30.5612, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(30.6788, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(30.1680, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(31.4043, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(28.0559, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(30.8869, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(29.0101, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(26.0167, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(28.9416, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(26.8020, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(26.9172, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(26.5453, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(26.2271, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(25.1289, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(24.6277, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(22.7519, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(24.1784, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(24.1880, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(24.1800, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(22.2921, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(21.4330, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(21.9616, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(21.6860, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(20.3250, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(19.5934, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(18.1388, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(19.5935, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(17.2858, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(18.8763, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(17.9629, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(17.5469, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(15.5321, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(16.7961, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(15.0789, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(15.3724, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(15.2293, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(14.2074, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(14.1405, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(13.9709, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(12.8776, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(13.3076, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(10.8517, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(10.7350, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(10.3987, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(12.7234, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(10.2826, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(11.7192, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(7.4259, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(10.5767, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(8.8432, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(8.9926, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(8.8089, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(8.4582, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(8.1442, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(8.2952, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(7.6448, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(6.9371, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(4.9384, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(6.2833, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(5.3132, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(6.2728, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(7.2726, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(5.6793, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(5.8012, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(6.0270, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(4.6016, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(5.0174, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(6.1949, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(4.9856, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(4.9193, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(4.3642, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(4.8953, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(4.3294, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(4.1637, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(5.0412, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(3.4674, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(3.6510, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(3.9880, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(3.6039, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(2.7840, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(3.8089, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(3.1806, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(3.0480, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(3.0075, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(2.9910, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(2.5051, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(3.4262, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(1.8908, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(2.7396, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(2.6401, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(2.3233, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(2.3186, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(2.2398, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(1.7762, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(1.9003, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(1.6961, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(1.3756, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(1.3352, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(1.6374, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(2.0217, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(1.7812, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(1.0901, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(2.0098, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(1.3371, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(1.1877, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(1.0882, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(0.8922, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(1.0081, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(0.8438, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(1.0195, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(1.0065, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(1.2528, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(0.9099, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(0.6487, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(1.0513, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(0.6815, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(1.0437, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(0.5434, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(0.9081, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(0.6792, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(0.6068, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(1.2902, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(0.5942, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(0.5598, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(0.6460, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(0.4351, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(0.4639, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(0.6123, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(0.7021, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(0.4253, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(0.5127, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(0.4066, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "tensor(0.4728, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 71\n",
      "14001\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "environmental-amsterdam",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('asd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "normal-grocery",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "============  Result of /home/jupyter-jason3/LAS_Mandarin_PyTorch-master/result/mozillacv11_asr_stm4atthead-test_test_output.csv ============\r\n",
      " -----------------------------------------------------------------------\r\n",
      "| Statics\t\t|  Truth\t|  Prediction\t| Abs. Diff.\t|\r\n",
      " -----------------------------------------------------------------------\r\n",
      "| Avg. # of chars\t|  8.01\t|  8.10\t|  0.16\t\t|\r\n",
      "| Avg. # of words\t|  1.00\t|  1.00\t|  0.00\t\t|\r\n",
      " -----------------------------------------------------------------------\r\n",
      " ---------------------------------------------------------------\r\n",
      "| Error Rate (%)| Mean\t\t| Std.\t\t| Min./Max.\t|\r\n",
      " ---------------------------------------------------------------\r\n",
      "| Character\t| 7.9479\t| 21.68\t\t| 0.00/240.00\t|\r\n",
      "| Word\t\t| 18.1725\t| 38.56\t\t| 0.00/100.00\t|\r\n",
      " ---------------------------------------------------------------\r\n",
      "Note : If the text unit is phoneme, WER = PER and CER is meaningless.\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!python eval.py --file ~/LAS_Mandarin_PyTorch-master/result/mozillacv11_asr_stm4atthead-test_test_output.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earlier-assignment",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
