{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "impossible-payment",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "expensive-boutique",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
    "# os.environ['CUDA_VISIBLE_DEVICES']='0,1'\n",
    "os.environ['CUDA_LAUNCH_BLOCKING']='1'\n",
    "import torch\n",
    "# torch.cuda.set_device(0)\n",
    "print(torch.cuda.current_device())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "spiritual-classic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "amino-coordinate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "written-skirt",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "blessed-friday",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cudaSetDevice(0)\n",
    "#dataset transcript要在dataset資好夾調\n",
    "#cuda 在basesolver init調\n",
    "#dataset要在data.py設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "illegal-estate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
    "# os.environ['CUDA_VISIBLE_DEVICES']='0,1'\n",
    "os.environ['CUDA_LAUNCH_BLOCKING']='1'\n",
    "import torch\n",
    "# torch.cuda.set_device(0)\n",
    "print(torch.cuda.current_device())\n",
    "#! python\n",
    "# -*- coding: utf-8 -*-\n",
    "# Author: kun\n",
    "# @Time: 2019-10-29 20:29\n",
    "\n",
    "import yaml\n",
    "import torch\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "class Para(object):\n",
    "    a=1\n",
    "\n",
    "def force_cudnn_initialization():\n",
    "    s = 32\n",
    "    dev = torch.device('cuda:0')\n",
    "    torch.nn.functional.conv2d(torch.zeros(s, s, s, s, device=dev), torch.zeros(s, s, s, s, device=dev))\n",
    "    \n",
    "#force_cudnn_initialization()\n",
    "def main():\n",
    "    # For reproducibility, comment these may speed up training\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    # Arguments\n",
    "#     parser = argparse.ArgumentParser(description='Training E2E asr.')\n",
    "#     parser.add_argument('--config', type=str, help='Path to experiment config.')\n",
    "#     parser.add_argument('--name', default=None, type=str, help='Name for logging.')\n",
    "#     parser.add_argument('--logdir', default='log/', type=str,\n",
    "#                         help='Logging path.', required=False)\n",
    "#     parser.add_argument('--ckpdir', default='ckpt/', type=str,\n",
    "#                         help='Checkpoint path.', required=False)\n",
    "#     parser.add_argument('--outdir', default='result/', type=str,\n",
    "#                         help='Decode output path.', required=False)\n",
    "#     parser.add_argument('--load', default=None, type=str,\n",
    "#                         help='Load pre-trained model (for training only)', required=False)\n",
    "#     parser.add_argument('--seed', default=0, type=int,\n",
    "#                         help='Random seed for reproducable results.', required=False)\n",
    "#     parser.add_argument('--cudnn-ctc', action='store_true',\n",
    "#                         help='Switches CTC backend from torch to cudnn')\n",
    "#     parser.add_argument('--njobs', default=32, type=int,\n",
    "#                         help='Number of threads for dataloader/decoding.', required=False)\n",
    "#     parser.add_argument('--cpu', action='store_true', help='Disable GPU training.')\n",
    "#     parser.add_argument('--no-pin', action='store_true',\n",
    "#                         help='Disable pin-memory for dataloader')\n",
    "#     parser.add_argument('--test', action='store_true', help='Test the model.')\n",
    "#     parser.add_argument('--no-msg', action='store_true', help='Hide all messages.')\n",
    "#     parser.add_argument('--lm', action='store_true',\n",
    "#                         help='Option for training RNNLM.')\n",
    "#     # Following features in development.\n",
    "#     parser.add_argument('--amp', action='store_true', help='Option to enable AMP.')\n",
    "#     parser.add_argument('--reserve-gpu', default=0, type=float,\n",
    "#                         help='Option to reserve GPU ram for training.')\n",
    "#     parser.add_argument('--jit', action='store_true',\n",
    "#                         help='Option for enabling jit in pytorch. (feature in development)')\n",
    "#     ###\n",
    "#     paras = parser.parse_args()\n",
    "    paras = Para()\n",
    "#     paras.config = './config/aishell_asr_example_lstm4atthead1-test.yaml'\n",
    "#     paras.name = None\n",
    "#     paras.logdir = 'log/'\n",
    "#     paras.ckpdir = 'ckpt/'\n",
    "#     paras.outdir = 'result/'\n",
    "#     paras.load = None\n",
    "#     paras.seed = 0\n",
    "#     paras.cudnn_ctc = False\n",
    "#     paras.cpu = False\n",
    "#     paras.no_pin = False\n",
    "#     paras.test = True\n",
    "#     paras.no_msg = False\n",
    "#     paras.lm = False\n",
    "#     paras.amp = False\n",
    "#     paras.reserve_gpu = 0\n",
    "#     paras.jit = False\n",
    "    setattr(paras, 'config', './config/cv11Lu_asr_lstm4atthead_allvocab-biclass2.yaml')\n",
    "    setattr(paras, 'name', None)\n",
    "    setattr(paras, 'logdir', 'log/')\n",
    "    setattr(paras, 'ckpdir', 'ckpt/')\n",
    "    setattr(paras, 'outdir', 'result/')\n",
    "    setattr(paras, 'load', './ckpt/cv11Lu_asr_lstm4atthead_allvocab_sd0/best_att-VAG01.pth')\n",
    "    setattr(paras, 'seed', 0)\n",
    "    setattr(paras, 'cudnn_ctc', False)\n",
    "    setattr(paras, 'njobs',8)\n",
    "    setattr(paras, 'cpu', False)\n",
    "    setattr(paras, 'no_pin', False)\n",
    "    setattr(paras, 'test', False)\n",
    "    setattr(paras, 'no_msg', False)\n",
    "    setattr(paras, 'lm', False)\n",
    "    setattr(paras, 'amp', False)\n",
    "    setattr(paras, 'reserve_gpu', 12)\n",
    "    setattr(paras, 'jit', False)\n",
    "    setattr(paras, 'gpu', not paras.cpu)\n",
    "    setattr(paras, 'pin_memory', not paras.no_pin)\n",
    "    setattr(paras, 'verbose', not paras.no_msg)\n",
    "    setattr(paras, 'finetune', False)\n",
    "    setattr(paras, 'binaryClass', True)\n",
    "    force_cudnn_initialization()\n",
    "\n",
    "    config = yaml.load(open(paras.config, 'r'), Loader=yaml.FullLoader)\n",
    "\n",
    "    np.random.seed(paras.seed)\n",
    "    torch.manual_seed(paras.seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(paras.seed)\n",
    "\n",
    "    # Hack to preserve GPU ram just incase OOM later on server\n",
    "    if paras.gpu and paras.reserve_gpu > 0:\n",
    "        buff = torch.randn(int(paras.reserve_gpu * 1e9 // 4)).cuda()\n",
    "        del buff\n",
    "\n",
    "    if paras.lm:\n",
    "        # Train RNNLM\n",
    "        from train_lm import Solver\n",
    "\n",
    "        mode = 'train'\n",
    "    else:\n",
    "        if paras.test:\n",
    "            # Test ASR\n",
    "            assert paras.load is None, 'Load option is mutually exclusive to --test'\n",
    "            from test_asr import Solver\n",
    "\n",
    "            mode = 'test'\n",
    "        elif paras.finetune:\n",
    "            assert paras.load is not None\n",
    "            from finetune_asr import Solver\n",
    "            mode = 'train'\n",
    "        elif paras.binaryClass:\n",
    "            assert paras.load is not None\n",
    "            from train_binaryclass2_4folds import Solver\n",
    "            mode = 'train'\n",
    "        else:\n",
    "            # Train ASR\n",
    "            from train_asr import Solver\n",
    "\n",
    "            mode = 'train'\n",
    "\n",
    "    print(\"\\nUsing {} mode\\n\".format(mode))\n",
    "    for idx in range(4):\n",
    "        paras.config = f'./config/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-{idx+1}.yaml'\n",
    "        config = yaml.load(open(paras.config, 'r'), Loader=yaml.FullLoader)\n",
    "        solver = Solver(config, paras, mode)\n",
    "\n",
    "        solver.load_data()\n",
    "    #     solver.print_model()\n",
    "        solver.set_model()\n",
    "        solver.exec()\n",
    "        del solver\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "taken-nerve",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using train mode\n",
      "\n",
      "[INFO] Exp. name : cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-1_sd0                                   \n",
      "[INFO] Loading data... large dataset may took a while.                                                     \n",
      "Load data for training/validation, store tokenizer and input/output shape\n",
      "Prepare dataloader for training/validation\n",
      "Interface for creating all kinds of dataset\n",
      "import VAGDataset as Dataset\n",
      "[VAGDataset] path: /home/jupyter-jason5/data_process, split: ['CTT4val-1']\n",
      "Mozillacv11Dataset CTT4val-1 found wav data: 5\n",
      "text len: 5\n",
      "remove None, then wav data: 5, text len: 5\n",
      "[VAGDataset] path: /home/jupyter-jason5/data_process, split: ['CTT4-4', 'CTT4-2', 'CTT4-3', 'CTT4val-4', 'CTT4val-2', 'CTT4val-3']\n",
      "Mozillacv11Dataset CTT4-4 found wav data: 19\n",
      "Mozillacv11Dataset CTT4-2 found wav data: 20\n",
      "Mozillacv11Dataset CTT4-3 found wav data: 19\n",
      "Mozillacv11Dataset CTT4val-4 found wav data: 5\n",
      "Mozillacv11Dataset CTT4val-2 found wav data: 5\n",
      "Mozillacv11Dataset CTT4val-3 found wav data: 5\n",
      "text len: 73\n",
      "remove None, then wav data: 73, text len: 73\n",
      "[INFO] Data spec. | Corpus = vag (from /home/jupyter-jason5/data_process)                                  \n",
      "[INFO]            | Train sets = ['CTT4-4', 'CTT4-2', 'CTT4-3', 'CTT4val-4', 'CTT4val-2', 'CTT4val-3']\t| Number of utts = 73\n",
      "[INFO]            | Dev sets = ['CTT4val-1']\t| Number of utts = 5                                          \n",
      "[INFO]            | Batch size = 1\t\t| Bucketing = True                                                     \n",
      "[INFO] I/O spec.  | Audio feature = fbank\t| feature dim = 120                                              \n",
      "Setup ASR model and optimizer \n",
      "[INFO] Model spec.| Encoder's downsampling rate of time axis is 4.                                         \n",
      "[INFO]            | VCC Extractor w/ time downsampling rate = 4 in encoder enabled.                        \n",
      "# Losses\n",
      "# Note: zero_infinity=False is unstable?\n",
      "# Optimizer\n",
      "[INFO] Optim.spec.| Algo. = Adadelta\t| Lr = 1.0\t (Scheduler = fixed)| Scheduled sampling = False           \n",
      "# Enable AMP if needed\n",
      "[INFO] Load ckpt from ./ckpt/cv11Lu_asr_lstm4atthead_allvocab_sd0/best_att-VAG01.pth, restarting at step 795000 (recorded wer = 0.11 %)\n",
      "encoder.layers.0.extractor.0.weight\n",
      "encoder.layers.0.extractor.0.bias\n",
      "encoder.layers.0.extractor.2.weight\n",
      "encoder.layers.0.extractor.2.bias\n",
      "encoder.layers.0.extractor.5.weight\n",
      "encoder.layers.0.extractor.5.bias\n",
      "encoder.layers.0.extractor.7.weight\n",
      "encoder.layers.0.extractor.7.bias\n",
      "encoder.layers.1.layer.weight_ih_l0\n",
      "encoder.layers.1.layer.weight_hh_l0\n",
      "encoder.layers.1.layer.bias_ih_l0\n",
      "encoder.layers.1.layer.bias_hh_l0\n",
      "encoder.layers.1.layer.weight_ih_l0_reverse\n",
      "encoder.layers.1.layer.weight_hh_l0_reverse\n",
      "encoder.layers.1.layer.bias_ih_l0_reverse\n",
      "encoder.layers.1.layer.bias_hh_l0_reverse\n",
      "encoder.layers.1.pj.weight\n",
      "encoder.layers.1.pj.bias\n",
      "encoder.layers.2.layer.weight_ih_l0\n",
      "encoder.layers.2.layer.weight_hh_l0\n",
      "encoder.layers.2.layer.bias_ih_l0\n",
      "encoder.layers.2.layer.bias_hh_l0\n",
      "encoder.layers.2.layer.weight_ih_l0_reverse\n",
      "encoder.layers.2.layer.weight_hh_l0_reverse\n",
      "encoder.layers.2.layer.bias_ih_l0_reverse\n",
      "encoder.layers.2.layer.bias_hh_l0_reverse\n",
      "encoder.layers.2.pj.weight\n",
      "encoder.layers.2.pj.bias\n",
      "encoder.layers.3.layer.weight_ih_l0\n",
      "encoder.layers.3.layer.weight_hh_l0\n",
      "encoder.layers.3.layer.bias_ih_l0\n",
      "encoder.layers.3.layer.bias_hh_l0\n",
      "encoder.layers.3.layer.weight_ih_l0_reverse\n",
      "encoder.layers.3.layer.weight_hh_l0_reverse\n",
      "encoder.layers.3.layer.bias_ih_l0_reverse\n",
      "encoder.layers.3.layer.bias_hh_l0_reverse\n",
      "encoder.layers.3.pj.weight\n",
      "encoder.layers.3.pj.bias\n",
      "encoder.layers.4.layer.weight_ih_l0\n",
      "encoder.layers.4.layer.weight_hh_l0\n",
      "encoder.layers.4.layer.bias_ih_l0\n",
      "encoder.layers.4.layer.bias_hh_l0\n",
      "encoder.layers.4.layer.weight_ih_l0_reverse\n",
      "encoder.layers.4.layer.weight_hh_l0_reverse\n",
      "encoder.layers.4.layer.bias_ih_l0_reverse\n",
      "encoder.layers.4.layer.bias_hh_l0_reverse\n",
      "encoder.layers.4.pj.weight\n",
      "encoder.layers.4.pj.bias\n",
      "fc.weight\n",
      "fc.bias\n",
      "Training End-to-end ASR system\n",
      "[INFO] Total training steps 1.0M.                                                                          \n",
      "self.tr_set: 73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-jason5/LAS_Mandarin_PyTorch-master/core/module.py:51: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  feat_len = feat_len // 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Saved checkpoint (step = 795.0K, loss = 0.61) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-1_sd0/best_biclass.pth\n",
      "43\n",
      "bestloss3.4014763832092285\n",
      "tensor(61.0084, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "[INFO] Saved checkpoint (step = 795.1K, loss = 0.58) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-1_sd0/best_biclass.pth\n",
      "116\n",
      "bestloss3.3900601863861084\n",
      "tensor(53.0420, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(59.5195, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(53.0600, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "[INFO] Saved checkpoint (step = 795.3K, loss = 0.51) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-1_sd0/best_biclass.pth\n",
      "335\n",
      "bestloss3.354658603668213\n",
      "tensor(52.9038, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(62.5491, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(52.9993, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(56.1881, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(57.5583, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(23.3755, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(5.8663, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(10.0318, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(6.1295, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(0.0041, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(0.0012, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(0.0010, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(0.0008, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(0.0006, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(0.0005, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(0.0004, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(0.0004, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(0.0004, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(0.0003, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(0.0003, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(0.0003, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(0.0003, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(0.0003, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(9.7871e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(9.5546e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(9.3162e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(9.0957e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(8.8871e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(8.7023e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(8.5235e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(8.3566e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(8.1956e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(7.9632e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(7.8142e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(7.7069e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(7.5221e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(7.3850e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(7.2479e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(7.1645e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(7.0036e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(6.8665e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(6.7413e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(6.6638e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(6.5029e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(6.4015e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(6.3181e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(6.2227e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(6.1393e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(6.0082e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(5.9485e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(5.8115e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(5.7459e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(5.6446e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(5.5790e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(5.5432e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(5.4240e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(5.3287e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(5.2452e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(5.1618e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(5.1022e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(5.0247e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(5.0008e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(4.9353e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(4.8399e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(4.8161e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(4.7445e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(4.6849e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(4.6074e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(4.5836e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(4.5300e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "802300\n",
      "[INFO] Exp. name : cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-2_sd0                                   \n",
      "[INFO] Loading data... large dataset may took a while.                                                     \n",
      "Load data for training/validation, store tokenizer and input/output shape\n",
      "Prepare dataloader for training/validation\n",
      "Interface for creating all kinds of dataset\n",
      "import VAGDataset as Dataset\n",
      "[VAGDataset] path: /home/jupyter-jason5/data_process, split: ['CTT4val-2']\n",
      "Mozillacv11Dataset CTT4val-2 found wav data: 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text len: 5\n",
      "remove None, then wav data: 5, text len: 5\n",
      "[VAGDataset] path: /home/jupyter-jason5/data_process, split: ['CTT4-1', 'CTT4-4', 'CTT4-3', 'CTT4val-1', 'CTT4val-4', 'CTT4val-3']\n",
      "Mozillacv11Dataset CTT4-1 found wav data: 21\n",
      "Mozillacv11Dataset CTT4-4 found wav data: 19\n",
      "Mozillacv11Dataset CTT4-3 found wav data: 19\n",
      "Mozillacv11Dataset CTT4val-1 found wav data: 5\n",
      "Mozillacv11Dataset CTT4val-4 found wav data: 5\n",
      "Mozillacv11Dataset CTT4val-3 found wav data: 5\n",
      "text len: 74\n",
      "remove None, then wav data: 74, text len: 74\n",
      "[INFO] Data spec. | Corpus = vag (from /home/jupyter-jason5/data_process)                                  \n",
      "[INFO]            | Train sets = ['CTT4-1', 'CTT4-4', 'CTT4-3', 'CTT4val-1', 'CTT4val-4', 'CTT4val-3']\t| Number of utts = 74\n",
      "[INFO]            | Dev sets = ['CTT4val-2']\t| Number of utts = 5                                          \n",
      "[INFO]            | Batch size = 1\t\t| Bucketing = True                                                     \n",
      "[INFO] I/O spec.  | Audio feature = fbank\t| feature dim = 120                                              \n",
      "Setup ASR model and optimizer \n",
      "[INFO] Model spec.| Encoder's downsampling rate of time axis is 4.                                         \n",
      "[INFO]            | VCC Extractor w/ time downsampling rate = 4 in encoder enabled.                        \n",
      "# Losses\n",
      "# Note: zero_infinity=False is unstable?\n",
      "# Optimizer\n",
      "[INFO] Optim.spec.| Algo. = Adadelta\t| Lr = 1.0\t (Scheduler = fixed)| Scheduled sampling = False           \n",
      "# Enable AMP if needed\n",
      "[INFO] Load ckpt from ./ckpt/cv11Lu_asr_lstm4atthead_allvocab_sd0/best_att-VAG01.pth, restarting at step 795000 (recorded wer = 0.11 %)\n",
      "encoder.layers.0.extractor.0.weight\n",
      "encoder.layers.0.extractor.0.bias\n",
      "encoder.layers.0.extractor.2.weight\n",
      "encoder.layers.0.extractor.2.bias\n",
      "encoder.layers.0.extractor.5.weight\n",
      "encoder.layers.0.extractor.5.bias\n",
      "encoder.layers.0.extractor.7.weight\n",
      "encoder.layers.0.extractor.7.bias\n",
      "encoder.layers.1.layer.weight_ih_l0\n",
      "encoder.layers.1.layer.weight_hh_l0\n",
      "encoder.layers.1.layer.bias_ih_l0\n",
      "encoder.layers.1.layer.bias_hh_l0\n",
      "encoder.layers.1.layer.weight_ih_l0_reverse\n",
      "encoder.layers.1.layer.weight_hh_l0_reverse\n",
      "encoder.layers.1.layer.bias_ih_l0_reverse\n",
      "encoder.layers.1.layer.bias_hh_l0_reverse\n",
      "encoder.layers.1.pj.weight\n",
      "encoder.layers.1.pj.bias\n",
      "encoder.layers.2.layer.weight_ih_l0\n",
      "encoder.layers.2.layer.weight_hh_l0\n",
      "encoder.layers.2.layer.bias_ih_l0\n",
      "encoder.layers.2.layer.bias_hh_l0\n",
      "encoder.layers.2.layer.weight_ih_l0_reverse\n",
      "encoder.layers.2.layer.weight_hh_l0_reverse\n",
      "encoder.layers.2.layer.bias_ih_l0_reverse\n",
      "encoder.layers.2.layer.bias_hh_l0_reverse\n",
      "encoder.layers.2.pj.weight\n",
      "encoder.layers.2.pj.bias\n",
      "encoder.layers.3.layer.weight_ih_l0\n",
      "encoder.layers.3.layer.weight_hh_l0\n",
      "encoder.layers.3.layer.bias_ih_l0\n",
      "encoder.layers.3.layer.bias_hh_l0\n",
      "encoder.layers.3.layer.weight_ih_l0_reverse\n",
      "encoder.layers.3.layer.weight_hh_l0_reverse\n",
      "encoder.layers.3.layer.bias_ih_l0_reverse\n",
      "encoder.layers.3.layer.bias_hh_l0_reverse\n",
      "encoder.layers.3.pj.weight\n",
      "encoder.layers.3.pj.bias\n",
      "encoder.layers.4.layer.weight_ih_l0\n",
      "encoder.layers.4.layer.weight_hh_l0\n",
      "encoder.layers.4.layer.bias_ih_l0\n",
      "encoder.layers.4.layer.bias_hh_l0\n",
      "encoder.layers.4.layer.weight_ih_l0_reverse\n",
      "encoder.layers.4.layer.weight_hh_l0_reverse\n",
      "encoder.layers.4.layer.bias_ih_l0_reverse\n",
      "encoder.layers.4.layer.bias_hh_l0_reverse\n",
      "encoder.layers.4.pj.weight\n",
      "encoder.layers.4.pj.bias\n",
      "fc.weight\n",
      "fc.bias\n",
      "Training End-to-end ASR system\n",
      "[INFO] Total training steps 1.0M.                                                                          \n",
      "self.tr_set: 74\n",
      "[INFO] Saved checkpoint (step = 795.0K, loss = 0.66) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-2_sd0/best_biclass.pth\n",
      "43\n",
      "bestloss3.439915657043457\n",
      "tensor(62.8538, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "[INFO] Saved checkpoint (step = 795.1K, loss = 0.57) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-2_sd0/best_biclass.pth\n",
      "116\n",
      "bestloss3.3733971118927\n",
      "tensor(63.0419, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "[INFO] Saved checkpoint (step = 795.2K, loss = 0.54) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-2_sd0/best_biclass.pth\n",
      "189\n",
      "bestloss3.3635854721069336\n",
      "tensor(52.2585, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(51.8584, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(58.1328, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(55.4210, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(56.7771, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(59.7822, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(62.8073, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(57.0590, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(35.3715, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(13.5560, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(18.5828, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(0.3228, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(0.0252, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(0.0041, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(0.0014, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(0.0011, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(0.0009, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(0.0008, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(0.0006, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(0.0006, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(0.0005, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(0.0005, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(0.0004, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(0.0004, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(0.0004, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(0.0003, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(0.0003, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(0.0003, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(0.0003, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(0.0003, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(0.0003, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(0.0003, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0001, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(9.9838e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(9.8050e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(9.6023e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(9.4116e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(9.2685e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(9.0838e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(8.9228e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(8.7440e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(8.6248e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(8.4937e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(8.2910e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(8.1718e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(8.0764e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(7.9215e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(7.7903e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(7.7069e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(7.5281e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(7.4446e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(7.3373e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(7.2181e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(7.1228e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(7.0274e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(6.9559e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(6.8247e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(6.7175e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(6.6459e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(6.5446e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(6.4492e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(6.3658e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(6.2823e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(6.2227e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(6.1154e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(6.0558e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "802400\n",
      "[INFO] Exp. name : cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-3_sd0                                   \n",
      "[INFO] Loading data... large dataset may took a while.                                                     \n",
      "Load data for training/validation, store tokenizer and input/output shape\n",
      "Prepare dataloader for training/validation\n",
      "Interface for creating all kinds of dataset\n",
      "import VAGDataset as Dataset\n",
      "[VAGDataset] path: /home/jupyter-jason5/data_process, split: ['CTT4val-3']\n",
      "Mozillacv11Dataset CTT4val-3 found wav data: 5\n",
      "text len: 5\n",
      "remove None, then wav data: 5, text len: 5\n",
      "[VAGDataset] path: /home/jupyter-jason5/data_process, split: ['CTT4-1', 'CTT4-2', 'CTT4-4', 'CTT4val-1', 'CTT4val-2', 'CTT4val-4']\n",
      "Mozillacv11Dataset CTT4-1 found wav data: 21\n",
      "Mozillacv11Dataset CTT4-2 found wav data: 20\n",
      "Mozillacv11Dataset CTT4-4 found wav data: 19\n",
      "Mozillacv11Dataset CTT4val-1 found wav data: 5\n",
      "Mozillacv11Dataset CTT4val-2 found wav data: 5\n",
      "Mozillacv11Dataset CTT4val-4 found wav data: 5\n",
      "text len: 75\n",
      "remove None, then wav data: 75, text len: 75\n",
      "[INFO] Data spec. | Corpus = vag (from /home/jupyter-jason5/data_process)                                  \n",
      "[INFO]            | Train sets = ['CTT4-1', 'CTT4-2', 'CTT4-4', 'CTT4val-1', 'CTT4val-2', 'CTT4val-4']\t| Number of utts = 75\n",
      "[INFO]            | Dev sets = ['CTT4val-3']\t| Number of utts = 5                                          \n",
      "[INFO]            | Batch size = 1\t\t| Bucketing = True                                                     \n",
      "[INFO] I/O spec.  | Audio feature = fbank\t| feature dim = 120                                              \n",
      "Setup ASR model and optimizer \n",
      "[INFO] Model spec.| Encoder's downsampling rate of time axis is 4.                                         \n",
      "[INFO]            | VCC Extractor w/ time downsampling rate = 4 in encoder enabled.                        \n",
      "# Losses\n",
      "# Note: zero_infinity=False is unstable?\n",
      "# Optimizer\n",
      "[INFO] Optim.spec.| Algo. = Adadelta\t| Lr = 1.0\t (Scheduler = fixed)| Scheduled sampling = False           \n",
      "# Enable AMP if needed\n",
      "[INFO] Load ckpt from ./ckpt/cv11Lu_asr_lstm4atthead_allvocab_sd0/best_att-VAG01.pth, restarting at step 795000 (recorded wer = 0.11 %)\n",
      "encoder.layers.0.extractor.0.weight\n",
      "encoder.layers.0.extractor.0.bias\n",
      "encoder.layers.0.extractor.2.weight\n",
      "encoder.layers.0.extractor.2.bias\n",
      "encoder.layers.0.extractor.5.weight\n",
      "encoder.layers.0.extractor.5.bias\n",
      "encoder.layers.0.extractor.7.weight\n",
      "encoder.layers.0.extractor.7.bias\n",
      "encoder.layers.1.layer.weight_ih_l0\n",
      "encoder.layers.1.layer.weight_hh_l0\n",
      "encoder.layers.1.layer.bias_ih_l0\n",
      "encoder.layers.1.layer.bias_hh_l0\n",
      "encoder.layers.1.layer.weight_ih_l0_reverse\n",
      "encoder.layers.1.layer.weight_hh_l0_reverse\n",
      "encoder.layers.1.layer.bias_ih_l0_reverse\n",
      "encoder.layers.1.layer.bias_hh_l0_reverse\n",
      "encoder.layers.1.pj.weight\n",
      "encoder.layers.1.pj.bias\n",
      "encoder.layers.2.layer.weight_ih_l0\n",
      "encoder.layers.2.layer.weight_hh_l0\n",
      "encoder.layers.2.layer.bias_ih_l0\n",
      "encoder.layers.2.layer.bias_hh_l0\n",
      "encoder.layers.2.layer.weight_ih_l0_reverse\n",
      "encoder.layers.2.layer.weight_hh_l0_reverse\n",
      "encoder.layers.2.layer.bias_ih_l0_reverse\n",
      "encoder.layers.2.layer.bias_hh_l0_reverse\n",
      "encoder.layers.2.pj.weight\n",
      "encoder.layers.2.pj.bias\n",
      "encoder.layers.3.layer.weight_ih_l0\n",
      "encoder.layers.3.layer.weight_hh_l0\n",
      "encoder.layers.3.layer.bias_ih_l0\n",
      "encoder.layers.3.layer.bias_hh_l0\n",
      "encoder.layers.3.layer.weight_ih_l0_reverse\n",
      "encoder.layers.3.layer.weight_hh_l0_reverse\n",
      "encoder.layers.3.layer.bias_ih_l0_reverse\n",
      "encoder.layers.3.layer.bias_hh_l0_reverse\n",
      "encoder.layers.3.pj.weight\n",
      "encoder.layers.3.pj.bias\n",
      "encoder.layers.4.layer.weight_ih_l0\n",
      "encoder.layers.4.layer.weight_hh_l0\n",
      "encoder.layers.4.layer.bias_ih_l0\n",
      "encoder.layers.4.layer.bias_hh_l0\n",
      "encoder.layers.4.layer.weight_ih_l0_reverse\n",
      "encoder.layers.4.layer.weight_hh_l0_reverse\n",
      "encoder.layers.4.layer.bias_ih_l0_reverse\n",
      "encoder.layers.4.layer.bias_hh_l0_reverse\n",
      "encoder.layers.4.pj.weight\n",
      "encoder.layers.4.pj.bias\n",
      "fc.weight\n",
      "fc.bias\n",
      "Training End-to-end ASR system\n",
      "[INFO] Total training steps 1.0M.                                                                          \n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 795.0K, loss = 0.64) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-3_sd0/best_biclass.pth\n",
      "43\n",
      "bestloss3.413907527923584\n",
      "tensor(61.1500, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 795.1K, loss = 0.52) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-3_sd0/best_biclass.pth\n",
      "116\n",
      "bestloss3.3664541244506836\n",
      "tensor(61.1318, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(51.5649, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 795.3K, loss = 0.52) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-3_sd0/best_biclass.pth\n",
      "262\n",
      "bestloss3.346099376678467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(55.8360, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 795.3K, loss = 0.56) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-3_sd0/best_biclass.pth\n",
      "335\n",
      "bestloss3.282402992248535\n",
      "tensor(55.4550, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(61.8993, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(56.5196, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 795.6K, loss = 0.75) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-3_sd0/best_biclass.pth\n",
      "554\n",
      "bestloss2.72458553314209\n",
      "tensor(61.0709, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(56.7233, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(34.8273, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(8.2830, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(6.9796, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(2.0336, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.0013, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.0010, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.0008, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.0006, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.0005, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.0005, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.0004, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.0004, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.0003, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.0003, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.0003, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.0003, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.0003, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(9.9838e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(9.7394e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(9.5367e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(9.2924e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(9.0599e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(8.8990e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(8.7023e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(8.5235e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(8.3447e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(8.1718e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(8.0287e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(7.8619e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(7.7069e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(7.5400e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(7.4506e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(7.3135e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(7.2062e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(7.0512e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(6.8963e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(6.7830e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(6.6996e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(6.5982e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(6.5148e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(6.4075e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(6.2883e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(6.1810e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(6.0558e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(6.0022e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(5.8770e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(5.8115e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(5.7280e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(5.6863e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(5.5552e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(5.4836e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(5.4479e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(5.3704e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(5.3167e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(5.2333e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(5.1320e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(5.0664e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(5.0068e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(4.9770e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(4.9114e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(4.8280e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(4.7863e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(4.7266e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(4.6790e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "802500\n",
      "[INFO] Exp. name : cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-4_sd0                                   \n",
      "[INFO] Loading data... large dataset may took a while.                                                     \n",
      "Load data for training/validation, store tokenizer and input/output shape\n",
      "Prepare dataloader for training/validation\n",
      "Interface for creating all kinds of dataset\n",
      "import VAGDataset as Dataset\n",
      "[VAGDataset] path: /home/jupyter-jason5/data_process, split: ['CTT4val-4']\n",
      "Mozillacv11Dataset CTT4val-4 found wav data: 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text len: 5\n",
      "remove None, then wav data: 5, text len: 5\n",
      "[VAGDataset] path: /home/jupyter-jason5/data_process, split: ['CTT4-1', 'CTT4-2', 'CTT4-3', 'CTT4val-1', 'CTT4val-2', 'CTT4val-3']\n",
      "Mozillacv11Dataset CTT4-1 found wav data: 21\n",
      "Mozillacv11Dataset CTT4-2 found wav data: 20\n",
      "Mozillacv11Dataset CTT4-3 found wav data: 19\n",
      "Mozillacv11Dataset CTT4val-1 found wav data: 5\n",
      "Mozillacv11Dataset CTT4val-2 found wav data: 5\n",
      "Mozillacv11Dataset CTT4val-3 found wav data: 5\n",
      "text len: 75\n",
      "remove None, then wav data: 75, text len: 75\n",
      "[INFO] Data spec. | Corpus = vag (from /home/jupyter-jason5/data_process)                                  \n",
      "[INFO]            | Train sets = ['CTT4-1', 'CTT4-2', 'CTT4-3', 'CTT4val-1', 'CTT4val-2', 'CTT4val-3']\t| Number of utts = 75\n",
      "[INFO]            | Dev sets = ['CTT4val-4']\t| Number of utts = 5                                          \n",
      "[INFO]            | Batch size = 1\t\t| Bucketing = True                                                     \n",
      "[INFO] I/O spec.  | Audio feature = fbank\t| feature dim = 120                                              \n",
      "Setup ASR model and optimizer \n",
      "[INFO] Model spec.| Encoder's downsampling rate of time axis is 4.                                         \n",
      "[INFO]            | VCC Extractor w/ time downsampling rate = 4 in encoder enabled.                        \n",
      "# Losses\n",
      "# Note: zero_infinity=False is unstable?\n",
      "# Optimizer\n",
      "[INFO] Optim.spec.| Algo. = Adadelta\t| Lr = 1.0\t (Scheduler = fixed)| Scheduled sampling = False           \n",
      "# Enable AMP if needed\n",
      "[INFO] Load ckpt from ./ckpt/cv11Lu_asr_lstm4atthead_allvocab_sd0/best_att-VAG01.pth, restarting at step 795000 (recorded wer = 0.11 %)\n",
      "encoder.layers.0.extractor.0.weight\n",
      "encoder.layers.0.extractor.0.bias\n",
      "encoder.layers.0.extractor.2.weight\n",
      "encoder.layers.0.extractor.2.bias\n",
      "encoder.layers.0.extractor.5.weight\n",
      "encoder.layers.0.extractor.5.bias\n",
      "encoder.layers.0.extractor.7.weight\n",
      "encoder.layers.0.extractor.7.bias\n",
      "encoder.layers.1.layer.weight_ih_l0\n",
      "encoder.layers.1.layer.weight_hh_l0\n",
      "encoder.layers.1.layer.bias_ih_l0\n",
      "encoder.layers.1.layer.bias_hh_l0\n",
      "encoder.layers.1.layer.weight_ih_l0_reverse\n",
      "encoder.layers.1.layer.weight_hh_l0_reverse\n",
      "encoder.layers.1.layer.bias_ih_l0_reverse\n",
      "encoder.layers.1.layer.bias_hh_l0_reverse\n",
      "encoder.layers.1.pj.weight\n",
      "encoder.layers.1.pj.bias\n",
      "encoder.layers.2.layer.weight_ih_l0\n",
      "encoder.layers.2.layer.weight_hh_l0\n",
      "encoder.layers.2.layer.bias_ih_l0\n",
      "encoder.layers.2.layer.bias_hh_l0\n",
      "encoder.layers.2.layer.weight_ih_l0_reverse\n",
      "encoder.layers.2.layer.weight_hh_l0_reverse\n",
      "encoder.layers.2.layer.bias_ih_l0_reverse\n",
      "encoder.layers.2.layer.bias_hh_l0_reverse\n",
      "encoder.layers.2.pj.weight\n",
      "encoder.layers.2.pj.bias\n",
      "encoder.layers.3.layer.weight_ih_l0\n",
      "encoder.layers.3.layer.weight_hh_l0\n",
      "encoder.layers.3.layer.bias_ih_l0\n",
      "encoder.layers.3.layer.bias_hh_l0\n",
      "encoder.layers.3.layer.weight_ih_l0_reverse\n",
      "encoder.layers.3.layer.weight_hh_l0_reverse\n",
      "encoder.layers.3.layer.bias_ih_l0_reverse\n",
      "encoder.layers.3.layer.bias_hh_l0_reverse\n",
      "encoder.layers.3.pj.weight\n",
      "encoder.layers.3.pj.bias\n",
      "encoder.layers.4.layer.weight_ih_l0\n",
      "encoder.layers.4.layer.weight_hh_l0\n",
      "encoder.layers.4.layer.bias_ih_l0\n",
      "encoder.layers.4.layer.bias_hh_l0\n",
      "encoder.layers.4.layer.weight_ih_l0_reverse\n",
      "encoder.layers.4.layer.weight_hh_l0_reverse\n",
      "encoder.layers.4.layer.bias_ih_l0_reverse\n",
      "encoder.layers.4.layer.bias_hh_l0_reverse\n",
      "encoder.layers.4.pj.weight\n",
      "encoder.layers.4.pj.bias\n",
      "fc.weight\n",
      "fc.bias\n",
      "Training End-to-end ASR system\n",
      "[INFO] Total training steps 1.0M.                                                                          \n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 795.0K, loss = 0.72) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-4_sd0/best_biclass.pth\n",
      "43\n",
      "bestloss3.434328317642212\n",
      "tensor(62.9094, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(52.5378, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(53.2736, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 795.3K, loss = 0.78) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-4_sd0/best_biclass.pth\n",
      "262\n",
      "bestloss3.3730597496032715\n",
      "tensor(52.7459, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(55.9969, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 795.4K, loss = 0.49) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-4_sd0/best_biclass.pth\n",
      "408\n",
      "bestloss2.819056272506714\n",
      "tensor(59.0376, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(62.0426, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(60.7447, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(62.1214, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 795.7K, loss = 0.48) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-4_sd0/best_biclass.pth\n",
      "700\n",
      "bestloss2.6691980361938477\n",
      "tensor(61.6120, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(51.4283, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 795.8K, loss = 0.00) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-4_sd0/best_biclass.pth\n",
      "846\n",
      "bestloss0.04051855951547623\n",
      "tensor(18.4518, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 795.9K, loss = 0.00) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-4_sd0/best_biclass.pth\n",
      "919\n",
      "bestloss0.013297113589942455\n",
      "tensor(4.3820, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(4.6940, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.0009, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.0006, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.0005, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.0004, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.0004, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.0003, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.0003, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.0003, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.0003, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(9.6977e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(9.4831e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(9.1911e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8.9646e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(8.7381e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(8.5533e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(8.3149e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(8.1599e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(7.9572e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(7.8023e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(7.6115e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(7.4506e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(7.2301e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(7.1049e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(7.0155e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 799.6K, loss = 0.00) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-4_sd0/best_biclass.pth\n",
      "4569\n",
      "bestloss0.013170023448765278\n",
      "tensor(6.8665e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 799.6K, loss = 0.00) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-4_sd0/best_biclass.pth\n",
      "4642\n",
      "bestloss0.012907974421977997\n",
      "tensor(6.6876e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 799.7K, loss = 0.00) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-4_sd0/best_biclass.pth\n",
      "4715\n",
      "bestloss0.012857511639595032\n",
      "tensor(6.5684e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(6.4433e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 799.9K, loss = 0.00) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-4_sd0/best_biclass.pth\n",
      "4861\n",
      "bestloss0.012261769734323025\n",
      "tensor(6.3658e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(6.2525e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 800.0K, loss = 0.00) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-4_sd0/best_biclass.pth\n",
      "5007\n",
      "bestloss0.011833307333290577\n",
      "tensor(6.1572e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(6.0499e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 800.2K, loss = 0.00) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-4_sd0/best_biclass.pth\n",
      "5153\n",
      "bestloss0.011371088214218616\n",
      "tensor(5.9307e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(5.8234e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 800.3K, loss = 0.00) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-4_sd0/best_biclass.pth\n",
      "5299\n",
      "bestloss0.011253329925239086\n",
      "tensor(5.6922e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(5.6386e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 800.4K, loss = 0.00) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-4_sd0/best_biclass.pth\n",
      "5445\n",
      "bestloss0.010978701524436474\n",
      "tensor(5.5492e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(5.4538e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(5.3823e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 800.7K, loss = 0.00) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-4_sd0/best_biclass.pth\n",
      "5664\n",
      "bestloss0.010783451609313488\n",
      "tensor(5.3287e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 800.7K, loss = 0.00) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-4_sd0/best_biclass.pth\n",
      "5737\n",
      "bestloss0.010402213782072067\n",
      "tensor(5.1975e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(5.0962e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 800.9K, loss = 0.00) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-4_sd0/best_biclass.pth\n",
      "5883\n",
      "bestloss0.010350142605602741\n",
      "tensor(5.0247e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 801.0K, loss = 0.00) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-4_sd0/best_biclass.pth\n",
      "5956\n",
      "bestloss0.01005383487790823\n",
      "tensor(4.9651e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(4.9114e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 801.1K, loss = 0.00) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-4_sd0/best_biclass.pth\n",
      "6102\n",
      "bestloss0.009819980710744858\n",
      "tensor(4.8816e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(4.7803e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 801.2K, loss = 0.00) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-4_sd0/best_biclass.pth\n",
      "6248\n",
      "bestloss0.009623314253985882\n",
      "tensor(4.7326e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(4.6730e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 801.4K, loss = 0.00) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-4_sd0/best_biclass.pth\n",
      "6394\n",
      "bestloss0.009337696246802807\n",
      "tensor(4.6253e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 801.5K, loss = 0.00) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-4_sd0/best_biclass.pth\n",
      "6467\n",
      "bestloss0.009329401887953281\n",
      "tensor(4.5359e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 801.5K, loss = 0.00) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-4_sd0/best_biclass.pth\n",
      "6540\n",
      "bestloss0.009163491427898407\n",
      "tensor(4.4704e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 801.6K, loss = 0.00) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-4_sd0/best_biclass.pth\n",
      "6613\n",
      "bestloss0.009160611778497696\n",
      "tensor(4.4048e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 801.7K, loss = 0.00) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-4_sd0/best_biclass.pth\n",
      "6686\n",
      "bestloss0.008908431977033615\n",
      "tensor(4.3452e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(4.2975e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(4.2558e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(4.1842e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(4.1246e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 802.1K, loss = 0.00) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-4_sd0/best_biclass.pth\n",
      "7051\n",
      "bestloss0.008752301335334778\n",
      "[INFO] Saved checkpoint (step = 802.1K, loss = 0.00) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-4_sd0/best_biclass.pth\n",
      "7124\n",
      "bestloss0.00870570819824934\n",
      "tensor(4.0650e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 802.2K, loss = 0.00) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-4_sd0/best_biclass.pth\n",
      "7197\n",
      "bestloss0.008633987046778202\n",
      "tensor(4.0412e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 802.3K, loss = 0.00) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-4_sd0/best_biclass.pth\n",
      "7270\n",
      "bestloss0.008535641245543957\n",
      "tensor(3.9935e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 802.3K, loss = 0.00) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-4_sd0/best_biclass.pth\n",
      "7343\n",
      "bestloss0.008484307676553726\n",
      "tensor(3.9756e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 802.4K, loss = 0.00) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-4_sd0/best_biclass.pth\n",
      "7416\n",
      "bestloss0.008388020098209381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.9458e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 802.5K, loss = 0.00) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-4_sd0/best_biclass.pth\n",
      "7489\n",
      "bestloss0.00829895306378603\n",
      "tensor(3.9220e-05, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "802500\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animal-friendly",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('asd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "homeless-rolling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "============  Result of /home/jupyter-jason3/LAS_Mandarin_PyTorch-master/result/mozillacv11_asr_stm4atthead-test_test_output.csv ============\r\n",
      " -----------------------------------------------------------------------\r\n",
      "| Statics\t\t|  Truth\t|  Prediction\t| Abs. Diff.\t|\r\n",
      " -----------------------------------------------------------------------\r\n",
      "| Avg. # of chars\t|  8.01\t|  8.10\t|  0.16\t\t|\r\n",
      "| Avg. # of words\t|  1.00\t|  1.00\t|  0.00\t\t|\r\n",
      " -----------------------------------------------------------------------\r\n",
      " ---------------------------------------------------------------\r\n",
      "| Error Rate (%)| Mean\t\t| Std.\t\t| Min./Max.\t|\r\n",
      " ---------------------------------------------------------------\r\n",
      "| Character\t| 7.9479\t| 21.68\t\t| 0.00/240.00\t|\r\n",
      "| Word\t\t| 18.1725\t| 38.56\t\t| 0.00/100.00\t|\r\n",
      " ---------------------------------------------------------------\r\n",
      "Note : If the text unit is phoneme, WER = PER and CER is meaningless.\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!python eval.py --file ~/LAS_Mandarin_PyTorch-master/result/mozillacv11_asr_stm4atthead-test_test_output.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sapphire-riverside",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
