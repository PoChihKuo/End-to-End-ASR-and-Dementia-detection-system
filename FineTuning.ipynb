{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "electoral-wonder",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from functools import partial\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from core.solver import BaseSolver\n",
    "from core.optim import Optimizer\n",
    "from core.asr import ASR\n",
    "from core.decode import BeamDecoder\n",
    "from core.data import load_dataset\n",
    "from core.util import human_format, cal_er, feat_to_fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adverse-brave",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Solver(BaseSolver):\n",
    "    ''' Solver for training'''\n",
    "\n",
    "    def __init__(self, config, paras, mode):\n",
    "        super().__init__(config, paras, mode)\n",
    "        # Logger settings\n",
    "        self.best_wer = {'att': 3.0, 'ctc': 3.0}\n",
    "        # Curriculum learning affects data loader\n",
    "        self.curriculum = self.config['hparas']['curriculum']\n",
    "        \n",
    "#     def load_ckpt(self):\n",
    "#         \"\"\"\n",
    "#          Load ckpt if --load option is specified\n",
    "#         :return:\n",
    "#         \"\"\"\n",
    "#         if self.paras.load:\n",
    "#             # Load weights\n",
    "#             ckpt = torch.load(self.paras.load, map_location=self.device if self.mode == 'train' else 'cpu')\n",
    "\n",
    "           \n",
    "                \n",
    "#             self.model.load_state_dict(ckpt['model'])\n",
    "\n",
    "#             if self.emb_decoder is not None:\n",
    "#                 self.emb_decoder.load_state_dict(ckpt['emb_decoder'])\n",
    "#             # if self.amp:\n",
    "#             #    amp.load_state_dict(ckpt['amp'])\n",
    "#             # Load task-dependent items\n",
    "#             for k, v in ckpt.items():\n",
    "#                 if type(v) is float:\n",
    "#                     metric, score = k, v\n",
    "#             if self.mode == 'train':\n",
    "#                 self.step = ckpt['global_step']\n",
    "#                 self.optimizer.load_opt_state_dict(ckpt['optimizer'])\n",
    "#                 self.verbose('Load ckpt from {}, restarting at step {} (recorded {} = {:.2f} %)'.format(\n",
    "#                     self.paras.load, self.step, metric, score))\n",
    "#             else:\n",
    "#                 self.model.eval()\n",
    "#                 if self.emb_decoder is not None:\n",
    "#                     self.emb_decoder.eval()\n",
    "#                 self.verbose('Evaluation target = {} (recorded {} = {:.2f} %)'.format(\n",
    "#                     self.paras.load, metric, score))\n",
    "\n",
    "    def fetch_data(self, data):\n",
    "        ''' Move data to device and compute text seq. length'''\n",
    "        _, feat, feat_len, txt = data\n",
    "        feat = feat.to(self.device)\n",
    "        feat_len = feat_len.to(self.device)\n",
    "        txt = txt.to(self.device)\n",
    "        txt_len = torch.sum(txt != 0, dim=-1)\n",
    "\n",
    "        return feat, feat_len, txt, txt_len\n",
    "\n",
    "    def load_data(self):\n",
    "        print(\"Load data for training/validation, store tokenizer and input/output shape\")\n",
    "        self.tr_set, self.dv_set, self.feat_dim, self.vocab_size, self.tokenizer, msg = \\\n",
    "            load_dataset(self.paras.njobs, self.paras.gpu, self.paras.pin_memory,\n",
    "                         self.curriculum > 0, **self.config['data'])\n",
    "        self.verbose(msg)\n",
    "\n",
    "    def set_model(self):\n",
    "        print(\"Setup ASR model and optimizer \")\n",
    "        nonfreeze_keys = ['decoder.layers.weight_ih_l1','decoder.layers.weight_hh_l1', 'decoder.layers.bias_ih_l1', 'decoder.layers.bias_hh_l1']\n",
    "        # Model\n",
    "        self.model = ASR(self.feat_dim, self.vocab_size, **\n",
    "        self.config['model']).to(self.device)\n",
    "        self.verbose(self.model.create_msg())\n",
    "        model_paras = [{'params': self.model.parameters()}]\n",
    "\n",
    "        print(\"# Losses\")\n",
    "        self.seq_loss = torch.nn.CrossEntropyLoss(ignore_index=0)\n",
    "        print(\"# Note: zero_infinity=False is unstable?\")\n",
    "        self.ctc_loss = torch.nn.CTCLoss(blank=0, zero_infinity=False)\n",
    "\n",
    "        print(\"Plug-ins\")\n",
    "        self.emb_fuse = False\n",
    "        self.emb_reg = ('emb' in self.config) and (\n",
    "            self.config['emb']['enable'])\n",
    "        if self.emb_reg:\n",
    "            from core.plugin import EmbeddingRegularizer\n",
    "            self.emb_decoder = EmbeddingRegularizer(\n",
    "                self.tokenizer, self.model.dec_dim, **self.config['emb']).to(self.device)\n",
    "            model_paras.append({'params': self.emb_decoder.parameters()})\n",
    "            self.emb_fuse = self.emb_decoder.apply_fuse\n",
    "            if self.emb_fuse:\n",
    "                self.seq_loss = torch.nn.NLLLoss(ignore_index=0)\n",
    "            self.verbose(self.emb_decoder.create_msg())\n",
    "\n",
    "        print(\"# Optimizer\")\n",
    "        self.optimizer = Optimizer(model_paras, **self.config['hparas'])\n",
    "        self.verbose(self.optimizer.create_msg())\n",
    "\n",
    "        print(\"# Enable AMP if needed\")\n",
    "        self.enable_apex()\n",
    "\n",
    "        # Automatically load pre-trained model if self.paras.load is given\n",
    "        self.load_ckpt()\n",
    "        for name, para in self.model.named_parameters():\n",
    "            if para.requires_grad and name not in nonfreeze_keys:\n",
    "                para.requires_grad = False\n",
    "        for name, para in self.model.named_parameters():\n",
    "            if para.requires_grad:print(name)\n",
    "        non_frozen_parameters = [p for p in self.model.parameters() if p.requires_grad]\n",
    "        self.optimizer = Optimizer(non_frozen_parameters, **self.config['hparas'])\n",
    "\n",
    "        # ToDo: other training methods\n",
    "\n",
    "    def exec(self):\n",
    "        print(\"Training End-to-end ASR system\")\n",
    "        self.verbose('Total training steps {}.'.format(\n",
    "            human_format(self.max_step)))\n",
    "        ctc_loss, att_loss, emb_loss = None, None, None\n",
    "        n_epochs = 0\n",
    "        self.timer.set()\n",
    "\n",
    "        while self.step < self.max_step:\n",
    "            # Renew dataloader to enable random sampling\n",
    "            if self.curriculum > 0 and n_epochs == self.curriculum:\n",
    "                self.verbose(\n",
    "                    'Curriculum learning ends after {} epochs, starting random sampling.'.format(n_epochs))\n",
    "                self.tr_set, _, _, _, _, _ = \\\n",
    "                    load_dataset(self.paras.njobs, self.paras.gpu, self.paras.pin_memory,\n",
    "                                 False, **self.config['data'])\n",
    "            print(\"self.tr_set: {}\".format(len(self.tr_set)))\n",
    "            for data in self.tr_set:\n",
    "                # print(\"Pre-step : update tf_rate/lr_rate and do zero_grad\")\n",
    "                tf_rate = self.optimizer.pre_step(self.step)\n",
    "                total_loss = 0\n",
    "\n",
    "                # Fetch data\n",
    "                feat, feat_len, txt, txt_len = self.fetch_data(data)\n",
    "                self.timer.cnt('rd')\n",
    "\n",
    "                # Forward model\n",
    "                # Note: txt should NOT start w/ <sos>\n",
    "                ctc_output, encode_len, att_output, att_align, dec_state = \\\n",
    "                    self.model(feat, feat_len, max(txt_len), tf_rate=tf_rate,\n",
    "                               teacher=txt, get_dec_state=self.emb_reg)\n",
    "\n",
    "                # Plugins\n",
    "                if self.emb_reg:\n",
    "                    emb_loss, fuse_output = self.emb_decoder(\n",
    "                        dec_state, att_output, label=txt)\n",
    "                    total_loss += self.emb_decoder.weight * emb_loss\n",
    "\n",
    "                # Compute all objectives\n",
    "                if ctc_output is not None:\n",
    "                    if self.paras.cudnn_ctc:\n",
    "                        ctc_loss = self.ctc_loss(ctc_output.transpose(0, 1),\n",
    "                                                 txt.to_sparse().values().to(device='cpu', dtype=torch.int32),\n",
    "                                                 [ctc_output.shape[1]] *\n",
    "                                                 len(ctc_output),\n",
    "                                                 txt_len.cpu().tolist())\n",
    "                    else:\n",
    "                        ctc_loss = self.ctc_loss(ctc_output.transpose(\n",
    "                            0, 1), txt, encode_len, txt_len)\n",
    "                    total_loss += ctc_loss * self.model.ctc_weight\n",
    "\n",
    "                if att_output is not None:\n",
    "                    b, t, _ = att_output.shape\n",
    "                    att_output = fuse_output if self.emb_fuse else att_output\n",
    "                    att_loss = self.seq_loss(\n",
    "                        att_output.view(b * t, -1), txt.view(-1))\n",
    "                    total_loss += att_loss * (1 - self.model.ctc_weight)\n",
    "\n",
    "                self.timer.cnt('fw')\n",
    "\n",
    "                # Backprop\n",
    "                grad_norm = self.backward(total_loss)\n",
    "                self.step += 1\n",
    "\n",
    "                # Logger\n",
    "                if (self.step == 1) or (self.step % self.PROGRESS_STEP == 0):\n",
    "                    self.progress('Tr stat | Loss - {:.2f} | Grad. Norm - {:.2f} | {}'\n",
    "                                  .format(total_loss.cpu().item(), grad_norm, self.timer.show()))\n",
    "                    self.write_log(\n",
    "                        'loss', {'tr_ctc': ctc_loss, 'tr_att': att_loss})\n",
    "                    self.write_log('emb_loss', {'tr': emb_loss})\n",
    "                    self.write_log('wer', {'tr_att': cal_er(self.tokenizer, att_output, txt),\n",
    "                                           'tr_ctc': cal_er(self.tokenizer, ctc_output, txt, ctc=True)})\n",
    "                    if self.emb_fuse:\n",
    "                        if self.emb_decoder.fuse_learnable:\n",
    "                            self.write_log('fuse_lambda', {\n",
    "                                'emb': self.emb_decoder.get_weight()})\n",
    "                        self.write_log(\n",
    "                            'fuse_temp', {'temp': self.emb_decoder.get_temp()})\n",
    "\n",
    "                # Validation\n",
    "                if (self.step == 1) or (self.step % self.valid_step == 0):\n",
    "                    self.validate()\n",
    "\n",
    "                # End of step\n",
    "                # https://github.com/pytorch/pytorch/issues/13246#issuecomment-529185354\n",
    "                torch.cuda.empty_cache()\n",
    "                self.timer.set()\n",
    "                if self.step > self.max_step:\n",
    "                    break\n",
    "            n_epochs += 1\n",
    "        self.log.close()\n",
    "\n",
    "    def validate(self):\n",
    "        # Eval mode\n",
    "        self.model.eval()\n",
    "        if self.emb_decoder is not None:\n",
    "            self.emb_decoder.eval()\n",
    "        dev_wer = {'att': [], 'ctc': []}\n",
    "\n",
    "        for i, data in enumerate(self.dv_set):\n",
    "            self.progress('Valid step - {}/{}'.format(i + 1, len(self.dv_set)))\n",
    "            # Fetch data\n",
    "            feat, feat_len, txt, txt_len = self.fetch_data(data)\n",
    "\n",
    "            # Forward model\n",
    "            with torch.no_grad():\n",
    "                ctc_output, encode_len, att_output, att_align, dec_state = \\\n",
    "                    self.model(feat, feat_len, int(max(txt_len) * self.DEV_STEP_RATIO),\n",
    "                               emb_decoder=self.emb_decoder)\n",
    "\n",
    "            dev_wer['att'].append(cal_er(self.tokenizer, att_output, txt))\n",
    "            dev_wer['ctc'].append(\n",
    "                cal_er(self.tokenizer, ctc_output, txt, ctc=True))\n",
    "\n",
    "            # Show some example on tensorboard\n",
    "            if i == len(self.dv_set) // 2:\n",
    "                for i in range(min(len(txt), self.DEV_N_EXAMPLE)):\n",
    "                    if self.step == 1:\n",
    "                        self.write_log('true_text{}'.format(\n",
    "                            i), self.tokenizer.decode(txt[i].tolist()))\n",
    "                    if att_output is not None:\n",
    "                        self.write_log('att_align{}'.format(i), feat_to_fig(\n",
    "                            att_align[i, 0, :, :].cpu().detach()))\n",
    "                        self.write_log('att_text{}'.format(i), self.tokenizer.decode(\n",
    "                            att_output[i].argmax(dim=-1).tolist()))\n",
    "                    if ctc_output is not None:\n",
    "                        self.write_log('ctc_text{}'.format(i), self.tokenizer.decode(ctc_output[i].argmax(dim=-1).tolist(),\n",
    "                                                                                     ignore_repeat=True))\n",
    "\n",
    "        # Ckpt if performance improves\n",
    "        self.save_checkpoint('latest.pth', 'wer',\n",
    "                             dev_wer['att'], show_msg=False)\n",
    "        for task in ['att', 'ctc']:\n",
    "            dev_wer[task] = sum(dev_wer[task]) / len(dev_wer[task])\n",
    "            if dev_wer[task] < self.best_wer[task]:\n",
    "                self.best_wer[task] = dev_wer[task]\n",
    "                self.save_checkpoint('best_{}.pth'.format(\n",
    "                    task), 'wer', dev_wer[task])\n",
    "            self.write_log('wer', {'dv_' + task: dev_wer[task]})\n",
    "\n",
    "        # Resume training\n",
    "        self.model.train()\n",
    "        if self.emb_decoder is not None:\n",
    "            self.emb_decoder.train()\n",
    "\n",
    "                    \n",
    "    def print_model(self):\n",
    "        self.model = ASR(self.feat_dim, self.vocab_size,\n",
    "                         **self.config['model'])\n",
    "        nonfreeze_keys = ['decoder.layers.weight_ih_l1','decoder.layers.weight_hh_l1', 'decoder.layers.bias_ih_l1', 'decoder.layers.bias_hh_l1']\n",
    "\n",
    "        # Plug-ins\n",
    "        if ('emb' in self.config) and (self.config['emb']['enable']) \\\n",
    "                and (self.config['emb']['fuse'] > 0):\n",
    "            from core.plugin import EmbeddingRegularizer\n",
    "            self.emb_decoder = EmbeddingRegularizer(\n",
    "                self.tokenizer, self.model.dec_dim, **self.config['emb'])\n",
    "\n",
    "        ckpt = torch.load(self.paras.load, map_location=self.device if self.mode == 'train' else 'cpu')\n",
    "           \n",
    "                \n",
    "        self.model.load_state_dict(ckpt['model'])\n",
    "        print(self.model)\n",
    "        for name, para in self.model.named_parameters():\n",
    "            if para.requires_grad and name not in nonfreeze_keys:\n",
    "                para.requires_grad = False\n",
    "            print(\"-\"*20)\n",
    "            print(f\"name: {name}\")\n",
    "            print(\"values: \")\n",
    "            print(para)\n",
    "        for name, para in self.model.named_parameters():\n",
    "            if para.requires_grad:print(name)\n",
    "        # Beam decoder\n",
    "#         self.decoder = BeamDecoder(\n",
    "#             self.model.cpu(), self.emb_decoder, **self.config['decode'])\n",
    "#         self.verbose(self.decoder.create_msg())\n",
    "        del self.model\n",
    "#         del self.emb_decoder\n",
    "    def print_model_detail(self):\n",
    "        self.model = ASR(self.feat_dim, self.vocab_size,\n",
    "                         **self.config['model'])\n",
    "\n",
    "        # Plug-ins\n",
    "        if ('emb' in self.config) and (self.config['emb']['enable']) \\\n",
    "                and (self.config['emb']['fuse'] > 0):\n",
    "            from core.plugin import EmbeddingRegularizer\n",
    "            self.emb_decoder = EmbeddingRegularizer(\n",
    "                self.tokenizer, self.model.dec_dim, **self.config['emb'])\n",
    "\n",
    "        ckpt = torch.load(self.paras.load, map_location=self.device if self.mode == 'train' else 'cpu')\n",
    "           \n",
    "                \n",
    "        self.model.load_state_dict(ckpt['model'])\n",
    "        params = self.model.state_dict()\n",
    "        print(params.keys())\n",
    "\n",
    "        del self.model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "alternative-compact",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! python\n",
    "# -*- coding: utf-8 -*-\n",
    "# Author: kun\n",
    "# @Time: 2019-10-29 20:29\n",
    "\n",
    "import yaml\n",
    "import torch\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "class Para(object):\n",
    "    a=1\n",
    "\n",
    "def force_cudnn_initialization():\n",
    "    s = 32\n",
    "    dev = torch.device('cuda:0')\n",
    "    torch.nn.functional.conv2d(torch.zeros(s, s, s, s, device=dev), torch.zeros(s, s, s, s, device=dev))\n",
    "    \n",
    "#force_cudnn_initialization()\n",
    "def main():\n",
    "    # For reproducibility, comment these may speed up training\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    # Arguments\n",
    "#     parser = argparse.ArgumentParser(description='Training E2E asr.')\n",
    "#     parser.add_argument('--config', type=str, help='Path to experiment config.')\n",
    "#     parser.add_argument('--name', default=None, type=str, help='Name for logging.')\n",
    "#     parser.add_argument('--logdir', default='log/', type=str,\n",
    "#                         help='Logging path.', required=False)\n",
    "#     parser.add_argument('--ckpdir', default='ckpt/', type=str,\n",
    "#                         help='Checkpoint path.', required=False)\n",
    "#     parser.add_argument('--outdir', default='result/', type=str,\n",
    "#                         help='Decode output path.', required=False)\n",
    "#     parser.add_argument('--load', default=None, type=str,\n",
    "#                         help='Load pre-trained model (for training only)', required=False)\n",
    "#     parser.add_argument('--seed', default=0, type=int,\n",
    "#                         help='Random seed for reproducable results.', required=False)\n",
    "#     parser.add_argument('--cudnn-ctc', action='store_true',\n",
    "#                         help='Switches CTC backend from torch to cudnn')\n",
    "#     parser.add_argument('--njobs', default=32, type=int,\n",
    "#                         help='Number of threads for dataloader/decoding.', required=False)\n",
    "#     parser.add_argument('--cpu', action='store_true', help='Disable GPU training.')\n",
    "#     parser.add_argument('--no-pin', action='store_true',\n",
    "#                         help='Disable pin-memory for dataloader')\n",
    "#     parser.add_argument('--test', action='store_true', help='Test the model.')\n",
    "#     parser.add_argument('--no-msg', action='store_true', help='Hide all messages.')\n",
    "#     parser.add_argument('--lm', action='store_true',\n",
    "#                         help='Option for training RNNLM.')\n",
    "#     # Following features in development.\n",
    "#     parser.add_argument('--amp', action='store_true', help='Option to enable AMP.')\n",
    "#     parser.add_argument('--reserve-gpu', default=0, type=float,\n",
    "#                         help='Option to reserve GPU ram for training.')\n",
    "#     parser.add_argument('--jit', action='store_true',\n",
    "#                         help='Option for enabling jit in pytorch. (feature in development)')\n",
    "#     ###\n",
    "#     paras = parser.parse_args()\n",
    "    paras = Para()\n",
    "#     paras.config = './config/aishell_asr_example_lstm4atthead1-test.yaml'\n",
    "#     paras.name = None\n",
    "#     paras.logdir = 'log/'\n",
    "#     paras.ckpdir = 'ckpt/'\n",
    "#     paras.outdir = 'result/'\n",
    "#     paras.load = None\n",
    "#     paras.seed = 0\n",
    "#     paras.cudnn_ctc = False\n",
    "#     paras.cpu = False\n",
    "#     paras.no_pin = False\n",
    "#     paras.test = True\n",
    "#     paras.no_msg = False\n",
    "#     paras.lm = False\n",
    "#     paras.amp = False\n",
    "#     paras.reserve_gpu = 0\n",
    "#     paras.jit = False\n",
    "    setattr(paras, 'config', './config/cv11Lu_asr_lstm4atthead_allvocab-Finetune.yaml')\n",
    "    setattr(paras, 'name', None)\n",
    "    setattr(paras, 'logdir', 'log/')\n",
    "    setattr(paras, 'ckpdir', 'ckpt/')\n",
    "    setattr(paras, 'outdir', 'result/')\n",
    "    setattr(paras, 'load', None)\n",
    "    setattr(paras, 'seed', 0)\n",
    "    setattr(paras, 'cudnn_ctc', False)\n",
    "    setattr(paras, 'njobs',7)\n",
    "    setattr(paras, 'cpu', False)\n",
    "    setattr(paras, 'no_pin', False)\n",
    "    setattr(paras, 'test', True)\n",
    "    setattr(paras, 'no_msg', False)\n",
    "    setattr(paras, 'lm', False)\n",
    "    setattr(paras, 'amp', False)\n",
    "    setattr(paras, 'reserve_gpu', 0)\n",
    "    setattr(paras, 'jit', False)\n",
    "    setattr(paras, 'gpu', not paras.cpu)\n",
    "    setattr(paras, 'pin_memory', not paras.no_pin)\n",
    "    setattr(paras, 'verbose', not paras.no_msg)\n",
    "    force_cudnn_initialization()\n",
    "\n",
    "    config = yaml.load(open(paras.config, 'r'), Loader=yaml.FullLoader)\n",
    "\n",
    "    np.random.seed(paras.seed)\n",
    "    torch.manual_seed(paras.seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(paras.seed)\n",
    "\n",
    "    # Hack to preserve GPU ram just incase OOM later on server\n",
    "    if paras.gpu and paras.reserve_gpu > 0:\n",
    "        buff = torch.randn(int(paras.reserve_gpu * 1e9 // 4)).cuda()\n",
    "        del buff\n",
    "\n",
    "#     if paras.lm:\n",
    "#         # Train RNNLM\n",
    "#         from train_lm import Solver\n",
    "\n",
    "#         mode = 'train'\n",
    "#     else:\n",
    "#         if paras.test:\n",
    "#             # Test ASR\n",
    "#             assert paras.load is None, 'Load option is mutually exclusive to --test'\n",
    "#             from test_asr import Solver\n",
    "\n",
    "#             mode = 'test'\n",
    "#         else:\n",
    "#             # Train ASR\n",
    "#             from train_asr import Solver\n",
    "\n",
    "#             mode = 'train'\n",
    "    mode = 'test'\n",
    "\n",
    "    print(\"\\nUsing {} mode\\n\".format(mode))\n",
    "    solver = Solver(config, paras, mode)\n",
    "    solver.load_data()\n",
    "#     solver.set_model()\n",
    "    solver.print_model()\n",
    "    solver.print_model_detail()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "coordinated-watershed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using test mode\n",
      "\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'core'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-263240bbee7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-e5c8225e66e6>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nUsing {} mode\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m     \u001b[0msolver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSolver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m     \u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;31m#     solver.set_model()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-1b58af813b86>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config, paras, mode)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0;31m# Logger settings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_wer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'att'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m3.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ctc'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m3.0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/LAS_Mandarin_PyTorch-master/core/solver.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config, paras, mode)\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0;31m# Load training config to get acoustic feat, text encoder and build model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             self.src_config = yaml.load(\n\u001b[0;32m---> 75\u001b[0;31m                 open(config['core']['config'], 'r'), Loader=yaml.FullLoader)\n\u001b[0m\u001b[1;32m     76\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'core'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ckpt'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'core'"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "norwegian-shower",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'solver' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-0a092b6a6bb8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'solver' is not defined"
     ]
    }
   ],
   "source": [
    "params = solver.model.state_dict()\n",
    "params.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specified-fiction",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
