{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "lasting-metadata",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "derived-claim",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
    "# os.environ['CUDA_VISIBLE_DEVICES']='0,1'\n",
    "os.environ['CUDA_LAUNCH_BLOCKING']='1'\n",
    "import torch\n",
    "# torch.cuda.set_device(0)\n",
    "print(torch.cuda.current_device())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "tamil-table",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "heated-firewall",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "graphic-lemon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "korean-sodium",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cudaSetDevice(0)\n",
    "#dataset transcript要在dataset資好夾調\n",
    "#cuda 在basesolver init調\n",
    "#dataset要在data.py設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "federal-generator",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='1'\n",
    "# os.environ['CUDA_VISIBLE_DEVICES']='0,1'\n",
    "os.environ['CUDA_LAUNCH_BLOCKING']='1'\n",
    "import torch\n",
    "# torch.cuda.set_device(0)\n",
    "print(torch.cuda.current_device())\n",
    "#! python\n",
    "# -*- coding: utf-8 -*-\n",
    "# Author: kun\n",
    "# @Time: 2019-10-29 20:29\n",
    "\n",
    "import yaml\n",
    "import torch\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "class Para(object):\n",
    "    a=1\n",
    "\n",
    "def force_cudnn_initialization():\n",
    "    s = 32\n",
    "    dev = torch.device('cuda:0')\n",
    "    torch.nn.functional.conv2d(torch.zeros(s, s, s, s, device=dev), torch.zeros(s, s, s, s, device=dev))\n",
    "    \n",
    "#force_cudnn_initialization()\n",
    "def main():\n",
    "    # For reproducibility, comment these may speed up training\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    # Arguments\n",
    "#     parser = argparse.ArgumentParser(description='Training E2E asr.')\n",
    "#     parser.add_argument('--config', type=str, help='Path to experiment config.')\n",
    "#     parser.add_argument('--name', default=None, type=str, help='Name for logging.')\n",
    "#     parser.add_argument('--logdir', default='log/', type=str,\n",
    "#                         help='Logging path.', required=False)\n",
    "#     parser.add_argument('--ckpdir', default='ckpt/', type=str,\n",
    "#                         help='Checkpoint path.', required=False)\n",
    "#     parser.add_argument('--outdir', default='result/', type=str,\n",
    "#                         help='Decode output path.', required=False)\n",
    "#     parser.add_argument('--load', default=None, type=str,\n",
    "#                         help='Load pre-trained model (for training only)', required=False)\n",
    "#     parser.add_argument('--seed', default=0, type=int,\n",
    "#                         help='Random seed for reproducable results.', required=False)\n",
    "#     parser.add_argument('--cudnn-ctc', action='store_true',\n",
    "#                         help='Switches CTC backend from torch to cudnn')\n",
    "#     parser.add_argument('--njobs', default=32, type=int,\n",
    "#                         help='Number of threads for dataloader/decoding.', required=False)\n",
    "#     parser.add_argument('--cpu', action='store_true', help='Disable GPU training.')\n",
    "#     parser.add_argument('--no-pin', action='store_true',\n",
    "#                         help='Disable pin-memory for dataloader')\n",
    "#     parser.add_argument('--test', action='store_true', help='Test the model.')\n",
    "#     parser.add_argument('--no-msg', action='store_true', help='Hide all messages.')\n",
    "#     parser.add_argument('--lm', action='store_true',\n",
    "#                         help='Option for training RNNLM.')\n",
    "#     # Following features in development.\n",
    "#     parser.add_argument('--amp', action='store_true', help='Option to enable AMP.')\n",
    "#     parser.add_argument('--reserve-gpu', default=0, type=float,\n",
    "#                         help='Option to reserve GPU ram for training.')\n",
    "#     parser.add_argument('--jit', action='store_true',\n",
    "#                         help='Option for enabling jit in pytorch. (feature in development)')\n",
    "#     ###\n",
    "#     paras = parser.parse_args()\n",
    "    paras = Para()\n",
    "#     paras.config = './config/aishell_asr_example_lstm4atthead1-test.yaml'\n",
    "#     paras.name = None\n",
    "#     paras.logdir = 'log/'\n",
    "#     paras.ckpdir = 'ckpt/'\n",
    "#     paras.outdir = 'result/'\n",
    "#     paras.load = None\n",
    "#     paras.seed = 0\n",
    "#     paras.cudnn_ctc = False\n",
    "#     paras.cpu = False\n",
    "#     paras.no_pin = False\n",
    "#     paras.test = True\n",
    "#     paras.no_msg = False\n",
    "#     paras.lm = False\n",
    "#     paras.amp = False\n",
    "#     paras.reserve_gpu = 0\n",
    "#     paras.jit = False\n",
    "    setattr(paras, 'config', './config/cv11Lu_asr_lstm4atthead_allvocab-biclass2.yaml')\n",
    "    setattr(paras, 'name', None)\n",
    "    setattr(paras, 'logdir', 'log/')\n",
    "    setattr(paras, 'ckpdir', 'ckpt/')\n",
    "    setattr(paras, 'outdir', 'result/')\n",
    "    setattr(paras, 'load', './ckpt/cv11Lu_asr_lstm4atthead_allvocab_sd0/best_att-VAG01.pth')\n",
    "    setattr(paras, 'seed', 0)\n",
    "    setattr(paras, 'cudnn_ctc', False)\n",
    "    setattr(paras, 'njobs',8)\n",
    "    setattr(paras, 'cpu', False)\n",
    "    setattr(paras, 'no_pin', False)\n",
    "    setattr(paras, 'test', False)\n",
    "    setattr(paras, 'no_msg', False)\n",
    "    setattr(paras, 'lm', False)\n",
    "    setattr(paras, 'amp', False)\n",
    "    setattr(paras, 'reserve_gpu', 12)\n",
    "    setattr(paras, 'jit', False)\n",
    "    setattr(paras, 'gpu', not paras.cpu)\n",
    "    setattr(paras, 'pin_memory', not paras.no_pin)\n",
    "    setattr(paras, 'verbose', not paras.no_msg)\n",
    "    setattr(paras, 'finetune', False)\n",
    "    setattr(paras, 'binaryClass', True)\n",
    "    force_cudnn_initialization()\n",
    "\n",
    "    config = yaml.load(open(paras.config, 'r'), Loader=yaml.FullLoader)\n",
    "\n",
    "    np.random.seed(paras.seed)\n",
    "    torch.manual_seed(paras.seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(paras.seed)\n",
    "\n",
    "    # Hack to preserve GPU ram just incase OOM later on server\n",
    "    if paras.gpu and paras.reserve_gpu > 0:\n",
    "        buff = torch.randn(int(paras.reserve_gpu * 1e9 // 4)).cuda()\n",
    "        del buff\n",
    "\n",
    "    if paras.lm:\n",
    "        # Train RNNLM\n",
    "        from train_lm import Solver\n",
    "\n",
    "        mode = 'train'\n",
    "    else:\n",
    "        if paras.test:\n",
    "            # Test ASR\n",
    "            assert paras.load is None, 'Load option is mutually exclusive to --test'\n",
    "            from test_asr import Solver\n",
    "\n",
    "            mode = 'test'\n",
    "        elif paras.finetune:\n",
    "            assert paras.load is not None\n",
    "            from finetune_asr import Solver\n",
    "            mode = 'train'\n",
    "        elif paras.binaryClass:\n",
    "            assert paras.load is not None\n",
    "            from train_binaryclass2_4folds2 import Solver\n",
    "            mode = 'train'\n",
    "        else:\n",
    "            # Train ASR\n",
    "            from train_asr import Solver\n",
    "\n",
    "            mode = 'train'\n",
    "\n",
    "    print(\"\\nUsing {} mode\\n\".format(mode))\n",
    "    for idx in range(4):\n",
    "        paras.config = f'./config/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-{idx+1}.yaml'\n",
    "        config = yaml.load(open(paras.config, 'r'), Loader=yaml.FullLoader)\n",
    "        solver = Solver(config, paras, mode)\n",
    "\n",
    "        solver.load_data()\n",
    "    #     solver.print_model()\n",
    "        solver.set_model()\n",
    "        solver.exec()\n",
    "        del solver\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "popular-swing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using train mode\n",
      "\n",
      "[INFO] Exp. name : cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-1_sd0                                   \n",
      "[INFO] Loading data... large dataset may took a while.                                                     \n",
      "Load data for training/validation, store tokenizer and input/output shape\n",
      "Prepare dataloader for training/validation\n",
      "Interface for creating all kinds of dataset\n",
      "import VAGDataset as Dataset\n",
      "[VAGDataset] path: /home/jupyter-jason5/data_process, split: ['CTT4val-1']\n",
      "Mozillacv11Dataset CTT4val-1 found wav data: 5\n",
      "text len: 5\n",
      "remove None, then wav data: 5, text len: 5\n",
      "[VAGDataset] path: /home/jupyter-jason5/data_process, split: ['CTT4-4', 'CTT4-2', 'CTT4-3', 'CTT4val-4', 'CTT4val-2', 'CTT4val-3']\n",
      "Mozillacv11Dataset CTT4-4 found wav data: 19\n",
      "Mozillacv11Dataset CTT4-2 found wav data: 20\n",
      "Mozillacv11Dataset CTT4-3 found wav data: 19\n",
      "Mozillacv11Dataset CTT4val-4 found wav data: 5\n",
      "Mozillacv11Dataset CTT4val-2 found wav data: 5\n",
      "Mozillacv11Dataset CTT4val-3 found wav data: 5\n",
      "text len: 73\n",
      "remove None, then wav data: 73, text len: 73\n",
      "[INFO] Data spec. | Corpus = vag (from /home/jupyter-jason5/data_process)                                  \n",
      "[INFO]            | Train sets = ['CTT4-4', 'CTT4-2', 'CTT4-3', 'CTT4val-4', 'CTT4val-2', 'CTT4val-3']\t| Number of utts = 73\n",
      "[INFO]            | Dev sets = ['CTT4val-1']\t| Number of utts = 5                                          \n",
      "[INFO]            | Batch size = 1\t\t| Bucketing = True                                                     \n",
      "[INFO] I/O spec.  | Audio feature = fbank\t| feature dim = 120                                              \n",
      "Setup ASR model and optimizer \n",
      "[INFO] Model spec.| Encoder's downsampling rate of time axis is 4.                                         \n",
      "[INFO]            | VCC Extractor w/ time downsampling rate = 4 in encoder enabled.                        \n",
      "# Losses\n",
      "# Note: zero_infinity=False is unstable?\n",
      "# Optimizer\n",
      "[INFO] Optim.spec.| Algo. = Adadelta\t| Lr = 1.0\t (Scheduler = fixed)| Scheduled sampling = False           \n",
      "# Enable AMP if needed\n",
      "[INFO] Load ckpt from ./ckpt/cv11Lu_asr_lstm4atthead_allvocab_sd0/best_att-VAG01.pth, restarting at step 795000 (recorded wer = 0.11 %)\n",
      "encoder.layers.0.extractor.0.weight\n",
      "encoder.layers.0.extractor.0.bias\n",
      "encoder.layers.4.layer.weight_ih_l0_reverse\n",
      "encoder.layers.4.layer.weight_hh_l0_reverse\n",
      "encoder.layers.4.layer.bias_ih_l0_reverse\n",
      "encoder.layers.4.layer.bias_hh_l0_reverse\n",
      "fc.weight\n",
      "fc.bias\n",
      "Training End-to-end ASR system\n",
      "[INFO] Total training steps 1.0M.                                                                          \n",
      "self.tr_set: 73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-jason5/LAS_Mandarin_PyTorch-master/core/module.py:51: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  feat_len = feat_len // 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Saved checkpoint (step = 795.0K, loss = 0.57) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-1_sd0/best_biclass2.pth\n",
      "43\n",
      "bestloss3.409372568130493\n",
      "tensor(50.7228, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(50.3385, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(50.0869, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(49.9788, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "[INFO] Saved checkpoint (step = 795.3K, loss = 0.49) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-1_sd0/best_biclass2.pth\n",
      "335\n",
      "bestloss3.409092426300049\n",
      "tensor(49.8721, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(49.6409, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "[INFO] Saved checkpoint (step = 795.5K, loss = 0.53) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-1_sd0/best_biclass2.pth\n",
      "481\n",
      "bestloss3.402940511703491\n",
      "tensor(49.4115, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(49.2219, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(49.0960, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(48.8590, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(48.4899, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(48.1835, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(47.6156, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(47.0313, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(46.8051, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(46.0354, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(46.0487, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(45.1763, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(44.6869, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(44.0086, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(43.4955, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(42.9081, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(41.9423, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(40.9209, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(39.9569, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(39.2711, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(38.6380, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(35.2531, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(37.7509, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(35.5804, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(35.2470, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(34.0175, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(32.9018, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(32.4191, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(28.0402, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(31.6064, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(28.8379, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(28.1125, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(25.7797, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(26.8730, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(25.0633, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(21.6694, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(22.1908, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(21.0770, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(21.1739, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(18.9368, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(19.5222, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(18.4134, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(16.8893, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(15.5948, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(14.8707, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(12.9880, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(11.8062, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(11.0254, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(11.6041, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(10.0575, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(9.7150, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(8.3953, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(8.4463, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(7.2503, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(6.3479, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(4.8849, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(5.4701, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(4.5200, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(4.0677, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(4.0600, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(3.0099, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(2.6262, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(2.6028, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(2.4038, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(1.7192, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(2.0603, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(1.4068, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(1.5451, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(1.3163, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(0.9688, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(0.7582, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(0.8353, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(0.7824, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(0.5530, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(0.5970, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(0.4636, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(0.3451, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(0.3872, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(0.3380, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(0.2396, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(0.2591, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(0.2420, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(0.1856, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(0.1982, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(0.1573, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(0.1397, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(0.1297, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(0.1065, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(0.1178, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(0.0956, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(0.0891, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(0.0869, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(0.0806, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 73\n",
      "tensor(0.0728, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "802300\n",
      "[INFO] Exp. name : cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-2_sd0                                   \n",
      "[INFO] Loading data... large dataset may took a while.                                                     \n",
      "Load data for training/validation, store tokenizer and input/output shape\n",
      "Prepare dataloader for training/validation\n",
      "Interface for creating all kinds of dataset\n",
      "import VAGDataset as Dataset\n",
      "[VAGDataset] path: /home/jupyter-jason5/data_process, split: ['CTT4val-2']\n",
      "Mozillacv11Dataset CTT4val-2 found wav data: 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text len: 5\n",
      "remove None, then wav data: 5, text len: 5\n",
      "[VAGDataset] path: /home/jupyter-jason5/data_process, split: ['CTT4-1', 'CTT4-4', 'CTT4-3', 'CTT4val-1', 'CTT4val-4', 'CTT4val-3']\n",
      "Mozillacv11Dataset CTT4-1 found wav data: 21\n",
      "Mozillacv11Dataset CTT4-4 found wav data: 19\n",
      "Mozillacv11Dataset CTT4-3 found wav data: 19\n",
      "Mozillacv11Dataset CTT4val-1 found wav data: 5\n",
      "Mozillacv11Dataset CTT4val-4 found wav data: 5\n",
      "Mozillacv11Dataset CTT4val-3 found wav data: 5\n",
      "text len: 74\n",
      "remove None, then wav data: 74, text len: 74\n",
      "[INFO] Data spec. | Corpus = vag (from /home/jupyter-jason5/data_process)                                  \n",
      "[INFO]            | Train sets = ['CTT4-1', 'CTT4-4', 'CTT4-3', 'CTT4val-1', 'CTT4val-4', 'CTT4val-3']\t| Number of utts = 74\n",
      "[INFO]            | Dev sets = ['CTT4val-2']\t| Number of utts = 5                                          \n",
      "[INFO]            | Batch size = 1\t\t| Bucketing = True                                                     \n",
      "[INFO] I/O spec.  | Audio feature = fbank\t| feature dim = 120                                              \n",
      "Setup ASR model and optimizer \n",
      "[INFO] Model spec.| Encoder's downsampling rate of time axis is 4.                                         \n",
      "[INFO]            | VCC Extractor w/ time downsampling rate = 4 in encoder enabled.                        \n",
      "# Losses\n",
      "# Note: zero_infinity=False is unstable?\n",
      "# Optimizer\n",
      "[INFO] Optim.spec.| Algo. = Adadelta\t| Lr = 1.0\t (Scheduler = fixed)| Scheduled sampling = False           \n",
      "# Enable AMP if needed\n",
      "[INFO] Load ckpt from ./ckpt/cv11Lu_asr_lstm4atthead_allvocab_sd0/best_att-VAG01.pth, restarting at step 795000 (recorded wer = 0.11 %)\n",
      "encoder.layers.0.extractor.0.weight\n",
      "encoder.layers.0.extractor.0.bias\n",
      "encoder.layers.4.layer.weight_ih_l0_reverse\n",
      "encoder.layers.4.layer.weight_hh_l0_reverse\n",
      "encoder.layers.4.layer.bias_ih_l0_reverse\n",
      "encoder.layers.4.layer.bias_hh_l0_reverse\n",
      "fc.weight\n",
      "fc.bias\n",
      "Training End-to-end ASR system\n",
      "[INFO] Total training steps 1.0M.                                                                          \n",
      "self.tr_set: 74\n",
      "[INFO] Saved checkpoint (step = 795.0K, loss = 0.64) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-2_sd0/best_biclass2.pth\n",
      "43\n",
      "bestloss3.411663055419922\n",
      "tensor(51.4641, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "[INFO] Saved checkpoint (step = 795.1K, loss = 0.50) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-2_sd0/best_biclass2.pth\n",
      "116\n",
      "bestloss3.331948757171631\n",
      "tensor(50.8890, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(50.6122, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(49.2565, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(50.4577, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(49.7897, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(49.3059, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(48.9057, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(48.2494, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(47.6151, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(46.4921, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(45.8192, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(45.5405, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(44.7759, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(42.9231, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(43.6180, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(42.7027, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(43.0266, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(43.1867, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(42.2773, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(41.4179, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(41.0316, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(41.0734, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(40.7552, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(40.0897, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(38.3873, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(39.0636, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(37.1990, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(37.3650, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(36.5230, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(36.1483, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(35.7888, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(34.4027, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(33.6051, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(32.3912, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(30.0436, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(31.0248, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(30.5520, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(29.5160, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(28.2543, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(27.3431, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(26.8568, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(25.3216, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(25.5017, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(24.4632, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(22.6363, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(23.2123, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(21.6744, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(19.2342, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(20.0870, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(19.3229, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(17.4357, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(18.4787, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(16.7292, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(16.7699, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(14.8128, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(16.2644, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(13.9773, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(11.8936, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(10.1855, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(11.8408, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(12.5895, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(11.7954, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(8.5294, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(7.0938, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(8.3946, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(6.5320, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(4.7693, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(4.7294, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(6.7317, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(4.5340, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(4.7715, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(3.8920, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(2.4950, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(2.8672, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(2.5441, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(2.1971, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6008, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(1.9006, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(1.8040, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(1.6809, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(1.1191, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(1.1076, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(0.6829, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(0.6315, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(1.3114, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(1.3046, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(0.7385, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(0.6408, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(0.4956, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(0.6074, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(0.4942, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(0.2917, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(0.4667, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(0.4036, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(0.2952, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(0.4019, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(0.2693, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(0.2472, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 74\n",
      "tensor(0.1997, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "802400\n",
      "[INFO] Exp. name : cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-3_sd0                                   \n",
      "[INFO] Loading data... large dataset may took a while.                                                     \n",
      "Load data for training/validation, store tokenizer and input/output shape\n",
      "Prepare dataloader for training/validation\n",
      "Interface for creating all kinds of dataset\n",
      "import VAGDataset as Dataset\n",
      "[VAGDataset] path: /home/jupyter-jason5/data_process, split: ['CTT4val-3']\n",
      "Mozillacv11Dataset CTT4val-3 found wav data: 5\n",
      "text len: 5\n",
      "remove None, then wav data: 5, text len: 5\n",
      "[VAGDataset] path: /home/jupyter-jason5/data_process, split: ['CTT4-1', 'CTT4-2', 'CTT4-4', 'CTT4val-1', 'CTT4val-2', 'CTT4val-4']\n",
      "Mozillacv11Dataset CTT4-1 found wav data: 21\n",
      "Mozillacv11Dataset CTT4-2 found wav data: 20\n",
      "Mozillacv11Dataset CTT4-4 found wav data: 19\n",
      "Mozillacv11Dataset CTT4val-1 found wav data: 5\n",
      "Mozillacv11Dataset CTT4val-2 found wav data: 5\n",
      "Mozillacv11Dataset CTT4val-4 found wav data: 5\n",
      "text len: 75\n",
      "remove None, then wav data: 75, text len: 75\n",
      "[INFO] Data spec. | Corpus = vag (from /home/jupyter-jason5/data_process)                                  \n",
      "[INFO]            | Train sets = ['CTT4-1', 'CTT4-2', 'CTT4-4', 'CTT4val-1', 'CTT4val-2', 'CTT4val-4']\t| Number of utts = 75\n",
      "[INFO]            | Dev sets = ['CTT4val-3']\t| Number of utts = 5                                          \n",
      "[INFO]            | Batch size = 1\t\t| Bucketing = True                                                     \n",
      "[INFO] I/O spec.  | Audio feature = fbank\t| feature dim = 120                                              \n",
      "Setup ASR model and optimizer \n",
      "[INFO] Model spec.| Encoder's downsampling rate of time axis is 4.                                         \n",
      "[INFO]            | VCC Extractor w/ time downsampling rate = 4 in encoder enabled.                        \n",
      "# Losses\n",
      "# Note: zero_infinity=False is unstable?\n",
      "# Optimizer\n",
      "[INFO] Optim.spec.| Algo. = Adadelta\t| Lr = 1.0\t (Scheduler = fixed)| Scheduled sampling = False           \n",
      "# Enable AMP if needed\n",
      "[INFO] Load ckpt from ./ckpt/cv11Lu_asr_lstm4atthead_allvocab_sd0/best_att-VAG01.pth, restarting at step 795000 (recorded wer = 0.11 %)\n",
      "encoder.layers.0.extractor.0.weight\n",
      "encoder.layers.0.extractor.0.bias\n",
      "encoder.layers.4.layer.weight_ih_l0_reverse\n",
      "encoder.layers.4.layer.weight_hh_l0_reverse\n",
      "encoder.layers.4.layer.bias_ih_l0_reverse\n",
      "encoder.layers.4.layer.bias_hh_l0_reverse\n",
      "fc.weight\n",
      "fc.bias\n",
      "Training End-to-end ASR system\n",
      "[INFO] Total training steps 1.0M.                                                                          \n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 795.0K, loss = 0.64) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-3_sd0/best_biclass2.pth\n",
      "43\n",
      "bestloss3.415304183959961\n",
      "tensor(52.2564, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 795.1K, loss = 0.52) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-3_sd0/best_biclass2.pth\n",
      "116\n",
      "bestloss3.342291831970215\n",
      "tensor(51.7360, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(51.1923, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 795.3K, loss = 0.52) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-3_sd0/best_biclass2.pth\n",
      "262\n",
      "bestloss3.316619873046875\n",
      "tensor(51.4996, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 795.3K, loss = 0.56) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-3_sd0/best_biclass2.pth\n",
      "335\n",
      "bestloss3.3018860816955566\n",
      "tensor(51.1013, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 795.4K, loss = 0.59) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-3_sd0/best_biclass2.pth\n",
      "408\n",
      "bestloss3.2860310077667236\n",
      "tensor(50.7415, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 795.5K, loss = 0.58) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-3_sd0/best_biclass2.pth\n",
      "481\n",
      "bestloss3.2518815994262695\n",
      "tensor(50.3725, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 795.6K, loss = 0.48) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-3_sd0/best_biclass2.pth\n",
      "554\n",
      "bestloss3.186657428741455\n",
      "tensor(49.9400, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 795.6K, loss = 0.50) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-3_sd0/best_biclass2.pth\n",
      "627\n",
      "bestloss3.1344118118286133\n",
      "tensor(49.3969, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(48.3974, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 795.8K, loss = 0.57) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-3_sd0/best_biclass2.pth\n",
      "773\n",
      "bestloss3.075430393218994\n",
      "tensor(48.2285, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(47.1820, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(46.5936, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(46.0896, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 796.1K, loss = 0.40) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-3_sd0/best_biclass2.pth\n",
      "1065\n",
      "bestloss2.8390777111053467\n",
      "tensor(44.7836, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(44.0158, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(43.8279, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 796.3K, loss = 0.53) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-3_sd0/best_biclass2.pth\n",
      "1284\n",
      "bestloss2.806537389755249\n",
      "tensor(42.0567, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(42.7170, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(41.4664, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(40.3509, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(39.9967, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 796.7K, loss = 0.52) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-3_sd0/best_biclass2.pth\n",
      "1722\n",
      "bestloss2.683941125869751\n",
      "tensor(39.7667, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(38.5538, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Saved checkpoint (step = 796.9K, loss = 0.50) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-3_sd0/best_biclass2.pth\n",
      "1868\n",
      "bestloss2.639981269836426\n",
      "tensor(38.2988, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(37.2370, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(36.7762, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(36.2133, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 797.2K, loss = 0.53) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-3_sd0/best_biclass2.pth\n",
      "2160\n",
      "bestloss2.605388641357422\n",
      "tensor(35.4159, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 797.2K, loss = 0.49) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-3_sd0/best_biclass2.pth\n",
      "2233\n",
      "bestloss2.527252674102783\n",
      "tensor(34.5968, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 797.3K, loss = 0.40) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-3_sd0/best_biclass2.pth\n",
      "2306\n",
      "bestloss2.392158031463623\n",
      "tensor(33.2799, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(32.6655, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(31.6944, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 797.5K, loss = 0.28) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-3_sd0/best_biclass2.pth\n",
      "2525\n",
      "bestloss2.1278438568115234\n",
      "tensor(31.0867, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(29.4357, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(28.9126, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(27.5413, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(26.9920, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 797.9K, loss = 0.23) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-3_sd0/best_biclass2.pth\n",
      "2890\n",
      "bestloss2.0248281955718994\n",
      "tensor(25.3097, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(25.3768, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(24.2134, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(23.5644, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(23.4814, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(22.4110, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 798.3K, loss = 0.08) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-3_sd0/best_biclass2.pth\n",
      "3328\n",
      "bestloss1.4882490634918213\n",
      "tensor(21.2585, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(20.1859, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(19.1346, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(18.8252, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(17.2172, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(16.4868, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(16.3765, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(15.0353, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(14.4732, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(12.8370, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(13.4576, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(11.6661, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(10.7648, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(10.5357, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 799.4K, loss = 0.02) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-3_sd0/best_biclass2.pth\n",
      "4423\n",
      "bestloss1.1976319551467896\n",
      "tensor(9.2106, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(9.5334, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(8.5878, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(8.1728, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(7.9587, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(6.7340, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(5.3621, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 799.9K, loss = 0.01) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-3_sd0/best_biclass2.pth\n",
      "4934\n",
      "bestloss0.9036838412284851\n",
      "tensor(5.3644, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(4.8664, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(4.1191, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(3.8544, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(2.5206, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(2.8711, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(2.4580, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(2.3264, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(1.5245, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(2.2438, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(1.5878, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(1.3103, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(1.2210, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(1.1436, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.7959, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.7808, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.7975, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.5989, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.5077, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.4605, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.4110, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.4106, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.3457, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.2904, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.2215, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.2377, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.2318, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.1723, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.1921, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.1597, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.1463, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.1235, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.1314, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.1176, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.1025, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "802500\n",
      "[INFO] Exp. name : cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-4_sd0                                   \n",
      "[INFO] Loading data... large dataset may took a while.                                                     \n",
      "Load data for training/validation, store tokenizer and input/output shape\n",
      "Prepare dataloader for training/validation\n",
      "Interface for creating all kinds of dataset\n",
      "import VAGDataset as Dataset\n",
      "[VAGDataset] path: /home/jupyter-jason5/data_process, split: ['CTT4val-4']\n",
      "Mozillacv11Dataset CTT4val-4 found wav data: 5\n",
      "text len: 5\n",
      "remove None, then wav data: 5, text len: 5\n",
      "[VAGDataset] path: /home/jupyter-jason5/data_process, split: ['CTT4-1', 'CTT4-2', 'CTT4-3', 'CTT4val-1', 'CTT4val-2', 'CTT4val-3']\n",
      "Mozillacv11Dataset CTT4-1 found wav data: 21\n",
      "Mozillacv11Dataset CTT4-2 found wav data: 20\n",
      "Mozillacv11Dataset CTT4-3 found wav data: 19\n",
      "Mozillacv11Dataset CTT4val-1 found wav data: 5\n",
      "Mozillacv11Dataset CTT4val-2 found wav data: 5\n",
      "Mozillacv11Dataset CTT4val-3 found wav data: 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text len: 75\n",
      "remove None, then wav data: 75, text len: 75\n",
      "[INFO] Data spec. | Corpus = vag (from /home/jupyter-jason5/data_process)                                  \n",
      "[INFO]            | Train sets = ['CTT4-1', 'CTT4-2', 'CTT4-3', 'CTT4val-1', 'CTT4val-2', 'CTT4val-3']\t| Number of utts = 75\n",
      "[INFO]            | Dev sets = ['CTT4val-4']\t| Number of utts = 5                                          \n",
      "[INFO]            | Batch size = 1\t\t| Bucketing = True                                                     \n",
      "[INFO] I/O spec.  | Audio feature = fbank\t| feature dim = 120                                              \n",
      "Setup ASR model and optimizer \n",
      "[INFO] Model spec.| Encoder's downsampling rate of time axis is 4.                                         \n",
      "[INFO]            | VCC Extractor w/ time downsampling rate = 4 in encoder enabled.                        \n",
      "# Losses\n",
      "# Note: zero_infinity=False is unstable?\n",
      "# Optimizer\n",
      "[INFO] Optim.spec.| Algo. = Adadelta\t| Lr = 1.0\t (Scheduler = fixed)| Scheduled sampling = False           \n",
      "# Enable AMP if needed\n",
      "[INFO] Load ckpt from ./ckpt/cv11Lu_asr_lstm4atthead_allvocab_sd0/best_att-VAG01.pth, restarting at step 795000 (recorded wer = 0.11 %)\n",
      "encoder.layers.0.extractor.0.weight\n",
      "encoder.layers.0.extractor.0.bias\n",
      "encoder.layers.4.layer.weight_ih_l0_reverse\n",
      "encoder.layers.4.layer.weight_hh_l0_reverse\n",
      "encoder.layers.4.layer.bias_ih_l0_reverse\n",
      "encoder.layers.4.layer.bias_hh_l0_reverse\n",
      "fc.weight\n",
      "fc.bias\n",
      "Training End-to-end ASR system\n",
      "[INFO] Total training steps 1.0M.                                                                          \n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 795.0K, loss = 0.79) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-4_sd0/best_biclass2.pth\n",
      "43\n",
      "bestloss3.3998398780822754\n",
      "tensor(52.1980, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(51.6931, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 795.2K, loss = 0.91) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-4_sd0/best_biclass2.pth\n",
      "189\n",
      "bestloss3.3760933876037598\n",
      "tensor(51.8085, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 795.3K, loss = 0.72) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-4_sd0/best_biclass2.pth\n",
      "262\n",
      "bestloss3.357914924621582\n",
      "tensor(51.3721, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 795.3K, loss = 0.96) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-4_sd0/best_biclass2.pth\n",
      "335\n",
      "bestloss3.343409299850464\n",
      "tensor(51.5628, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 795.4K, loss = 0.70) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-4_sd0/best_biclass2.pth\n",
      "408\n",
      "bestloss3.3056697845458984\n",
      "tensor(51.1813, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 795.5K, loss = 0.74) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-4_sd0/best_biclass2.pth\n",
      "481\n",
      "bestloss3.265850067138672\n",
      "tensor(51.1189, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 795.6K, loss = 0.89) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-4_sd0/best_biclass2.pth\n",
      "554\n",
      "bestloss3.2370519638061523\n",
      "tensor(50.4612, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 795.6K, loss = 0.68) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-4_sd0/best_biclass2.pth\n",
      "627\n",
      "bestloss3.1544055938720703\n",
      "tensor(50.9391, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 795.7K, loss = 0.65) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-4_sd0/best_biclass2.pth\n",
      "700\n",
      "bestloss3.1481378078460693\n",
      "tensor(50.5566, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 795.8K, loss = 0.78) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-4_sd0/best_biclass2.pth\n",
      "773\n",
      "bestloss3.0880041122436523\n",
      "tensor(50.4543, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 795.8K, loss = 0.60) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-4_sd0/best_biclass2.pth\n",
      "846\n",
      "bestloss3.0744781494140625\n",
      "tensor(50.0407, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 795.9K, loss = 0.70) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-4_sd0/best_biclass2.pth\n",
      "919\n",
      "bestloss2.9907240867614746\n",
      "tensor(49.4836, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 796.0K, loss = 0.67) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-4_sd0/best_biclass2.pth\n",
      "992\n",
      "bestloss2.93218731880188\n",
      "tensor(49.3111, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(49.3034, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 796.1K, loss = 0.64) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-4_sd0/best_biclass2.pth\n",
      "1138\n",
      "bestloss2.7977371215820312\n",
      "tensor(49.0244, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 796.2K, loss = 0.49) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-4_sd0/best_biclass2.pth\n",
      "1211\n",
      "bestloss2.729579448699951\n",
      "tensor(48.7816, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 796.3K, loss = 0.51) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-4_sd0/best_biclass2.pth\n",
      "1284\n",
      "bestloss2.6589670181274414\n",
      "tensor(48.3943, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 796.4K, loss = 0.52) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-4_sd0/best_biclass2.pth\n",
      "1357\n",
      "bestloss2.613206148147583\n",
      "tensor(47.7277, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(47.4575, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 796.5K, loss = 0.34) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-4_sd0/best_biclass2.pth\n",
      "1503\n",
      "bestloss2.473414182662964\n",
      "tensor(47.4712, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 796.6K, loss = 0.34) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-4_sd0/best_biclass2.pth\n",
      "1576\n",
      "bestloss2.408829689025879\n",
      "[INFO] Saved checkpoint (step = 796.6K, loss = 0.29) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-4_sd0/best_biclass2.pth\n",
      "1649\n",
      "bestloss2.364792823791504\n",
      "tensor(47.0874, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(45.1271, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 796.8K, loss = 0.28) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-4_sd0/best_biclass2.pth\n",
      "1795\n",
      "bestloss2.2615461349487305\n",
      "tensor(46.1452, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 796.9K, loss = 0.24) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-4_sd0/best_biclass2.pth\n",
      "1868\n",
      "bestloss2.209263563156128\n",
      "tensor(46.2285, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 796.9K, loss = 0.27) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-4_sd0/best_biclass2.pth\n",
      "1941\n",
      "bestloss2.2007861137390137\n",
      "tensor(45.5947, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 797.0K, loss = 0.14) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-4_sd0/best_biclass2.pth\n",
      "2014\n",
      "bestloss2.150515556335449\n",
      "tensor(45.4259, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 797.1K, loss = 0.19) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-4_sd0/best_biclass2.pth\n",
      "2087\n",
      "bestloss2.0977394580841064\n",
      "tensor(44.3036, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(43.3698, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 797.2K, loss = 0.19) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-4_sd0/best_biclass2.pth\n",
      "2233\n",
      "bestloss2.062889575958252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(44.1382, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 797.3K, loss = 0.17) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-4_sd0/best_biclass2.pth\n",
      "2306\n",
      "bestloss2.0222856998443604\n",
      "tensor(43.4554, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(42.7136, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 797.5K, loss = 0.14) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-4_sd0/best_biclass2.pth\n",
      "2452\n",
      "bestloss1.9790030717849731\n",
      "tensor(42.5432, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 797.5K, loss = 0.09) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-4_sd0/best_biclass2.pth\n",
      "2525\n",
      "bestloss1.9561643600463867\n",
      "tensor(41.6991, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 797.6K, loss = 0.09) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-4_sd0/best_biclass2.pth\n",
      "2598\n",
      "bestloss1.868705153465271\n",
      "tensor(40.8031, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(39.8963, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(39.6446, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(39.3446, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 797.9K, loss = 0.05) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-4_sd0/best_biclass2.pth\n",
      "2890\n",
      "bestloss1.7681163549423218\n",
      "tensor(38.0540, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 798.0K, loss = 0.05) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-4_sd0/best_biclass2.pth\n",
      "2963\n",
      "bestloss1.6883525848388672\n",
      "tensor(37.0848, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(35.8031, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(34.4078, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 798.2K, loss = 0.03) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-4_sd0/best_biclass2.pth\n",
      "3182\n",
      "bestloss1.5374168157577515\n",
      "tensor(32.6643, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(32.5829, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(30.4256, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(30.3293, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 798.5K, loss = 0.01) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-4_sd0/best_biclass2.pth\n",
      "3474\n",
      "bestloss1.3200645446777344\n",
      "tensor(29.3076, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(24.7698, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 798.6K, loss = 0.01) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-4_sd0/best_biclass2.pth\n",
      "3620\n",
      "bestloss1.2517850399017334\n",
      "tensor(25.9060, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 798.7K, loss = 0.01) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-4_sd0/best_biclass2.pth\n",
      "3693\n",
      "bestloss1.198974847793579\n",
      "tensor(24.2828, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(23.1352, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(21.8025, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(20.3759, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(18.2660, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(17.5697, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 799.1K, loss = 0.00) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-4_sd0/best_biclass2.pth\n",
      "4131\n",
      "bestloss0.8448869585990906\n",
      "tensor(14.4642, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 799.2K, loss = 0.00) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-4_sd0/best_biclass2.pth\n",
      "4204\n",
      "bestloss0.7373327016830444\n",
      "tensor(15.4192, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(13.6591, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(12.5319, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 799.5K, loss = 0.00) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-4_sd0/best_biclass2.pth\n",
      "4496\n",
      "bestloss0.7249910235404968\n",
      "tensor(10.0305, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 799.6K, loss = 0.00) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-4_sd0/best_biclass2.pth\n",
      "4569\n",
      "bestloss0.5508813858032227\n",
      "tensor(9.9780, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(10.3102, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(8.7140, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 799.8K, loss = 0.00) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-4_sd0/best_biclass2.pth\n",
      "4788\n",
      "bestloss0.44200843572616577\n",
      "tensor(6.0608, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(7.4858, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 799.9K, loss = 0.00) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-4_sd0/best_biclass2.pth\n",
      "4934\n",
      "bestloss0.4064432680606842\n",
      "tensor(6.2804, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(5.7478, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 800.1K, loss = 0.00) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-4_sd0/best_biclass2.pth\n",
      "5080\n",
      "bestloss0.397026926279068\n",
      "tensor(5.8919, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 800.2K, loss = 0.00) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-4_sd0/best_biclass2.pth\n",
      "5153\n",
      "bestloss0.3624259829521179\n",
      "tensor(4.2728, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(4.1560, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(3.8806, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(3.8676, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 800.4K, loss = 0.00) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-4_sd0/best_biclass2.pth\n",
      "5445\n",
      "bestloss0.35587742924690247\n",
      "tensor(3.2087, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(2.2621, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(2.0036, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 800.7K, loss = 0.00) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-4_sd0/best_biclass2.pth\n",
      "5664\n",
      "bestloss0.32655221223831177\n",
      "tensor(2.1400, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(1.4667, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(1.3418, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(1.2381, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.9015, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 801.0K, loss = 0.00) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-4_sd0/best_biclass2.pth\n",
      "6029\n",
      "bestloss0.28257837891578674\n",
      "tensor(0.9902, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.8953, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.8068, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.5872, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.5823, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 801.4K, loss = 0.00) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-4_sd0/best_biclass2.pth\n",
      "6394\n",
      "bestloss0.25127390027046204\n",
      "tensor(0.6174, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.3871, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3385, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.3220, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "[INFO] Saved checkpoint (step = 801.7K, loss = 0.00) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab-biclass2-4fold-4_sd0/best_biclass2.pth\n",
      "6686\n",
      "bestloss0.23486748337745667\n",
      "tensor(0.2858, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.2883, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.2421, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.2544, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.1853, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.1764, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.1925, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.1465, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.1309, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.1306, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "self.tr_set: 75\n",
      "tensor(0.1120, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "\n",
      "802500\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "federal-floating",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('asd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "respective-fruit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "============  Result of /home/jupyter-jason3/LAS_Mandarin_PyTorch-master/result/mozillacv11_asr_stm4atthead-test_test_output.csv ============\r\n",
      " -----------------------------------------------------------------------\r\n",
      "| Statics\t\t|  Truth\t|  Prediction\t| Abs. Diff.\t|\r\n",
      " -----------------------------------------------------------------------\r\n",
      "| Avg. # of chars\t|  8.01\t|  8.10\t|  0.16\t\t|\r\n",
      "| Avg. # of words\t|  1.00\t|  1.00\t|  0.00\t\t|\r\n",
      " -----------------------------------------------------------------------\r\n",
      " ---------------------------------------------------------------\r\n",
      "| Error Rate (%)| Mean\t\t| Std.\t\t| Min./Max.\t|\r\n",
      " ---------------------------------------------------------------\r\n",
      "| Character\t| 7.9479\t| 21.68\t\t| 0.00/240.00\t|\r\n",
      "| Word\t\t| 18.1725\t| 38.56\t\t| 0.00/100.00\t|\r\n",
      " ---------------------------------------------------------------\r\n",
      "Note : If the text unit is phoneme, WER = PER and CER is meaningless.\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!python eval.py --file ~/LAS_Mandarin_PyTorch-master/result/mozillacv11_asr_stm4atthead-test_test_output.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interpreted-bahrain",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
