{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "handy-writing",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "compressed-journalism",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
    "# os.environ['CUDA_VISIBLE_DEVICES']='0,1'\n",
    "os.environ['CUDA_LAUNCH_BLOCKING']='1'\n",
    "import torch\n",
    "# torch.cuda.set_device(0)\n",
    "print(torch.cuda.current_device())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "sexual-string",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "elementary-scholar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "nervous-completion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "outdoor-burst",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cudaSetDevice(0)\n",
    "#dataset transcript要在dataset資好夾調\n",
    "#cuda 在basesolver init調\n",
    "#dataset要在data.py設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "nutritional-bishop",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! python\n",
    "# -*- coding: utf-8 -*-\n",
    "# Author: kun\n",
    "# @Time: 2019-10-29 20:29\n",
    "\n",
    "import yaml\n",
    "import torch\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "class Para(object):\n",
    "    a=1\n",
    "\n",
    "def force_cudnn_initialization():\n",
    "    s = 32\n",
    "    dev = torch.device('cuda:0')\n",
    "    torch.nn.functional.conv2d(torch.zeros(s, s, s, s, device=dev), torch.zeros(s, s, s, s, device=dev))\n",
    "    \n",
    "#force_cudnn_initialization()\n",
    "def main():\n",
    "    # For reproducibility, comment these may speed up training\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    # Arguments\n",
    "#     parser = argparse.ArgumentParser(description='Training E2E asr.')\n",
    "#     parser.add_argument('--config', type=str, help='Path to experiment config.')\n",
    "#     parser.add_argument('--name', default=None, type=str, help='Name for logging.')\n",
    "#     parser.add_argument('--logdir', default='log/', type=str,\n",
    "#                         help='Logging path.', required=False)\n",
    "#     parser.add_argument('--ckpdir', default='ckpt/', type=str,\n",
    "#                         help='Checkpoint path.', required=False)\n",
    "#     parser.add_argument('--outdir', default='result/', type=str,\n",
    "#                         help='Decode output path.', required=False)\n",
    "#     parser.add_argument('--load', default=None, type=str,\n",
    "#                         help='Load pre-trained model (for training only)', required=False)\n",
    "#     parser.add_argument('--seed', default=0, type=int,\n",
    "#                         help='Random seed for reproducable results.', required=False)\n",
    "#     parser.add_argument('--cudnn-ctc', action='store_true',\n",
    "#                         help='Switches CTC backend from torch to cudnn')\n",
    "#     parser.add_argument('--njobs', default=32, type=int,\n",
    "#                         help='Number of threads for dataloader/decoding.', required=False)\n",
    "#     parser.add_argument('--cpu', action='store_true', help='Disable GPU training.')\n",
    "#     parser.add_argument('--no-pin', action='store_true',\n",
    "#                         help='Disable pin-memory for dataloader')\n",
    "#     parser.add_argument('--test', action='store_true', help='Test the model.')\n",
    "#     parser.add_argument('--no-msg', action='store_true', help='Hide all messages.')\n",
    "#     parser.add_argument('--lm', action='store_true',\n",
    "#                         help='Option for training RNNLM.')\n",
    "#     # Following features in development.\n",
    "#     parser.add_argument('--amp', action='store_true', help='Option to enable AMP.')\n",
    "#     parser.add_argument('--reserve-gpu', default=0, type=float,\n",
    "#                         help='Option to reserve GPU ram for training.')\n",
    "#     parser.add_argument('--jit', action='store_true',\n",
    "#                         help='Option for enabling jit in pytorch. (feature in development)')\n",
    "#     ###\n",
    "#     paras = parser.parse_args()\n",
    "    paras = Para()\n",
    "#     paras.config = './config/aishell_asr_example_lstm4atthead1-test.yaml'\n",
    "#     paras.name = None\n",
    "#     paras.logdir = 'log/'\n",
    "#     paras.ckpdir = 'ckpt/'\n",
    "#     paras.outdir = 'result/'\n",
    "#     paras.load = None\n",
    "#     paras.seed = 0\n",
    "#     paras.cudnn_ctc = False\n",
    "#     paras.cpu = False\n",
    "#     paras.no_pin = False\n",
    "#     paras.test = True\n",
    "#     paras.no_msg = False\n",
    "#     paras.lm = False\n",
    "#     paras.amp = False\n",
    "#     paras.reserve_gpu = 0\n",
    "#     paras.jit = False\n",
    "    setattr(paras, 'config', './config/cv11Lu_asr_lstm4atthead_allvocab-Finetune.yaml')\n",
    "    setattr(paras, 'name', None)\n",
    "    setattr(paras, 'logdir', 'log/')\n",
    "    setattr(paras, 'ckpdir', 'ckpt/')\n",
    "    setattr(paras, 'outdir', 'result/')\n",
    "    setattr(paras, 'load', './ckpt/cv11Lu_asr_lstm4atthead_allvocab_sd0/best_att-VAG01.pth')\n",
    "    setattr(paras, 'seed', 0)\n",
    "    setattr(paras, 'cudnn_ctc', False)\n",
    "    setattr(paras, 'njobs',8)\n",
    "    setattr(paras, 'cpu', False)\n",
    "    setattr(paras, 'no_pin', False)\n",
    "    setattr(paras, 'test', False)\n",
    "    setattr(paras, 'no_msg', False)\n",
    "    setattr(paras, 'lm', False)\n",
    "    setattr(paras, 'amp', False)\n",
    "    setattr(paras, 'reserve_gpu', 8)\n",
    "    setattr(paras, 'jit', False)\n",
    "    setattr(paras, 'gpu', not paras.cpu)\n",
    "    setattr(paras, 'pin_memory', not paras.no_pin)\n",
    "    setattr(paras, 'verbose', not paras.no_msg)\n",
    "    setattr(paras, 'finetune', True)\n",
    "    force_cudnn_initialization()\n",
    "\n",
    "    config = yaml.load(open(paras.config, 'r'), Loader=yaml.FullLoader)\n",
    "\n",
    "    np.random.seed(paras.seed)\n",
    "    torch.manual_seed(paras.seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(paras.seed)\n",
    "\n",
    "    # Hack to preserve GPU ram just incase OOM later on server\n",
    "    if paras.gpu and paras.reserve_gpu > 0:\n",
    "        buff = torch.randn(int(paras.reserve_gpu * 1e9 // 4)).cuda()\n",
    "        del buff\n",
    "\n",
    "    if paras.lm:\n",
    "        # Train RNNLM\n",
    "        from train_lm import Solver\n",
    "\n",
    "        mode = 'train'\n",
    "    else:\n",
    "        if paras.test:\n",
    "            # Test ASR\n",
    "            assert paras.load is None, 'Load option is mutually exclusive to --test'\n",
    "            from test_asr import Solver\n",
    "\n",
    "            mode = 'test'\n",
    "        elif paras.finetune:\n",
    "            assert paras.load is not None\n",
    "            from finetune_asr import Solver\n",
    "            mode = 'train'\n",
    "        else:\n",
    "            # Train ASR\n",
    "            from train_asr import Solver\n",
    "\n",
    "            mode = 'train'\n",
    "\n",
    "    print(\"\\nUsing {} mode\\n\".format(mode))\n",
    "    solver = Solver(config, paras, mode)\n",
    "    solver.load_data()\n",
    "    solver.print_model()\n",
    "#     solver.set_model()\n",
    "#     solver.exec()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "revolutionary-toolbox",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using train mode\n",
      "\n",
      "[INFO] Exp. name : cv11Lu_asr_lstm4atthead_allvocab-Finetune_sd0                                           \n",
      "[INFO] Loading data... large dataset may took a while.                                                     \n",
      "Load data for training/validation, store tokenizer and input/output shape\n",
      "Prepare dataloader for training/validation\n",
      "Load text encoder : CharacterTextEncoder\n",
      "Interface for creating all kinds of dataset\n",
      "import Mozillacv11Dataset as Dataset\n",
      "[Mozillacv11Dataset] path: /mnt/usb/jason3/cv-corpus-11.0-2022-09-21/zh-TW/wavs, split: ['VAG01CTT']\n",
      "Mozillacv11Dataset VAG01CTT found wav data: 20\n",
      "text len: 20\n",
      "remove None, then wav data: 20, text len: 20\n",
      "[Mozillacv11Dataset] path: /mnt/usb/jason3/cv-corpus-11.0-2022-09-21/zh-TW/wavs, split: ['VAG01read']\n",
      "Mozillacv11Dataset VAG01read found wav data: 7\n",
      "text len: 7\n",
      "remove None, then wav data: 7, text len: 7\n",
      "[INFO] Data spec. | Corpus = mozilla_cv11 (from /mnt/usb/jason3/cv-corpus-11.0-2022-09-21/zh-TW/wavs)      \n",
      "[INFO]            | Train sets = ['VAG01read']\t| Number of utts = 7                                        \n",
      "[INFO]            | Dev sets = ['VAG01CTT']\t| Number of utts = 20                                          \n",
      "[INFO]            | Batch size = 16\t\t| Bucketing = True                                                    \n",
      "[INFO] I/O spec.  | Audio feature = fbank\t| feature dim = 120\t| Token type = character\t| Vocab size = 3283 \n",
      "ASR(\n",
      "  (encoder): Encoder(\n",
      "    (layers): ModuleList(\n",
      "      (0): VGGExtractor(\n",
      "        (extractor): Sequential(\n",
      "          (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): ReLU()\n",
      "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (3): ReLU()\n",
      "          (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "          (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (6): ReLU()\n",
      "          (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (8): ReLU()\n",
      "          (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        )\n",
      "      )\n",
      "      (1): RNNLayer(\n",
      "        (layer): LSTM(1280, 1024, batch_first=True, bidirectional=True)\n",
      "        (pj): Linear(in_features=2048, out_features=2048, bias=True)\n",
      "      )\n",
      "      (2): RNNLayer(\n",
      "        (layer): LSTM(2048, 1024, batch_first=True, bidirectional=True)\n",
      "        (pj): Linear(in_features=2048, out_features=2048, bias=True)\n",
      "      )\n",
      "      (3): RNNLayer(\n",
      "        (layer): LSTM(2048, 1024, batch_first=True, bidirectional=True)\n",
      "        (pj): Linear(in_features=2048, out_features=2048, bias=True)\n",
      "      )\n",
      "      (4): RNNLayer(\n",
      "        (layer): LSTM(2048, 1024, batch_first=True, bidirectional=True)\n",
      "        (pj): Linear(in_features=2048, out_features=2048, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pre_embed): Embedding(3283, 1024)\n",
      "  (embed_drop): Dropout(p=0.0, inplace=False)\n",
      "  (decoder): Decoder(\n",
      "    (layers): LSTM(3072, 1024, num_layers=2, batch_first=True)\n",
      "    (char_trans): Linear(in_features=1024, out_features=3283, bias=True)\n",
      "    (final_dropout): Dropout(p=0, inplace=False)\n",
      "  )\n",
      "  (attention): Attention(\n",
      "    (proj_q): Linear(in_features=2048, out_features=512, bias=True)\n",
      "    (proj_k): Linear(in_features=2048, out_features=512, bias=True)\n",
      "    (att_layer): LocationAwareAttention(\n",
      "      (softmax): Softmax(dim=-1)\n",
      "      (loc_conv): Conv1d(1, 10, kernel_size=(201,), stride=(1,), padding=(100,), bias=False)\n",
      "      (loc_proj): Linear(in_features=10, out_features=512, bias=False)\n",
      "      (gen_energy): Linear(in_features=512, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "--------------------\n",
      "name: encoder.layers.0.extractor.0.weight\n",
      "values: \n",
      "Parameter containing:\n",
      "tensor([[[[ 9.6222e-02,  7.6138e-01, -3.7662e-02],\n",
      "          [ 2.9261e-01, -2.4968e-01, -8.6099e-02],\n",
      "          [-3.0563e-01, -2.6197e-01, -8.2383e-03]],\n",
      "\n",
      "         [[ 2.2520e-02,  3.5746e-01,  4.6209e-01],\n",
      "          [-2.6567e-01,  1.1248e-01, -7.0288e-02],\n",
      "          [-2.3813e-01, -1.8876e-01, -1.5983e-01]],\n",
      "\n",
      "         [[-2.8689e-01,  1.1100e-01,  1.7761e-01],\n",
      "          [-1.8644e-02,  1.5893e-01,  1.1872e-01],\n",
      "          [-7.4138e-02, -9.8524e-03,  2.5827e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.2679e-01,  2.8614e-01,  1.4042e-01],\n",
      "          [ 4.5851e-01, -4.5531e-02, -3.1435e-01],\n",
      "          [-3.7686e-01,  8.0822e-02,  1.3911e-01]],\n",
      "\n",
      "         [[ 9.2054e-02, -2.1379e-01,  1.1240e-01],\n",
      "          [-1.7981e-02, -3.1213e-01, -4.5985e-01],\n",
      "          [ 1.3361e-01,  9.6717e-02,  1.5560e-01]],\n",
      "\n",
      "         [[-6.0517e-02,  2.1487e-01, -3.5690e-04],\n",
      "          [-2.8690e-02, -1.3563e-01, -2.4484e-01],\n",
      "          [-1.0663e-02, -1.3355e-01,  4.6515e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3139e-01, -2.5452e-01,  6.2867e-02],\n",
      "          [ 9.7187e-02,  3.5619e-01,  1.1828e-01],\n",
      "          [-1.6850e-01,  3.9973e-02, -1.5366e-01]],\n",
      "\n",
      "         [[-1.0350e-02,  1.3377e-01, -1.9723e-01],\n",
      "          [ 2.8400e-01,  8.7151e-02, -1.3627e-01],\n",
      "          [ 2.0057e-01,  2.0728e-01,  1.2897e-01]],\n",
      "\n",
      "         [[-1.4423e-01,  1.2440e-01,  7.1692e-02],\n",
      "          [-2.1840e-01,  8.3616e-02, -8.1802e-02],\n",
      "          [-4.5780e-02,  7.6534e-02,  2.7937e-01]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.2729e-01, -2.7842e-01,  1.6485e-01],\n",
      "          [-1.7013e-01, -3.0637e-01, -1.6076e-01],\n",
      "          [-3.0201e-01, -3.4908e-02,  1.5176e-01]],\n",
      "\n",
      "         [[ 3.0895e-01, -4.3433e-02, -8.3862e-02],\n",
      "          [ 4.6367e-02, -4.5136e-02, -1.7263e-01],\n",
      "          [ 2.8379e-02, -2.3665e-01, -4.5970e-01]],\n",
      "\n",
      "         [[ 7.6653e-02,  3.5312e-01,  1.7705e-01],\n",
      "          [-3.6143e-03, -2.8642e-01, -9.0141e-02],\n",
      "          [-2.3304e-01, -1.9686e-01,  1.3864e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.6467e-01, -1.4530e-01,  7.4505e-02],\n",
      "          [-1.0543e-01, -6.9261e-02, -1.9343e-02],\n",
      "          [ 2.0914e-01,  1.4294e-01, -1.7503e-01]],\n",
      "\n",
      "         [[-5.7259e-01, -1.3114e-01, -9.6374e-02],\n",
      "          [ 1.8574e-02,  2.5043e-01,  3.4916e-02],\n",
      "          [-8.9632e-02,  1.0285e-01,  5.5479e-02]],\n",
      "\n",
      "         [[-5.8876e-03, -2.9341e-01, -1.5948e-01],\n",
      "          [ 1.3085e-01,  2.6058e-01, -2.6127e-01],\n",
      "          [-1.4263e-01,  1.2705e-01,  1.0278e-01]]],\n",
      "\n",
      "\n",
      "        [[[-6.9949e-02, -5.6696e-02,  1.0272e-01],\n",
      "          [ 2.4161e-01,  7.9595e-02,  1.9023e-01],\n",
      "          [-1.4223e-01,  2.6031e-02, -3.5168e-01]],\n",
      "\n",
      "         [[-2.4907e-01, -3.0225e-02,  2.3070e-02],\n",
      "          [ 3.7343e-01, -2.6404e-03,  1.2703e-01],\n",
      "          [ 6.2027e-02, -3.8326e-02,  1.2278e-02]],\n",
      "\n",
      "         [[-2.4230e-01,  1.8740e-01, -1.7103e-01],\n",
      "          [-6.7449e-02, -1.5376e-01,  7.0485e-02],\n",
      "          [ 2.2431e-02,  2.1270e-01,  2.5397e-02]]]], requires_grad=True)\n",
      "--------------------\n",
      "name: encoder.layers.0.extractor.0.bias\n",
      "values: \n",
      "Parameter containing:\n",
      "tensor([-0.0480,  0.0459, -0.1195, -0.1289, -0.1030, -0.1388, -0.0272, -0.0083,\n",
      "        -0.1080, -0.0958, -0.0429,  0.0872,  0.0874, -0.0531, -0.0408, -0.0681,\n",
      "        -0.0355, -0.1017,  0.0081,  0.0062, -0.0847, -0.0065, -0.1233,  0.0124,\n",
      "        -0.0012, -0.0898, -0.0218,  0.0699,  0.0130, -0.1168, -0.0569,  0.0659,\n",
      "        -0.0130,  0.0148, -0.0310, -0.0367, -0.1862, -0.1257, -0.0451,  0.0191,\n",
      "        -0.1066,  0.1073, -0.0054, -0.1312, -0.0943, -0.1264, -0.1776, -0.1781,\n",
      "         0.0730, -0.1609, -0.1642, -0.0033,  0.0924, -0.1362,  0.0429, -0.1036,\n",
      "        -0.1219, -0.0929, -0.1467,  0.0211, -0.1271, -0.0063, -0.1167, -0.0425],\n",
      "       requires_grad=True)\n",
      "--------------------\n",
      "name: encoder.layers.0.extractor.2.weight\n",
      "values: \n",
      "Parameter containing:\n",
      "tensor([[[[-6.9841e-03,  2.4155e-02,  3.6073e-02],\n",
      "          [ 1.1157e-02, -4.5861e-02, -1.0908e-01],\n",
      "          [-1.3344e-01, -3.8589e-02, -8.6979e-02]],\n",
      "\n",
      "         [[ 1.2551e-01,  7.9403e-02,  7.4807e-03],\n",
      "          [ 2.6958e-02,  1.0819e-02,  4.9236e-02],\n",
      "          [ 2.8065e-02,  1.5107e-02, -2.8743e-02]],\n",
      "\n",
      "         [[-2.6134e-03,  1.7860e-02, -1.6329e-02],\n",
      "          [-4.5932e-02,  5.7215e-02, -5.0258e-02],\n",
      "          [ 2.9730e-02,  3.1781e-02,  1.7276e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.0811e-02, -5.1146e-05, -4.8973e-02],\n",
      "          [ 1.1549e-01,  3.2122e-02,  1.3686e-02],\n",
      "          [ 1.1502e-01,  2.0375e-02, -5.6667e-03]],\n",
      "\n",
      "         [[ 1.1484e-01,  8.1415e-02,  1.3328e-01],\n",
      "          [ 9.7086e-02,  4.8475e-02,  6.6432e-02],\n",
      "          [-4.7596e-03,  3.2292e-02, -8.2262e-03]],\n",
      "\n",
      "         [[ 3.8464e-02,  2.3379e-02, -3.0533e-02],\n",
      "          [-1.0066e-01, -7.1987e-02,  1.5193e-02],\n",
      "          [-6.8892e-02, -1.9124e-01, -3.0265e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.4335e-02,  1.9212e-02,  1.3298e-01],\n",
      "          [-1.1007e-01, -1.7444e-02, -7.2396e-02],\n",
      "          [-1.4900e-01, -4.3816e-02, -1.0838e-01]],\n",
      "\n",
      "         [[ 3.9487e-02, -2.9873e-02, -2.4605e-02],\n",
      "          [ 9.5926e-03,  2.8681e-02,  5.6764e-02],\n",
      "          [-8.1060e-02, -3.5406e-02,  4.9362e-02]],\n",
      "\n",
      "         [[ 4.2338e-02, -5.3773e-02, -2.3784e-02],\n",
      "          [ 7.1985e-02,  1.1013e-02, -4.5905e-02],\n",
      "          [ 1.0196e-01,  2.2013e-03,  1.1982e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.8988e-02, -7.1692e-02, -5.5004e-02],\n",
      "          [-7.0944e-03, -8.7833e-02, -9.9887e-02],\n",
      "          [-1.5618e-02,  8.8098e-03, -3.0164e-02]],\n",
      "\n",
      "         [[-4.1109e-02, -2.1167e-02,  6.9088e-02],\n",
      "          [ 1.3553e-02, -1.7781e-02,  1.3917e-02],\n",
      "          [-7.9797e-02,  1.0282e-03,  1.6221e-02]],\n",
      "\n",
      "         [[-2.9909e-02,  3.7717e-02, -7.6969e-02],\n",
      "          [-5.7085e-02,  9.7053e-04, -7.4860e-02],\n",
      "          [-6.8657e-02,  1.4888e-02, -1.1551e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 6.9150e-02,  8.8684e-02,  6.0262e-02],\n",
      "          [ 2.7746e-02,  6.1767e-02, -4.5205e-02],\n",
      "          [-3.2992e-02, -7.9135e-02, -1.2227e-01]],\n",
      "\n",
      "         [[-2.9201e-02, -7.1631e-02, -1.2128e-01],\n",
      "          [ 3.5629e-02,  2.7371e-02,  1.8119e-01],\n",
      "          [ 1.0506e-02, -6.3542e-02, -2.0509e-02]],\n",
      "\n",
      "         [[-3.3566e-02, -1.1255e-01, -6.4784e-02],\n",
      "          [-4.2625e-02, -9.7325e-02, -8.9590e-02],\n",
      "          [-1.3984e-01, -7.4660e-02, -2.7145e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.5022e-02,  1.1031e-01,  4.2083e-02],\n",
      "          [ 1.2666e-01,  2.3900e-03,  9.7682e-02],\n",
      "          [-3.2421e-02, -2.0025e-03,  1.0467e-02]],\n",
      "\n",
      "         [[-1.1071e-01, -5.9585e-02,  1.6697e-02],\n",
      "          [-1.2389e-01, -1.1743e-01, -1.3901e-01],\n",
      "          [-5.0083e-02,  3.9842e-02, -5.6772e-03]],\n",
      "\n",
      "         [[ 4.1632e-02, -1.9419e-02, -2.8952e-02],\n",
      "          [-3.5234e-02, -8.3134e-02, -5.3359e-02],\n",
      "          [ 4.2108e-02,  5.2958e-04,  3.8788e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-4.4148e-03, -7.4985e-02,  7.7011e-03],\n",
      "          [ 3.5427e-02, -3.5407e-02, -3.7110e-02],\n",
      "          [-1.2717e-02,  2.3533e-02,  6.9470e-02]],\n",
      "\n",
      "         [[ 3.7072e-02,  2.5766e-02, -2.3874e-03],\n",
      "          [-1.3431e-01, -6.0230e-02, -2.0589e-02],\n",
      "          [ 6.2705e-02,  3.5483e-02, -2.1147e-02]],\n",
      "\n",
      "         [[-2.7357e-02,  7.1685e-02,  3.9225e-02],\n",
      "          [ 1.7976e-02, -1.4323e-02,  4.8894e-02],\n",
      "          [ 1.8745e-02, -7.0066e-02,  2.5475e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.4041e-02, -1.8239e-02,  5.0908e-03],\n",
      "          [-8.8047e-02,  1.8366e-02,  5.1715e-02],\n",
      "          [ 3.4119e-02,  6.4129e-02,  4.9589e-04]],\n",
      "\n",
      "         [[-5.8233e-02, -5.9944e-02,  5.0578e-02],\n",
      "          [-9.9858e-03, -4.9715e-02, -1.1298e-02],\n",
      "          [ 3.5327e-02,  1.4299e-02, -2.7085e-02]],\n",
      "\n",
      "         [[ 2.0513e-02, -2.3705e-02, -2.1041e-02],\n",
      "          [-2.8811e-02, -9.1224e-03, -1.0389e-03],\n",
      "          [-1.3296e-02, -1.0554e-02, -8.2467e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 9.9286e-02, -8.9921e-02, -4.1126e-02],\n",
      "          [-1.2654e-01, -2.5491e-01, -1.2792e-01],\n",
      "          [-1.6742e-02, -7.4179e-02,  1.4320e-03]],\n",
      "\n",
      "         [[-5.9615e-02, -2.6896e-02,  9.7460e-03],\n",
      "          [-1.1745e-01, -1.6604e-01, -5.3404e-03],\n",
      "          [-8.0150e-02, -2.4282e-02, -6.7652e-02]],\n",
      "\n",
      "         [[-1.1163e-02,  5.9558e-02,  5.9718e-02],\n",
      "          [ 5.1017e-02,  6.3756e-02, -5.3483e-02],\n",
      "          [ 4.4005e-02,  1.7848e-02, -1.0970e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-8.0051e-02, -1.3479e-01, -7.5940e-02],\n",
      "          [-9.5929e-02, -9.9402e-02, -8.5210e-02],\n",
      "          [-1.8015e-02, -4.4436e-02, -1.3363e-01]],\n",
      "\n",
      "         [[-1.1842e-01, -1.5501e-02,  6.1068e-02],\n",
      "          [-1.3669e-01, -1.1277e-01, -9.2625e-02],\n",
      "          [-1.5046e-02, -1.7151e-01, -1.1016e-01]],\n",
      "\n",
      "         [[ 6.2587e-02,  2.5099e-02,  4.5224e-02],\n",
      "          [-7.4363e-02, -6.8104e-02, -4.4279e-02],\n",
      "          [-5.0195e-02,  1.2411e-01,  1.0693e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.7019e-02,  3.6244e-02, -2.4970e-02],\n",
      "          [-1.6629e-02, -1.3241e-01,  2.1616e-02],\n",
      "          [-1.8675e-03, -5.7754e-02, -3.9573e-03]],\n",
      "\n",
      "         [[ 6.6335e-03, -1.2923e-02, -9.8150e-02],\n",
      "          [ 2.0593e-02,  2.0558e-02,  3.7603e-02],\n",
      "          [ 1.0594e-02,  1.1451e-02,  7.0313e-02]],\n",
      "\n",
      "         [[-9.5791e-02, -5.2355e-02,  1.6809e-02],\n",
      "          [ 3.4763e-02, -4.4702e-03, -8.1226e-02],\n",
      "          [ 2.4538e-02, -3.7677e-02, -5.4773e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.0308e-01, -8.2294e-02, -8.5668e-02],\n",
      "          [-1.7273e-01, -5.7105e-02, -5.4554e-02],\n",
      "          [-9.0487e-02, -2.1198e-02, -9.7206e-02]],\n",
      "\n",
      "         [[ 5.0543e-02,  5.2110e-02, -4.7654e-02],\n",
      "          [ 4.2561e-02, -6.4905e-02, -7.3444e-02],\n",
      "          [-7.3544e-03,  3.2311e-02, -3.0047e-02]],\n",
      "\n",
      "         [[ 1.9117e-02,  6.8369e-02, -5.5112e-03],\n",
      "          [-4.9083e-02, -1.2926e-02, -5.4084e-02],\n",
      "          [-1.6462e-02,  5.2059e-02,  3.5358e-04]]]], requires_grad=True)\n",
      "--------------------\n",
      "name: encoder.layers.0.extractor.2.bias\n",
      "values: \n",
      "Parameter containing:\n",
      "tensor([-2.9403e-02,  7.8617e-02, -2.7439e-03,  2.5228e-02, -2.6120e-02,\n",
      "        -1.2079e-03,  3.8186e-04,  3.8475e-02, -5.0139e-02,  6.4816e-02,\n",
      "        -5.2401e-02,  2.0799e-02, -3.0709e-02, -6.7222e-02, -7.0350e-02,\n",
      "        -7.7295e-06, -3.8175e-02,  7.1992e-04, -6.1430e-03, -6.0822e-02,\n",
      "         8.1671e-02, -2.2930e-02,  1.9579e-02,  8.2765e-02, -1.0567e-02,\n",
      "         8.4336e-05, -2.4757e-02, -3.0521e-02, -3.4860e-02, -1.8470e-02,\n",
      "         3.3427e-02,  1.7576e-02, -6.3224e-02,  8.5820e-02,  2.3212e-02,\n",
      "        -1.7547e-02, -2.2904e-02,  7.7124e-02, -3.3160e-02, -3.1906e-02,\n",
      "         5.5915e-02,  4.5131e-02, -7.7984e-03, -9.4261e-02, -1.5217e-02,\n",
      "         6.4488e-02,  4.0563e-02,  2.5944e-02, -2.5584e-02, -6.8374e-03,\n",
      "        -2.5299e-03,  1.3628e-02, -5.3868e-02,  6.1552e-02, -4.3187e-02,\n",
      "         8.5456e-03,  5.9370e-02, -1.6871e-02, -9.3313e-03,  2.6919e-02,\n",
      "         9.3274e-05, -7.1390e-03, -4.3870e-02,  1.0748e-01],\n",
      "       requires_grad=True)\n",
      "--------------------\n",
      "name: encoder.layers.0.extractor.5.weight\n",
      "values: \n",
      "Parameter containing:\n",
      "tensor([[[[-5.0545e-02, -4.2687e-02,  5.1273e-02],\n",
      "          [-3.2933e-02,  7.4797e-02,  4.7797e-02],\n",
      "          [-1.9435e-02, -2.2188e-03, -8.4741e-02]],\n",
      "\n",
      "         [[-1.1835e-02, -2.3471e-02,  1.0002e-01],\n",
      "          [-1.9916e-02, -1.7116e-02,  2.7697e-02],\n",
      "          [-5.6281e-02, -3.9423e-02,  2.5349e-02]],\n",
      "\n",
      "         [[-1.6395e-02,  2.2944e-02, -3.6794e-02],\n",
      "          [-2.8609e-02, -1.8862e-02, -7.0042e-02],\n",
      "          [ 3.7275e-03,  1.5757e-02,  4.1731e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 8.3960e-02,  3.9969e-03,  5.3707e-02],\n",
      "          [-8.2672e-02,  2.0658e-02, -1.5808e-02],\n",
      "          [-4.6064e-02,  4.2825e-02, -1.5722e-02]],\n",
      "\n",
      "         [[-9.8129e-02,  3.7458e-02, -8.8269e-02],\n",
      "          [ 1.6825e-02, -5.0356e-02, -7.5497e-02],\n",
      "          [-5.0783e-02, -1.2655e-01,  8.2865e-03]],\n",
      "\n",
      "         [[ 7.2946e-02, -1.7913e-02, -2.0795e-02],\n",
      "          [ 1.9215e-02, -1.8059e-02, -4.6325e-02],\n",
      "          [ 5.5026e-02,  4.2021e-02,  2.9616e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.6476e-02,  5.7705e-02,  9.2990e-02],\n",
      "          [-1.6598e-02,  2.6875e-02,  5.2177e-02],\n",
      "          [-6.5628e-02,  6.0514e-02, -2.2200e-03]],\n",
      "\n",
      "         [[ 8.5965e-02, -4.1840e-02, -4.9287e-02],\n",
      "          [ 2.2198e-02,  6.8771e-02, -7.8823e-02],\n",
      "          [-8.1770e-03,  1.5194e-05, -1.1139e-01]],\n",
      "\n",
      "         [[-9.9181e-02, -8.0288e-02, -8.4253e-02],\n",
      "          [ 5.6296e-02,  3.1064e-02, -1.6451e-03],\n",
      "          [ 7.8103e-02, -1.3427e-02, -5.8244e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.9762e-02,  9.9361e-03, -1.0268e-02],\n",
      "          [ 2.1208e-02,  2.0086e-02, -2.2971e-02],\n",
      "          [ 2.4081e-02,  6.3125e-03, -1.5721e-02]],\n",
      "\n",
      "         [[-2.2583e-02, -3.4537e-02, -1.8533e-02],\n",
      "          [-9.6415e-02, -8.7783e-02, -1.7805e-01],\n",
      "          [-9.0800e-02, -1.5971e-01, -2.4805e-01]],\n",
      "\n",
      "         [[ 1.6918e-02,  2.0207e-02, -5.6368e-02],\n",
      "          [-1.7410e-02,  4.1048e-03,  3.4989e-02],\n",
      "          [-1.7755e-02,  9.1773e-03, -4.9214e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.0070e-02, -6.2148e-02,  2.3319e-02],\n",
      "          [-1.4080e-02, -5.3775e-02, -2.2658e-02],\n",
      "          [ 2.7713e-02, -3.2121e-03, -9.7849e-02]],\n",
      "\n",
      "         [[ 1.4091e-03,  4.7732e-02, -6.2281e-03],\n",
      "          [ 6.4190e-02,  5.1803e-02, -5.7863e-02],\n",
      "          [-5.1184e-02, -8.1060e-02, -1.8408e-03]],\n",
      "\n",
      "         [[-2.2856e-02, -4.3128e-02,  3.8998e-03],\n",
      "          [-2.5849e-02, -4.6155e-02,  5.9515e-02],\n",
      "          [ 1.9261e-03,  1.9071e-02, -3.3411e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.9378e-03, -1.7988e-02, -7.1588e-02],\n",
      "          [ 3.6241e-02, -1.0508e-03,  5.6266e-02],\n",
      "          [ 5.8606e-02,  2.9274e-02, -2.6740e-03]],\n",
      "\n",
      "         [[ 4.6077e-02,  7.6515e-02, -5.5916e-02],\n",
      "          [-1.1141e-01,  3.7338e-02, -2.8776e-02],\n",
      "          [-8.1532e-02, -6.5129e-03, -3.4780e-04]],\n",
      "\n",
      "         [[-1.7793e-03, -5.9122e-02,  4.1103e-02],\n",
      "          [-3.1576e-02,  1.6357e-02,  5.6557e-02],\n",
      "          [ 2.3047e-02,  1.8782e-02,  3.4210e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.1932e-01, -1.1786e-01, -7.2232e-02],\n",
      "          [-7.7194e-02,  2.0538e-02,  1.2949e-01],\n",
      "          [ 3.7826e-02,  7.2126e-02,  8.9527e-02]],\n",
      "\n",
      "         [[ 3.5921e-02, -7.1327e-02,  1.8056e-03],\n",
      "          [ 7.3740e-02,  9.7002e-02,  7.3462e-02],\n",
      "          [ 2.4056e-02, -9.5788e-02, -1.0698e-01]],\n",
      "\n",
      "         [[ 2.4938e-02,  2.9341e-02, -1.6644e-02],\n",
      "          [ 1.1418e-02, -1.2286e-02, -8.9130e-02],\n",
      "          [-2.4036e-02,  5.3005e-02,  2.9637e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.4444e-02, -3.0090e-02,  4.5579e-02],\n",
      "          [-2.6511e-02,  2.0865e-02, -1.6954e-02],\n",
      "          [ 2.4828e-02, -2.7822e-02,  5.8626e-02]],\n",
      "\n",
      "         [[ 2.0333e-02,  8.0099e-02,  1.1260e-02],\n",
      "          [ 4.4625e-02, -8.1173e-02, -1.1523e-02],\n",
      "          [-1.3446e-02, -1.0126e-01, -7.6138e-03]],\n",
      "\n",
      "         [[ 2.2396e-02,  1.9752e-01,  1.1953e-01],\n",
      "          [ 2.8538e-02, -3.4641e-02, -1.6386e-01],\n",
      "          [-1.2887e-01, -1.3271e-01, -2.4105e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2026e-01, -8.8375e-03, -1.0642e-01],\n",
      "          [ 2.4141e-02, -6.0262e-02, -1.2920e-02],\n",
      "          [-3.4721e-02, -6.0762e-02,  4.2703e-02]],\n",
      "\n",
      "         [[ 9.8867e-02,  3.4054e-03, -1.1921e-02],\n",
      "          [ 6.0167e-02,  1.7588e-02,  2.0198e-02],\n",
      "          [ 7.1420e-02,  3.2366e-02,  1.0017e-01]],\n",
      "\n",
      "         [[ 2.9596e-02,  1.6925e-02, -1.1568e-02],\n",
      "          [-8.4677e-02, -4.3222e-02, -7.6203e-02],\n",
      "          [ 8.3388e-03, -5.4421e-02, -9.2349e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.7712e-03, -1.1681e-02, -3.3095e-02],\n",
      "          [ 9.1963e-02,  3.3349e-02,  9.8339e-02],\n",
      "          [-3.3236e-03, -1.0629e-02,  1.8967e-02]],\n",
      "\n",
      "         [[-2.1814e-02,  2.2139e-03,  6.8682e-02],\n",
      "          [-3.3634e-02, -6.2926e-02, -3.1129e-02],\n",
      "          [ 2.4003e-02,  4.1759e-02,  7.5417e-02]],\n",
      "\n",
      "         [[-7.1238e-02,  5.2519e-02,  1.0372e-01],\n",
      "          [-7.4304e-02, -8.3508e-02,  2.5766e-01],\n",
      "          [-2.4990e-02, -5.8073e-02,  1.4928e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 8.9103e-03, -2.2049e-03,  7.5359e-03],\n",
      "          [-5.8747e-04,  2.3098e-02,  3.3009e-02],\n",
      "          [ 4.6732e-02, -5.6485e-02, -1.1198e-01]],\n",
      "\n",
      "         [[ 2.9350e-02,  3.9901e-04,  6.7314e-03],\n",
      "          [ 1.1015e-01,  1.6409e-02, -5.3309e-02],\n",
      "          [ 2.7595e-02,  1.0239e-01, -1.7233e-03]],\n",
      "\n",
      "         [[-1.2902e-01, -8.1402e-02,  1.7180e-02],\n",
      "          [-5.7906e-02, -5.3717e-02, -5.0887e-02],\n",
      "          [ 6.0911e-02,  2.7722e-02,  8.2664e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.7994e-02, -1.6440e-02, -5.9350e-03],\n",
      "          [ 3.7045e-02,  4.6856e-03, -1.1024e-02],\n",
      "          [ 6.5701e-02, -3.5151e-02, -1.2551e-02]],\n",
      "\n",
      "         [[ 1.1813e-01, -3.6651e-02, -1.7934e-01],\n",
      "          [ 6.7250e-02, -1.4718e-02, -1.9403e-01],\n",
      "          [-1.3321e-02,  3.4839e-02,  1.6006e-02]],\n",
      "\n",
      "         [[ 6.0687e-02,  2.2921e-03, -6.4623e-02],\n",
      "          [ 1.8335e-02, -1.2698e-02,  1.3101e-02],\n",
      "          [ 9.0842e-02, -1.4163e-02, -2.1332e-02]]]])\n",
      "--------------------\n",
      "name: encoder.layers.0.extractor.5.bias\n",
      "values: \n",
      "Parameter containing:\n",
      "tensor([ 0.0782,  0.0631,  0.0651, -0.0811,  0.1018,  0.1702, -0.0733, -0.0464,\n",
      "         0.0061, -0.0237, -0.0040,  0.0159,  0.0701,  0.0773,  0.0344,  0.1049,\n",
      "         0.0812,  0.0908,  0.0561,  0.0375,  0.1074,  0.0045, -0.0670,  0.0665,\n",
      "         0.0484, -0.0058, -0.0294, -0.0039, -0.0483, -0.0420, -0.0929,  0.0393,\n",
      "         0.0325,  0.0394, -0.0591,  0.0154,  0.0786, -0.0041, -0.0093,  0.0424,\n",
      "         0.0346, -0.0592,  0.0213, -0.0480,  0.0139,  0.0575,  0.0096,  0.0474,\n",
      "         0.0098,  0.1327,  0.0867,  0.0157,  0.0304,  0.0016,  0.0368,  0.0682,\n",
      "        -0.0432, -0.0297,  0.0222,  0.0397,  0.0993,  0.0071, -0.0349, -0.0319,\n",
      "        -0.0287, -0.0430,  0.0689, -0.0102,  0.0955, -0.0348,  0.0151,  0.0444,\n",
      "        -0.1112,  0.0834, -0.1198,  0.0205, -0.0917,  0.0312, -0.1262,  0.0083,\n",
      "        -0.0482, -0.0655,  0.0725, -0.0599,  0.0487,  0.0055, -0.0350,  0.0809,\n",
      "        -0.1091, -0.0179, -0.0089,  0.0368,  0.0637,  0.0289, -0.0803,  0.0604,\n",
      "        -0.0072,  0.0713,  0.0059,  0.0555,  0.0483,  0.0064,  0.0442,  0.0527,\n",
      "         0.1273, -0.0683, -0.0601,  0.0773,  0.0065,  0.0131, -0.0248, -0.1278,\n",
      "         0.0789, -0.0294,  0.0101,  0.0798,  0.0152, -0.0081,  0.1003,  0.0168,\n",
      "         0.1404, -0.0227, -0.0551,  0.0367, -0.0772, -0.0600,  0.1126, -0.1210])\n",
      "--------------------\n",
      "name: encoder.layers.0.extractor.7.weight\n",
      "values: \n",
      "Parameter containing:\n",
      "tensor([[[[ 0.0196, -0.0548,  0.0035],\n",
      "          [-0.0422, -0.0993, -0.0628],\n",
      "          [-0.0918, -0.0283,  0.0382]],\n",
      "\n",
      "         [[ 0.0700, -0.0904, -0.0791],\n",
      "          [-0.0911, -0.1288, -0.1160],\n",
      "          [-0.0930, -0.1180, -0.0858]],\n",
      "\n",
      "         [[-0.0366, -0.0564, -0.0805],\n",
      "          [-0.1149, -0.1757, -0.0874],\n",
      "          [-0.0406, -0.0030,  0.0896]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0449, -0.0176, -0.0177],\n",
      "          [ 0.0147, -0.0498, -0.0328],\n",
      "          [-0.1099, -0.0311, -0.0864]],\n",
      "\n",
      "         [[-0.1018, -0.1088,  0.0191],\n",
      "          [-0.0437, -0.0563,  0.0516],\n",
      "          [ 0.0298,  0.0072, -0.0074]],\n",
      "\n",
      "         [[ 0.0398,  0.0761,  0.0426],\n",
      "          [ 0.0309,  0.0045, -0.0294],\n",
      "          [-0.1748, -0.0838, -0.0864]]],\n",
      "\n",
      "\n",
      "        [[[-0.0321, -0.1255, -0.0543],\n",
      "          [-0.0480, -0.1551, -0.0991],\n",
      "          [-0.0730, -0.0669, -0.0395]],\n",
      "\n",
      "         [[-0.0293, -0.1336, -0.1054],\n",
      "          [ 0.0310, -0.0004, -0.0824],\n",
      "          [-0.0451, -0.0190,  0.0464]],\n",
      "\n",
      "         [[-0.0709,  0.0372,  0.0558],\n",
      "          [-0.0259, -0.1084, -0.0254],\n",
      "          [ 0.0748, -0.0511, -0.0336]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0507,  0.0061,  0.0559],\n",
      "          [-0.0358, -0.0313, -0.0566],\n",
      "          [-0.0799, -0.0027, -0.0356]],\n",
      "\n",
      "         [[ 0.0630, -0.0109, -0.0254],\n",
      "          [ 0.0850,  0.0820,  0.0121],\n",
      "          [ 0.0563,  0.0387,  0.0466]],\n",
      "\n",
      "         [[-0.0994, -0.1286, -0.0245],\n",
      "          [-0.0048, -0.0720, -0.1316],\n",
      "          [ 0.1033, -0.0934, -0.0465]]],\n",
      "\n",
      "\n",
      "        [[[-0.1700, -0.1874, -0.0699],\n",
      "          [-0.0985, -0.0710,  0.0622],\n",
      "          [-0.0823,  0.0141,  0.1145]],\n",
      "\n",
      "         [[-0.0660, -0.0316, -0.0045],\n",
      "          [-0.0199, -0.0106,  0.0246],\n",
      "          [-0.0206, -0.0172,  0.0310]],\n",
      "\n",
      "         [[-0.0245,  0.0319, -0.0880],\n",
      "          [-0.0213, -0.0827, -0.0378],\n",
      "          [-0.0253, -0.0855,  0.0144]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0316, -0.0558, -0.0464],\n",
      "          [-0.1025, -0.0112, -0.0506],\n",
      "          [ 0.0188,  0.0661,  0.0458]],\n",
      "\n",
      "         [[ 0.0515,  0.0409, -0.0085],\n",
      "          [ 0.0182,  0.0112,  0.0126],\n",
      "          [ 0.1316,  0.0732, -0.0195]],\n",
      "\n",
      "         [[ 0.0080, -0.0781, -0.0654],\n",
      "          [ 0.0331, -0.0062, -0.0702],\n",
      "          [-0.0507, -0.0952, -0.0473]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0099, -0.0892, -0.1147],\n",
      "          [-0.0466, -0.0659, -0.0307],\n",
      "          [ 0.0027,  0.0618,  0.0952]],\n",
      "\n",
      "         [[-0.0356, -0.0218,  0.0190],\n",
      "          [ 0.0449, -0.0284, -0.0590],\n",
      "          [-0.0035,  0.0877,  0.0305]],\n",
      "\n",
      "         [[-0.0460,  0.0118, -0.0132],\n",
      "          [-0.0232,  0.0413,  0.0698],\n",
      "          [ 0.0577, -0.0450,  0.0023]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1315, -0.0906, -0.0234],\n",
      "          [ 0.0766, -0.0699, -0.0554],\n",
      "          [-0.0403, -0.0216, -0.0058]],\n",
      "\n",
      "         [[-0.0259,  0.0018, -0.0216],\n",
      "          [-0.0064, -0.0054, -0.0253],\n",
      "          [-0.0139,  0.0095, -0.0368]],\n",
      "\n",
      "         [[ 0.0406,  0.0311,  0.0174],\n",
      "          [-0.0766, -0.0965, -0.0223],\n",
      "          [-0.0168, -0.0205, -0.0570]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0613,  0.0445,  0.0392],\n",
      "          [ 0.0372, -0.0033,  0.0004],\n",
      "          [ 0.0092, -0.0670, -0.0565]],\n",
      "\n",
      "         [[ 0.0139,  0.0037,  0.0486],\n",
      "          [-0.0752, -0.0046,  0.0163],\n",
      "          [ 0.0300,  0.0350, -0.0291]],\n",
      "\n",
      "         [[-0.0408, -0.1048, -0.0043],\n",
      "          [ 0.0087, -0.0754,  0.0067],\n",
      "          [ 0.0281,  0.0027,  0.0055]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0371,  0.1584,  0.0387],\n",
      "          [ 0.0391, -0.0100, -0.0502],\n",
      "          [-0.0838,  0.0394,  0.1562]],\n",
      "\n",
      "         [[ 0.0253, -0.1563, -0.1380],\n",
      "          [-0.1123, -0.0362, -0.1258],\n",
      "          [-0.1540, -0.0474, -0.1205]],\n",
      "\n",
      "         [[ 0.0305, -0.0392,  0.0035],\n",
      "          [ 0.0310,  0.0309, -0.0381],\n",
      "          [-0.0395, -0.0298, -0.1384]]],\n",
      "\n",
      "\n",
      "        [[[-0.0056, -0.0411, -0.0341],\n",
      "          [-0.1231, -0.0021, -0.0182],\n",
      "          [-0.1297, -0.0487,  0.0940]],\n",
      "\n",
      "         [[ 0.0609, -0.0303, -0.0798],\n",
      "          [-0.0343, -0.1192, -0.0230],\n",
      "          [ 0.0354, -0.0530, -0.0034]],\n",
      "\n",
      "         [[ 0.0354,  0.0563,  0.0275],\n",
      "          [ 0.0132, -0.0491,  0.0422],\n",
      "          [ 0.0862,  0.0179,  0.0147]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0948, -0.1063, -0.0456],\n",
      "          [ 0.0095, -0.0057, -0.0312],\n",
      "          [ 0.0736, -0.0581, -0.0132]],\n",
      "\n",
      "         [[-0.0043, -0.0393,  0.0220],\n",
      "          [ 0.0272,  0.0090,  0.0542],\n",
      "          [ 0.0105,  0.0197,  0.0214]],\n",
      "\n",
      "         [[ 0.0233, -0.0575, -0.0702],\n",
      "          [-0.0115, -0.0518, -0.0157],\n",
      "          [-0.0944,  0.0205, -0.0209]]]])\n",
      "--------------------\n",
      "name: encoder.layers.0.extractor.7.bias\n",
      "values: \n",
      "Parameter containing:\n",
      "tensor([-8.1134e-02, -6.2830e-02,  5.1033e-02, -1.4329e-01, -7.8563e-02,\n",
      "         1.2196e-01, -2.1151e-03,  3.0322e-02,  1.8543e-02,  3.0360e-02,\n",
      "         8.6198e-02,  3.3976e-02, -5.4198e-03,  4.0955e-02,  2.0489e-02,\n",
      "         1.3909e-02,  4.5068e-02, -4.5739e-02, -4.0507e-02, -2.8458e-02,\n",
      "         3.0472e-02, -5.0013e-03, -1.0708e-02,  1.9486e-02,  1.2234e-02,\n",
      "         8.9270e-02,  1.5192e-02,  2.5187e-02,  5.8755e-02,  3.8887e-02,\n",
      "        -6.7796e-02, -4.2889e-02,  7.1350e-02,  2.6187e-02, -7.0299e-04,\n",
      "        -2.1334e-02, -5.2276e-02,  6.0530e-02, -6.0678e-02, -2.9742e-02,\n",
      "        -8.1582e-03, -4.4150e-02, -1.0477e-01, -1.0066e-02, -1.1235e-01,\n",
      "         4.4266e-02,  5.5793e-02, -3.2475e-02, -2.8075e-02, -1.8822e-02,\n",
      "         1.3519e-03,  5.2775e-02, -5.5986e-04, -6.1514e-02, -1.4036e-02,\n",
      "         1.2085e-04,  4.3371e-03,  5.6066e-03, -4.9283e-02,  2.6140e-02,\n",
      "        -8.7312e-03,  4.6196e-02, -2.7135e-02, -4.6098e-02,  1.9016e-02,\n",
      "        -1.9943e-02, -1.9164e-02, -5.2404e-02, -2.7169e-02,  5.6356e-02,\n",
      "         3.2872e-02, -3.9397e-02, -4.9376e-02, -8.8224e-02, -6.5956e-02,\n",
      "        -2.9978e-02,  9.8345e-02,  5.2118e-02,  1.5574e-02, -6.0764e-04,\n",
      "         4.5566e-02, -3.0219e-02, -7.8211e-03,  2.9160e-02, -4.8352e-02,\n",
      "         7.2175e-02,  1.5437e-02,  1.0221e-03, -2.3441e-03, -2.0912e-02,\n",
      "         5.4926e-02,  3.0561e-03, -4.8955e-02,  7.0857e-02, -6.6103e-03,\n",
      "        -4.0275e-02, -5.8869e-02,  1.1290e-01,  8.0273e-02,  8.6274e-02,\n",
      "        -1.1873e-02,  2.1245e-02,  4.2219e-02, -1.2381e-01, -2.5709e-02,\n",
      "        -1.6292e-02,  3.0712e-02,  1.7607e-03,  1.7817e-02,  1.4947e-02,\n",
      "         6.0763e-02,  6.9300e-02, -1.2298e-02, -4.9907e-02, -8.8531e-02,\n",
      "        -2.7013e-02, -8.2085e-03,  1.5707e-02, -7.4746e-04, -1.4148e-02,\n",
      "        -1.1796e-02,  9.5542e-03,  3.4460e-02,  1.6550e-02,  5.6167e-02,\n",
      "        -3.8286e-02, -5.1196e-02,  1.0957e-02])\n",
      "--------------------\n",
      "name: encoder.layers.1.layer.weight_ih_l0\n",
      "values: \n",
      "Parameter containing:\n",
      "tensor([[-0.0476,  0.0015,  0.0257,  ..., -0.0680,  0.0312,  0.0318],\n",
      "        [ 0.0545,  0.0006,  0.0021,  ..., -0.0359,  0.0024, -0.0449],\n",
      "        [ 0.0228,  0.0657, -0.0004,  ..., -0.0313,  0.0008, -0.0227],\n",
      "        ...,\n",
      "        [-0.0625,  0.0180, -0.0325,  ...,  0.0737, -0.0072,  0.0231],\n",
      "        [ 0.0266,  0.0161,  0.0272,  ...,  0.0233, -0.0162, -0.0880],\n",
      "        [ 0.0388, -0.0396, -0.0303,  ..., -0.0249,  0.0025, -0.0215]])\n",
      "--------------------\n",
      "name: encoder.layers.1.layer.weight_hh_l0\n",
      "values: \n",
      "Parameter containing:\n",
      "tensor([[-0.0693, -0.0558, -0.0233,  ...,  0.0190, -0.0150,  0.0126],\n",
      "        [-0.0352,  0.0272,  0.0127,  ...,  0.0020, -0.0077,  0.0017],\n",
      "        [ 0.0279, -0.0847,  0.0629,  ..., -0.0069, -0.0029, -0.0087],\n",
      "        ...,\n",
      "        [ 0.0332,  0.0342,  0.0295,  ...,  0.0247,  0.0187, -0.0271],\n",
      "        [ 0.0280, -0.0085,  0.0266,  ...,  0.0306,  0.0202, -0.0193],\n",
      "        [-0.0097, -0.0110, -0.0030,  ...,  0.0277,  0.0126, -0.0430]])\n",
      "--------------------\n",
      "name: encoder.layers.1.layer.bias_ih_l0\n",
      "values: \n",
      "Parameter containing:\n",
      "tensor([-0.0326,  0.0073,  0.0195,  ..., -0.0192, -0.0001, -0.0031])\n",
      "--------------------\n",
      "name: encoder.layers.1.layer.bias_hh_l0\n",
      "values: \n",
      "Parameter containing:\n",
      "tensor([-0.0326,  0.0073,  0.0195,  ..., -0.0192, -0.0001, -0.0031])\n",
      "--------------------\n",
      "name: encoder.layers.1.layer.weight_ih_l0_reverse\n",
      "values: \n",
      "Parameter containing:\n",
      "tensor([[ 0.0191, -0.0160, -0.0291,  ...,  0.0806, -0.0033,  0.0750],\n",
      "        [ 0.0270,  0.0554, -0.0331,  ...,  0.0045,  0.0255,  0.1144],\n",
      "        [ 0.0118, -0.0415, -0.0304,  ..., -0.0156,  0.0069,  0.0056],\n",
      "        ...,\n",
      "        [ 0.0100,  0.0592,  0.0382,  ...,  0.0244,  0.0281,  0.0316],\n",
      "        [ 0.0213, -0.0303,  0.0073,  ...,  0.0165, -0.0139,  0.0008],\n",
      "        [ 0.0018,  0.0180, -0.0133,  ..., -0.0752,  0.0088,  0.0534]])\n",
      "--------------------\n",
      "name: encoder.layers.1.layer.weight_hh_l0_reverse\n",
      "values: \n",
      "Parameter containing:\n",
      "tensor([[ 0.0039,  0.0266,  0.0200,  ...,  0.0402, -0.0037,  0.0126],\n",
      "        [ 0.0670,  0.0145,  0.0015,  ..., -0.0196, -0.0259, -0.0161],\n",
      "        [-0.0381,  0.0136, -0.0386,  ...,  0.0278,  0.0578,  0.0071],\n",
      "        ...,\n",
      "        [-0.0034, -0.0596, -0.0131,  ...,  0.0509, -0.0264,  0.0237],\n",
      "        [ 0.0189,  0.0243,  0.0341,  ..., -0.0142, -0.0034,  0.0430],\n",
      "        [-0.0647, -0.1007,  0.0077,  ...,  0.0267,  0.0076, -0.0011]])\n",
      "--------------------\n",
      "name: encoder.layers.1.layer.bias_ih_l0_reverse\n",
      "values: \n",
      "Parameter containing:\n",
      "tensor([ 0.0089, -0.0181, -0.0138,  ..., -0.0104,  0.0131, -0.0397])\n",
      "--------------------\n",
      "name: encoder.layers.1.layer.bias_hh_l0_reverse\n",
      "values: \n",
      "Parameter containing:\n",
      "tensor([ 0.0089, -0.0181, -0.0138,  ..., -0.0104,  0.0131, -0.0397])\n",
      "--------------------\n",
      "name: encoder.layers.1.pj.weight\n",
      "values: \n",
      "Parameter containing:\n",
      "tensor([[ 0.0727,  0.0286,  0.0028,  ...,  0.0080,  0.0116,  0.0742],\n",
      "        [-0.0634,  0.0425,  0.0031,  ...,  0.0671, -0.0027,  0.0159],\n",
      "        [ 0.0678, -0.0139, -0.0044,  ...,  0.0699,  0.0516, -0.0142],\n",
      "        ...,\n",
      "        [ 0.0267,  0.0136,  0.0190,  ...,  0.0171, -0.0696, -0.0062],\n",
      "        [ 0.0456,  0.0177, -0.0360,  ..., -0.0121, -0.0028,  0.0072],\n",
      "        [-0.0202, -0.0060,  0.0255,  ...,  0.0600, -0.0497, -0.0051]])\n",
      "--------------------\n",
      "name: encoder.layers.1.pj.bias\n",
      "values: \n",
      "Parameter containing:\n",
      "tensor([-0.0210, -0.0055,  0.0072,  ..., -0.0061, -0.0142,  0.0440])\n",
      "--------------------\n",
      "name: encoder.layers.2.layer.weight_ih_l0\n",
      "values: \n",
      "Parameter containing:\n",
      "tensor([[-0.0377, -0.0112,  0.0245,  ..., -0.0084,  0.0169,  0.0114],\n",
      "        [-0.0197, -0.0107,  0.0277,  ..., -0.0164,  0.0081, -0.0101],\n",
      "        [ 0.0343,  0.0417, -0.0300,  ...,  0.0164, -0.0154,  0.0360],\n",
      "        ...,\n",
      "        [-0.0033, -0.0172, -0.0231,  ...,  0.0547, -0.0226, -0.0184],\n",
      "        [ 0.0158, -0.0095,  0.0313,  ...,  0.0142,  0.0259, -0.0111],\n",
      "        [ 0.0154, -0.0284,  0.0325,  ..., -0.0078, -0.0254,  0.0176]])\n",
      "--------------------\n",
      "name: encoder.layers.2.layer.weight_hh_l0\n",
      "values: \n",
      "Parameter containing:\n",
      "tensor([[ 0.0108,  0.0034,  0.0090,  ...,  0.0015, -0.0095, -0.0049],\n",
      "        [ 0.0117, -0.0027, -0.0011,  ..., -0.0417, -0.0335,  0.0113],\n",
      "        [ 0.0223,  0.0099, -0.0668,  ...,  0.0171, -0.0061,  0.0144],\n",
      "        ...,\n",
      "        [-0.0095,  0.0046,  0.0608,  ..., -0.0196,  0.0304, -0.0194],\n",
      "        [ 0.0090,  0.0506, -0.0319,  ...,  0.0122,  0.0258, -0.0165],\n",
      "        [-0.0181, -0.0013, -0.0103,  ..., -0.0099,  0.0812,  0.0593]])\n",
      "--------------------\n",
      "name: encoder.layers.2.layer.bias_ih_l0\n",
      "values: \n",
      "Parameter containing:\n",
      "tensor([ 0.0215,  0.0041,  0.0143,  ...,  0.0035, -0.0190,  0.0066])\n",
      "--------------------\n",
      "name: encoder.layers.2.layer.bias_hh_l0\n",
      "values: \n",
      "Parameter containing:\n",
      "tensor([ 0.0215,  0.0041,  0.0143,  ...,  0.0035, -0.0190,  0.0066])\n",
      "--------------------\n",
      "name: encoder.layers.2.layer.weight_ih_l0_reverse\n",
      "values: \n",
      "Parameter containing:\n",
      "tensor([[ 4.2521e-02, -2.5630e-02, -1.6895e-05,  ...,  1.4645e-02,\n",
      "          1.0056e-02, -3.4334e-03],\n",
      "        [-2.2582e-02,  4.9438e-03,  2.2027e-02,  ..., -1.6404e-02,\n",
      "          3.0729e-03,  1.4686e-02],\n",
      "        [ 2.2672e-02,  5.8238e-02,  3.2599e-03,  ...,  4.2029e-02,\n",
      "          5.6509e-02, -1.1686e-02],\n",
      "        ...,\n",
      "        [-3.5218e-02, -2.2181e-02,  1.4650e-02,  ..., -3.7653e-03,\n",
      "          3.6925e-02,  6.5149e-02],\n",
      "        [-3.3174e-03, -1.4176e-02, -4.6390e-02,  ...,  3.7879e-02,\n",
      "          1.4585e-02,  6.7602e-03],\n",
      "        [ 2.9193e-02, -1.3405e-02,  2.0955e-02,  ...,  1.5417e-02,\n",
      "          5.7395e-03,  3.2734e-03]])\n",
      "--------------------\n",
      "name: encoder.layers.2.layer.weight_hh_l0_reverse\n",
      "values: \n",
      "Parameter containing:\n",
      "tensor([[ 0.0016,  0.0201, -0.0305,  ...,  0.0149, -0.0014, -0.0465],\n",
      "        [ 0.0253,  0.0418, -0.0405,  ...,  0.0433,  0.0062, -0.0138],\n",
      "        [-0.0072,  0.0133,  0.0558,  ...,  0.0139,  0.0524, -0.0519],\n",
      "        ...,\n",
      "        [-0.0557,  0.0572,  0.0029,  ..., -0.0045,  0.0358,  0.0848],\n",
      "        [ 0.0058,  0.0036,  0.0138,  ..., -0.0372, -0.0093,  0.0058],\n",
      "        [ 0.0174, -0.0116, -0.0038,  ...,  0.0117,  0.0197,  0.0206]])\n",
      "--------------------\n",
      "name: encoder.layers.2.layer.bias_ih_l0_reverse\n",
      "values: \n",
      "Parameter containing:\n",
      "tensor([ 0.0138,  0.0087, -0.0040,  ...,  0.0055,  0.0146,  0.0016])\n",
      "--------------------\n",
      "name: encoder.layers.2.layer.bias_hh_l0_reverse\n",
      "values: \n",
      "Parameter containing:\n",
      "tensor([ 0.0138,  0.0087, -0.0040,  ...,  0.0055,  0.0146,  0.0016])\n",
      "--------------------\n",
      "name: encoder.layers.2.pj.weight\n",
      "values: \n",
      "Parameter containing:\n",
      "tensor([[ 0.0172, -0.0271,  0.0440,  ...,  0.0543,  0.0131, -0.0270],\n",
      "        [ 0.0377, -0.0044,  0.0084,  ...,  0.0386, -0.0063, -0.0559],\n",
      "        [ 0.0168,  0.0174,  0.0124,  ..., -0.0092,  0.0228, -0.0549],\n",
      "        ...,\n",
      "        [-0.0042,  0.0329, -0.0509,  ..., -0.0541,  0.0235, -0.0459],\n",
      "        [-0.0010, -0.0059,  0.0560,  ...,  0.0468, -0.0113, -0.0217],\n",
      "        [ 0.0150, -0.0410, -0.0412,  ...,  0.0569, -0.0523,  0.0123]])\n",
      "--------------------\n",
      "name: encoder.layers.2.pj.bias\n",
      "values: \n",
      "Parameter containing:\n",
      "tensor([ 0.0074,  0.0127,  0.0159,  ..., -0.0339,  0.0461,  0.0079])\n",
      "--------------------\n",
      "name: encoder.layers.3.layer.weight_ih_l0\n",
      "values: \n",
      "Parameter containing:\n",
      "tensor([[ 0.0182, -0.0200, -0.0047,  ...,  0.0242, -0.0304,  0.0298],\n",
      "        [-0.0038,  0.0385, -0.0548,  ..., -0.0327, -0.0002, -0.0217],\n",
      "        [ 0.0009, -0.0490, -0.0052,  ..., -0.0091, -0.0278,  0.0415],\n",
      "        ...,\n",
      "        [-0.0366,  0.0459, -0.0389,  ...,  0.0026, -0.0361,  0.0318],\n",
      "        [-0.0257, -0.0476,  0.0059,  ..., -0.0064,  0.0437, -0.0192],\n",
      "        [-0.0148,  0.0133, -0.0243,  ...,  0.0361,  0.0348, -0.0265]])\n",
      "--------------------\n",
      "name: encoder.layers.3.layer.weight_hh_l0\n",
      "values: \n",
      "Parameter containing:\n",
      "tensor([[-0.0044, -0.0466, -0.0241,  ...,  0.0210, -0.0176, -0.0023],\n",
      "        [-0.0310,  0.0246, -0.0962,  ...,  0.0205,  0.0323,  0.0144],\n",
      "        [ 0.0226,  0.0258, -0.0165,  ..., -0.0221, -0.0332,  0.0010],\n",
      "        ...,\n",
      "        [ 0.0156,  0.0020, -0.0495,  ...,  0.0413,  0.0464, -0.0057],\n",
      "        [-0.0174,  0.0336,  0.0027,  ..., -0.0335, -0.0088,  0.0227],\n",
      "        [-0.0223,  0.0302,  0.0092,  ...,  0.0739, -0.0255,  0.0280]])\n",
      "--------------------\n",
      "name: encoder.layers.3.layer.bias_ih_l0\n",
      "values: \n",
      "Parameter containing:\n",
      "tensor([-0.0157,  0.0513,  0.0072,  ...,  0.0286, -0.0415,  0.0521])\n",
      "--------------------\n",
      "name: encoder.layers.3.layer.bias_hh_l0\n",
      "values: \n",
      "Parameter containing:\n",
      "tensor([-0.0157,  0.0513,  0.0072,  ...,  0.0286, -0.0415,  0.0521])\n",
      "--------------------\n",
      "name: encoder.layers.3.layer.weight_ih_l0_reverse\n",
      "values: \n",
      "Parameter containing:\n",
      "tensor([[ 0.0333,  0.0271, -0.0386,  ...,  0.0688,  0.0261, -0.0061],\n",
      "        [-0.0083,  0.0292,  0.0159,  ...,  0.0040, -0.0345,  0.0896],\n",
      "        [ 0.0159,  0.0231, -0.0040,  ...,  0.0066,  0.0152,  0.0297],\n",
      "        ...,\n",
      "        [-0.0210,  0.0046, -0.0273,  ..., -0.0252,  0.0167,  0.0277],\n",
      "        [ 0.0388,  0.0052, -0.0036,  ...,  0.0361,  0.0043,  0.0194],\n",
      "        [-0.0295,  0.0179,  0.0543,  ...,  0.0233, -0.0588,  0.0098]])\n",
      "--------------------\n",
      "name: encoder.layers.3.layer.weight_hh_l0_reverse\n",
      "values: \n",
      "Parameter containing:\n",
      "tensor([[ 0.0066, -0.0036, -0.0572,  ...,  0.0025, -0.0038, -0.0337],\n",
      "        [-0.0316, -0.0152,  0.0322,  ...,  0.0390,  0.0407, -0.0097],\n",
      "        [-0.0216, -0.0343,  0.0246,  ..., -0.0354,  0.0380,  0.0562],\n",
      "        ...,\n",
      "        [ 0.0129, -0.0146, -0.0192,  ...,  0.0329,  0.0015,  0.0151],\n",
      "        [ 0.0326, -0.0209, -0.0286,  ..., -0.0112,  0.0174, -0.0025],\n",
      "        [ 0.0233, -0.0080, -0.0265,  ..., -0.0027,  0.0794,  0.0556]])\n",
      "--------------------\n",
      "name: encoder.layers.3.layer.bias_ih_l0_reverse\n",
      "values: \n",
      "Parameter containing:\n",
      "tensor([ 0.0055, -0.0139, -0.0199,  ..., -0.0120,  0.0072, -0.0145])\n",
      "--------------------\n",
      "name: encoder.layers.3.layer.bias_hh_l0_reverse\n",
      "values: \n",
      "Parameter containing:\n",
      "tensor([ 0.0055, -0.0139, -0.0199,  ..., -0.0120,  0.0072, -0.0145])\n",
      "--------------------\n",
      "name: encoder.layers.3.pj.weight\n",
      "values: \n",
      "Parameter containing:\n",
      "tensor([[-0.0078,  0.0565, -0.0224,  ..., -0.0247, -0.0207, -0.0400],\n",
      "        [ 0.0435, -0.0085, -0.0616,  ...,  0.0066,  0.0484,  0.0315],\n",
      "        [ 0.0080, -0.0649,  0.0044,  ...,  0.0301, -0.0371, -0.0208],\n",
      "        ...,\n",
      "        [ 0.0429,  0.0469, -0.0502,  ...,  0.0107, -0.0041,  0.0248],\n",
      "        [ 0.0104, -0.0070, -0.0334,  ..., -0.0120,  0.0131, -0.0187],\n",
      "        [-0.0038,  0.0211,  0.0061,  ..., -0.0192,  0.0025, -0.0173]])\n",
      "--------------------\n",
      "name: encoder.layers.3.pj.bias\n",
      "values: \n",
      "Parameter containing:\n",
      "tensor([-0.0394,  0.0005,  0.0162,  ...,  0.0124, -0.0444,  0.0132])\n",
      "--------------------\n",
      "name: encoder.layers.4.layer.weight_ih_l0\n",
      "values: \n",
      "Parameter containing:\n",
      "tensor([[ 0.0039,  0.0147,  0.0112,  ...,  0.0504, -0.0057,  0.0324],\n",
      "        [-0.0307,  0.0375,  0.0377,  ..., -0.0325,  0.0656,  0.0788],\n",
      "        [ 0.0242,  0.0022,  0.0427,  ...,  0.0071, -0.0314, -0.0438],\n",
      "        ...,\n",
      "        [ 0.0460,  0.0311,  0.0211,  ..., -0.0216,  0.0388,  0.0114],\n",
      "        [ 0.0213,  0.0055, -0.0465,  ..., -0.0018, -0.0121,  0.0040],\n",
      "        [ 0.0194,  0.0203,  0.0075,  ..., -0.0373, -0.0100,  0.0224]])\n",
      "--------------------\n",
      "name: encoder.layers.4.layer.weight_hh_l0\n",
      "values: \n",
      "Parameter containing:\n",
      "tensor([[ 0.0055,  0.0220, -0.0529,  ...,  0.0689,  0.0302, -0.0173],\n",
      "        [-0.0045, -0.0218,  0.0383,  ...,  0.0159,  0.0572,  0.0435],\n",
      "        [ 0.0141, -0.0279,  0.0040,  ..., -0.0600,  0.0073,  0.0083],\n",
      "        ...,\n",
      "        [ 0.0530, -0.0212,  0.0333,  ...,  0.0092,  0.0099, -0.0095],\n",
      "        [ 0.0376,  0.0008,  0.0208,  ...,  0.0075,  0.0214, -0.0633],\n",
      "        [ 0.0428,  0.0149, -0.0338,  ..., -0.0370,  0.0700,  0.0331]])\n",
      "--------------------\n",
      "name: encoder.layers.4.layer.bias_ih_l0\n",
      "values: \n",
      "Parameter containing:\n",
      "tensor([-0.0393, -0.0505, -0.0408,  ..., -0.0372, -0.0047, -0.0329])\n",
      "--------------------\n",
      "name: encoder.layers.4.layer.bias_hh_l0\n",
      "values: \n",
      "Parameter containing:\n",
      "tensor([-0.0393, -0.0505, -0.0408,  ..., -0.0372, -0.0047, -0.0329])\n",
      "--------------------\n",
      "name: encoder.layers.4.layer.weight_ih_l0_reverse\n",
      "values: \n",
      "Parameter containing:\n",
      "tensor([[-0.0094, -0.0625,  0.0237,  ..., -0.0200, -0.0372, -0.0295],\n",
      "        [-0.0012, -0.0158,  0.0244,  ..., -0.0011, -0.0263,  0.0241],\n",
      "        [ 0.0457,  0.0095,  0.0066,  ..., -0.0002,  0.0206, -0.0270],\n",
      "        ...,\n",
      "        [ 0.0137, -0.0560,  0.0030,  ...,  0.0609, -0.0296,  0.0153],\n",
      "        [-0.0445,  0.0385,  0.0347,  ..., -0.0269, -0.0310, -0.0141],\n",
      "        [ 0.0049,  0.0325, -0.0099,  ..., -0.0105, -0.0083, -0.0267]])\n",
      "--------------------\n",
      "name: encoder.layers.4.layer.weight_hh_l0_reverse\n",
      "values: \n",
      "Parameter containing:\n",
      "tensor([[-0.0858, -0.0643, -0.0295,  ...,  0.0181,  0.0083,  0.0133],\n",
      "        [ 0.0674,  0.0577, -0.0056,  ..., -0.0045, -0.0038, -0.0339],\n",
      "        [ 0.0062,  0.0356,  0.0407,  ...,  0.0033,  0.0023, -0.0181],\n",
      "        ...,\n",
      "        [ 0.0452,  0.0150,  0.0086,  ...,  0.0614, -0.0545, -0.0105],\n",
      "        [-0.0148, -0.0113,  0.0775,  ..., -0.0164, -0.0043,  0.0156],\n",
      "        [ 0.0180,  0.0148,  0.0628,  ...,  0.0321,  0.0032, -0.0505]])\n",
      "--------------------\n",
      "name: encoder.layers.4.layer.bias_ih_l0_reverse\n",
      "values: \n",
      "Parameter containing:\n",
      "tensor([-0.0180, -0.0345, -0.0347,  ..., -0.0096, -0.0555, -0.0359])\n",
      "--------------------\n",
      "name: encoder.layers.4.layer.bias_hh_l0_reverse\n",
      "values: \n",
      "Parameter containing:\n",
      "tensor([-0.0180, -0.0345, -0.0347,  ..., -0.0096, -0.0555, -0.0359])\n",
      "--------------------\n",
      "name: encoder.layers.4.pj.weight\n",
      "values: \n",
      "Parameter containing:\n",
      "tensor([[ 0.0654,  0.0123,  0.0054,  ..., -0.0128,  0.0676, -0.0351],\n",
      "        [-0.0005, -0.0052,  0.0044,  ..., -0.0220,  0.0298, -0.0492],\n",
      "        [ 0.0619,  0.0008,  0.0141,  ...,  0.0329,  0.0413, -0.0070],\n",
      "        ...,\n",
      "        [ 0.0054,  0.0425, -0.0049,  ...,  0.0902,  0.0409, -0.0160],\n",
      "        [ 0.0224,  0.0029,  0.0009,  ..., -0.0235,  0.0225,  0.0145],\n",
      "        [ 0.0387, -0.0199,  0.0052,  ...,  0.0600,  0.0146, -0.0158]])\n",
      "--------------------\n",
      "name: encoder.layers.4.pj.bias\n",
      "values: \n",
      "Parameter containing:\n",
      "tensor([-0.1355,  0.0474,  0.0168,  ..., -0.0407,  0.0131,  0.0471])\n",
      "--------------------\n",
      "name: pre_embed.weight\n",
      "values: \n",
      "Parameter containing:\n",
      "tensor([[ 0.0153, -0.0515,  0.0837,  ..., -0.0930, -0.0896, -0.0437],\n",
      "        [-0.0092, -0.0053,  0.0008,  ...,  0.0027, -0.0257,  0.0101],\n",
      "        [ 0.0439,  0.0411, -0.0539,  ...,  0.0305, -0.0500,  0.0232],\n",
      "        ...,\n",
      "        [-0.0154,  0.0309, -0.0128,  ..., -0.0054,  0.0090, -0.0117],\n",
      "        [ 0.0414,  0.0494,  0.0525,  ...,  0.0552,  0.0119,  0.0236],\n",
      "        [-0.0327, -0.0405, -0.0141,  ...,  0.0292,  0.0154, -0.0240]])\n",
      "--------------------\n",
      "name: decoder.layers.weight_ih_l0\n",
      "values: \n",
      "Parameter containing:\n",
      "tensor([[-0.0020, -0.0163,  0.0070,  ...,  0.0034,  0.0484,  0.0188],\n",
      "        [ 0.0017,  0.0156,  0.0172,  ...,  0.0106, -0.0008,  0.0015],\n",
      "        [-0.0145, -0.0135,  0.0018,  ...,  0.0204,  0.0067,  0.0448],\n",
      "        ...,\n",
      "        [-0.0352, -0.0104, -0.0320,  ...,  0.1018,  0.0288,  0.0341],\n",
      "        [ 0.0161, -0.0064,  0.0390,  ..., -0.0446,  0.0646,  0.0537],\n",
      "        [ 0.0009,  0.0009, -0.0657,  ...,  0.0442,  0.0256, -0.0516]])\n",
      "--------------------\n",
      "name: decoder.layers.weight_hh_l0\n",
      "values: \n",
      "Parameter containing:\n",
      "tensor([[-0.0147,  0.0121,  0.0262,  ...,  0.0244, -0.0277,  0.0078],\n",
      "        [-0.0422, -0.0108, -0.0288,  ...,  0.0068, -0.0535, -0.0037],\n",
      "        [ 0.0016, -0.0171, -0.0241,  ...,  0.0312, -0.0276,  0.0096],\n",
      "        ...,\n",
      "        [ 0.0706,  0.0232,  0.0057,  ...,  0.0118,  0.0483,  0.0786],\n",
      "        [ 0.0003, -0.0351,  0.0381,  ...,  0.0316,  0.0666, -0.0896],\n",
      "        [-0.0341, -0.0250,  0.0035,  ...,  0.0263,  0.0138,  0.0057]])\n",
      "--------------------\n",
      "name: decoder.layers.bias_ih_l0\n",
      "values: \n",
      "Parameter containing:\n",
      "tensor([0.0931, 0.0561, 0.0795,  ..., 0.0169, 0.0674, 0.0087])\n",
      "--------------------\n",
      "name: decoder.layers.bias_hh_l0\n",
      "values: \n",
      "Parameter containing:\n",
      "tensor([0.0931, 0.0561, 0.0795,  ..., 0.0169, 0.0674, 0.0087])\n",
      "--------------------\n",
      "name: decoder.layers.weight_ih_l1\n",
      "values: \n",
      "Parameter containing:\n",
      "tensor([[-0.0317,  0.0936, -0.0405,  ...,  0.0073, -0.0088,  0.0530],\n",
      "        [-0.0150, -0.0321, -0.0452,  ...,  0.0900, -0.0683,  0.0834],\n",
      "        [ 0.0377,  0.0431,  0.0561,  ...,  0.0402,  0.1470,  0.1009],\n",
      "        ...,\n",
      "        [-0.0305, -0.0101, -0.0351,  ..., -0.0004, -0.0904,  0.0032],\n",
      "        [ 0.0722,  0.0867,  0.0517,  ...,  0.1164, -0.0964, -0.0432],\n",
      "        [ 0.0677, -0.0563, -0.0593,  ..., -0.0555, -0.0797,  0.0089]])\n",
      "--------------------\n",
      "name: decoder.layers.weight_hh_l1\n",
      "values: \n",
      "Parameter containing:\n",
      "tensor([[-2.2908e-02,  9.2702e-02,  2.2497e-02,  ...,  1.6253e-02,\n",
      "          1.0511e-02,  4.0440e-02],\n",
      "        [-1.0964e-01,  8.6621e-02,  1.0544e-02,  ...,  1.9033e-02,\n",
      "         -1.2146e-02,  7.9120e-02],\n",
      "        [-6.5783e-02,  7.1634e-02,  9.0832e-02,  ...,  9.5858e-02,\n",
      "          5.4465e-02,  5.5642e-02],\n",
      "        ...,\n",
      "        [-2.5783e-03,  8.0878e-02,  2.6413e-02,  ...,  9.8850e-02,\n",
      "         -3.1425e-04,  4.3919e-02],\n",
      "        [ 2.3762e-02,  2.9211e-02, -3.6918e-02,  ...,  3.8495e-02,\n",
      "          7.4694e-04, -1.2811e-02],\n",
      "        [ 6.9200e-02, -5.4948e-02, -3.6881e-02,  ..., -7.2617e-02,\n",
      "         -1.6128e-02, -4.7592e-01]])\n",
      "--------------------\n",
      "name: decoder.layers.bias_ih_l1\n",
      "values: \n",
      "Parameter containing:\n",
      "tensor([0.1162, 0.1584, 0.0184,  ..., 0.1632, 0.0803, 0.0039])\n",
      "--------------------\n",
      "name: decoder.layers.bias_hh_l1\n",
      "values: \n",
      "Parameter containing:\n",
      "tensor([0.1162, 0.1584, 0.0184,  ..., 0.1632, 0.0803, 0.0039])\n",
      "--------------------\n",
      "name: decoder.char_trans.weight\n",
      "values: \n",
      "Parameter containing:\n",
      "tensor([[ 1.1938, -1.1832,  0.1316,  ..., -0.1802, -0.2143,  0.2721],\n",
      "        [ 1.5527, -0.2941,  0.1250,  ...,  0.0479, -0.4793,  0.2285],\n",
      "        [ 1.1955, -1.2192,  0.1487,  ..., -0.1744, -0.2265,  0.3142],\n",
      "        ...,\n",
      "        [ 1.2384, -1.1723,  0.1456,  ..., -0.1486, -0.1896,  0.2880],\n",
      "        [ 1.2612, -1.2450,  0.1596,  ..., -0.1646, -0.1807,  0.3174],\n",
      "        [ 1.2275, -1.2373,  0.1485,  ..., -0.2014, -0.1920,  0.2894]])\n",
      "--------------------\n",
      "name: decoder.char_trans.bias\n",
      "values: \n",
      "Parameter containing:\n",
      "tensor([-3.1036, -1.8332, -3.0848,  ..., -3.0726, -3.0733, -3.0707])\n",
      "--------------------\n",
      "name: attention.proj_q.weight\n",
      "values: \n",
      "Parameter containing:\n",
      "tensor([[ 3.8852e-02,  2.1233e-02,  1.5894e-02,  ...,  2.7710e-02,\n",
      "         -7.9271e-03, -1.7457e-02],\n",
      "        [ 3.5218e-03, -5.7275e-03,  5.4062e-03,  ...,  6.8475e-03,\n",
      "         -1.6957e-02,  1.9038e-02],\n",
      "        [-3.8783e-02,  4.7968e-02, -1.3851e-02,  ..., -1.4576e-02,\n",
      "         -1.0436e-02, -6.0163e-02],\n",
      "        ...,\n",
      "        [ 1.2055e-02,  2.5957e-02, -3.7572e-04,  ...,  1.7834e-02,\n",
      "          3.4371e-02,  4.8725e-05],\n",
      "        [-5.5319e-03,  1.4943e-02, -1.4033e-02,  ...,  1.0587e-02,\n",
      "          3.4186e-02, -2.8248e-02],\n",
      "        [-1.6291e-02,  3.1161e-04,  3.9328e-02,  ...,  2.1536e-02,\n",
      "          3.7562e-02, -1.3681e-01]])\n",
      "--------------------\n",
      "name: attention.proj_q.bias\n",
      "values: \n",
      "Parameter containing:\n",
      "tensor([-0.2033,  0.1486,  0.5733, -0.1579,  0.2040, -0.0620,  0.1926,  0.3108,\n",
      "         0.2802,  0.4275,  0.1643, -0.4534, -0.1708, -0.2175,  0.1828,  0.1391,\n",
      "        -0.2307, -0.3597, -0.1694,  0.5280,  0.5518,  0.1996, -0.4419, -0.2850,\n",
      "        -0.4033,  0.1249,  0.5599,  0.1157,  0.2361,  0.5087,  0.3342, -0.4457,\n",
      "        -0.1610, -0.3419, -0.5801,  0.2459,  0.1717, -0.2325, -0.4461,  0.3900,\n",
      "        -0.1314, -0.3619,  0.1497,  0.1648, -0.1412, -0.3179,  0.3531, -0.4958,\n",
      "        -0.2626, -0.3174, -0.1749, -0.2717,  0.4235,  0.1857, -0.0758, -0.2130,\n",
      "        -0.1739, -0.2785, -0.2010, -0.0110,  0.1533,  0.3470,  0.4068,  0.2226,\n",
      "        -0.2460,  0.2028, -0.2987,  0.3213, -0.2717, -0.2689, -0.2433,  0.2221,\n",
      "        -0.4363, -0.3902,  0.1741,  0.3794,  0.1735, -0.1792,  0.1566,  0.3128,\n",
      "        -0.3377,  0.2790,  0.3410,  0.1790, -0.5151, -0.1512,  0.3382,  0.0992,\n",
      "        -0.1806,  0.0916, -0.3047,  0.3796,  0.3378,  0.4882, -0.1463, -0.2380,\n",
      "        -0.1597, -0.4235, -0.2641,  0.3461,  0.1148,  0.2217,  0.2862, -0.4060,\n",
      "        -0.4993, -0.3452, -0.2336,  0.5959, -0.1537, -0.4915,  0.1895,  0.2976,\n",
      "         0.0960,  0.3043,  0.3933, -0.1261,  0.5111,  0.3518, -0.3032,  0.3234,\n",
      "        -0.3265,  0.1972, -0.1706, -0.0976,  0.1843, -0.0839, -0.3944, -0.2327,\n",
      "         0.3459, -0.6012,  0.2768, -0.2333,  0.1603,  0.3758, -0.4642, -0.1858,\n",
      "         0.2505, -0.5245, -0.5858, -0.4398, -0.4032,  0.1645,  0.3357,  0.2388,\n",
      "        -0.2843, -0.1939, -0.2145,  0.1412, -0.5204, -0.4651, -0.1963, -0.1897,\n",
      "         0.2870, -0.1852,  0.0025, -0.0767, -0.1630, -0.2198, -0.6107, -0.1599,\n",
      "        -0.2580, -0.2357, -0.2133, -0.1159, -0.6934, -0.2996, -0.3577,  0.2068,\n",
      "         0.2146, -0.4738,  0.3515,  0.1151,  0.2200, -0.2179,  0.2420,  0.1737,\n",
      "        -0.1747,  0.4443, -0.2044,  0.2963,  0.4270, -0.2161,  0.1924, -0.4568,\n",
      "        -0.1918,  0.0140,  0.1951,  0.5280, -0.1993, -0.2432,  0.2388,  0.4224,\n",
      "        -0.1897, -0.1745,  0.3859, -0.3163,  0.3494,  0.4098, -0.4171, -0.2217,\n",
      "         0.2682,  0.1383,  0.1366, -0.2920, -0.2650, -0.1609,  0.1434,  0.2188,\n",
      "         0.1146,  0.2797,  0.4546,  0.1672, -0.7210,  0.3426, -0.1241, -0.1750,\n",
      "         0.5035,  0.1741,  0.7655, -0.5325,  0.2042, -0.2733, -0.4945,  0.2004,\n",
      "        -0.3855, -0.4860, -0.3502, -0.2985,  0.0141, -0.1468, -0.2359,  0.2632,\n",
      "         0.1916,  0.2031, -0.4197, -0.2593, -0.5926, -0.3884,  0.1230, -0.1145,\n",
      "         0.2913,  0.3672,  0.1476, -0.1451, -0.3917,  0.1733,  0.4801, -0.1165,\n",
      "         0.1525,  0.3598, -0.1677,  0.1820,  0.3510, -0.1089, -0.0928, -0.2000,\n",
      "         0.4769, -0.1841, -0.2675,  0.2629,  0.4942,  0.1214, -0.1694, -0.1259,\n",
      "         0.4958,  0.3656, -0.2125, -0.4339, -0.2030, -0.0373, -0.2794, -0.2588,\n",
      "        -0.0989, -0.7759,  0.2715,  0.2650, -0.1524,  0.1385, -0.1270,  0.1314,\n",
      "        -0.1429, -0.2366, -0.4739,  0.1617, -0.3662,  0.2262,  0.2070, -0.1736,\n",
      "         0.5028,  0.4149, -0.2581,  0.3813, -0.4510,  0.1780, -0.2273, -0.5184,\n",
      "        -0.4429,  0.3361,  0.1556,  0.4571, -0.1253,  0.3082,  0.2403,  0.1316,\n",
      "         0.4412,  0.4984,  0.2420, -0.4202, -0.1922, -0.5700,  0.1512, -0.3911,\n",
      "         0.1967,  0.1384,  0.4676,  0.4234, -0.0586,  0.3809, -0.1577,  0.4712,\n",
      "        -0.2982, -0.2181, -0.2230,  0.1403,  0.4848, -0.0238,  0.1165, -0.4447,\n",
      "        -0.4190, -0.3645, -0.2430,  0.2185, -0.3385, -0.3827, -0.2717,  0.1020,\n",
      "        -0.2514, -0.3557,  0.1574,  0.3166, -0.2948, -0.1037, -0.3295, -0.1363,\n",
      "        -0.7460, -0.3008, -0.0445, -0.7207, -0.4283,  0.0746,  0.1044, -0.1864,\n",
      "        -0.2978,  0.2577,  0.1511, -0.1808,  0.5393, -0.1209, -0.0668,  0.1579,\n",
      "         0.5428, -0.4666, -0.3917,  0.1579,  0.5837,  0.2349,  0.1602,  0.2578,\n",
      "         0.1118,  0.2662, -0.3573, -0.1712, -0.4615, -0.1845, -0.2559,  0.2586,\n",
      "         0.4474, -0.3172, -0.4482, -0.1568,  0.1149,  0.2909,  0.4834, -0.2500,\n",
      "        -0.1860, -0.1289,  0.2222,  0.4805,  0.1573,  0.3981,  0.0131,  0.1928,\n",
      "        -0.2440, -0.1865,  0.2695,  0.1835,  0.0536,  0.1936, -0.1956, -0.2483,\n",
      "         0.0610,  0.2049, -0.3592,  0.2188,  0.4247, -0.2104,  0.1969, -0.1879,\n",
      "         0.2002, -0.1737, -0.0644,  0.2470,  0.0034,  0.3612, -0.1311, -0.1856,\n",
      "         0.4520,  0.2388, -0.2556,  0.1682, -0.1846,  0.8263, -0.0197,  0.2575,\n",
      "         0.2550, -0.2662, -0.2841, -0.3149,  0.1454, -0.0499, -0.1848, -0.2511,\n",
      "        -0.3865, -0.4989,  0.3061, -0.4444,  0.4421,  0.2138, -0.1933, -0.2530,\n",
      "        -0.3939,  0.4427, -0.4195, -0.1357, -0.6794, -0.1865,  0.9126,  0.1964,\n",
      "         0.2614,  0.2108,  0.3773, -0.4719, -0.0985,  0.1682,  0.4288, -0.1231,\n",
      "        -0.2926, -0.2343, -0.1272,  0.1531,  0.2174, -0.4616, -0.3790,  0.1617,\n",
      "        -0.5061,  0.0110, -0.3719, -0.1824, -0.1775,  0.3698,  0.1549,  0.1684,\n",
      "         0.1962, -0.2523,  0.4358,  0.2871,  0.3712,  0.3150, -0.0190, -0.3298,\n",
      "         0.1534, -0.4007,  0.4267, -0.2452,  0.5264, -0.7223,  0.2080, -0.1212,\n",
      "        -0.1609, -0.3145,  0.6288, -0.1790, -0.0211, -0.1672, -0.1350, -0.3986,\n",
      "        -0.1396, -0.1107,  0.2138, -0.1615, -0.4266, -0.1765, -0.2109,  0.5563,\n",
      "        -0.2445, -0.2303,  0.2175, -0.2951,  0.3217,  0.4606, -0.2769,  0.4498])\n",
      "--------------------\n",
      "name: attention.proj_k.weight\n",
      "values: \n",
      "Parameter containing:\n",
      "tensor([[-0.0172,  0.0033, -0.0058,  ...,  0.0228, -0.0006,  0.0226],\n",
      "        [-0.0532,  0.0552, -0.0243,  ..., -0.0002,  0.0271, -0.0980],\n",
      "        [-0.0146, -0.0417,  0.0258,  ..., -0.0368, -0.0069,  0.0459],\n",
      "        ...,\n",
      "        [ 0.0312,  0.0457, -0.0498,  ..., -0.0188,  0.0355, -0.0340],\n",
      "        [-0.0412, -0.0223,  0.0210,  ..., -0.0316,  0.0343,  0.0028],\n",
      "        [-0.0072, -0.0447,  0.0364,  ...,  0.0291, -0.0009,  0.0110]])\n",
      "--------------------\n",
      "name: attention.proj_k.bias\n",
      "values: \n",
      "Parameter containing:\n",
      "tensor([ 0.0924, -0.0859,  0.0888,  0.0836, -0.0022, -0.2193, -0.0151, -0.1179,\n",
      "        -0.0564, -0.0634, -0.1322,  0.0566, -0.2651,  0.1047, -0.0531, -0.0580,\n",
      "         0.0679, -0.0834,  0.0235,  0.0137,  0.0623,  0.0264,  0.0318, -0.1023,\n",
      "        -0.0167, -0.0677,  0.1534, -0.1065, -0.0608, -0.0869,  0.0370,  0.1028,\n",
      "         0.0683, -0.0647, -0.0260,  0.0599, -0.1072,  0.1195,  0.0926, -0.0492,\n",
      "         0.1006, -0.0991, -0.0723, -0.1102, -0.0094,  0.1146,  0.0317, -0.0463,\n",
      "        -0.1814,  0.0181, -0.1287,  0.0712,  0.1539, -0.0452,  0.1443, -0.0235,\n",
      "         0.0612,  0.0132,  0.0636,  0.0278,  0.0930,  0.0139, -0.0674, -0.0904,\n",
      "        -0.0868, -0.1152,  0.0689,  0.0639, -0.0647, -0.0684,  0.0606, -0.0626,\n",
      "         0.0277, -0.0581, -0.0918, -0.0106, -0.1028, -0.1674,  0.1427,  0.1178,\n",
      "        -0.1006,  0.1083,  0.1162,  0.0023, -0.0532,  0.0341, -0.1250, -0.0015,\n",
      "         0.0841,  0.1794, -0.0570,  0.2641,  0.1642, -0.1307,  0.0563,  0.0595,\n",
      "         0.0757, -0.0533,  0.0704, -0.0660, -0.1143, -0.1777,  0.0256,  0.0959,\n",
      "         0.0929, -0.0474,  0.0562,  0.0532,  0.0754,  0.0319, -0.0475, -0.0481,\n",
      "        -0.0140, -0.0858, -0.0653,  0.1342, -0.0295,  0.1560, -0.0894,  0.1415,\n",
      "        -0.0038,  0.0983,  0.1071, -0.1714, -0.0733, -0.0804, -0.0611, -0.0433,\n",
      "        -0.0100,  0.0948, -0.0446, -0.0355, -0.0590,  0.0231, -0.0953,  0.0563,\n",
      "         0.0832,  0.0041,  0.0273,  0.0955,  0.1178, -0.1037,  0.0471,  0.0663,\n",
      "        -0.0480,  0.1021,  0.0749, -0.1118, -0.0364,  0.1170,  0.1469,  0.0367,\n",
      "         0.0937, -0.0690, -0.0037,  0.0794,  0.1013,  0.1441, -0.1367,  0.0964,\n",
      "         0.0224,  0.1057,  0.0841, -0.0063, -0.0809, -0.0147,  0.0832, -0.0868,\n",
      "        -0.0904, -0.0559, -0.0061,  0.2367,  0.0945,  0.0309, -0.0149, -0.0708,\n",
      "         0.1117, -0.0692,  0.1289, -0.0722,  0.0827,  0.0220, -0.1025, -0.0274,\n",
      "         0.0964, -0.1092, -0.0534,  0.0826,  0.0917,  0.0452,  0.0259, -0.1414,\n",
      "        -0.1415,  0.0795, -0.0998,  0.0911,  0.0606, -0.0069, -0.0400,  0.0156,\n",
      "         0.0741, -0.1035, -0.0251, -0.0369, -0.0162,  0.0941, -0.1038, -0.0323,\n",
      "        -0.0933, -0.0571, -0.1097, -0.0816, -0.1061,  0.0650,  0.0701, -0.0524,\n",
      "         0.1011, -0.0149, -0.0133,  0.1154, -0.0997,  0.0062, -0.0183, -0.0631,\n",
      "        -0.1159, -0.0416,  0.1208,  0.1288,  0.0163,  0.0956,  0.0288, -0.1254,\n",
      "        -0.1449, -0.0215, -0.1331,  0.0968, -0.0352, -0.0521, -0.0581,  0.0746,\n",
      "         0.0912,  0.0146, -0.1809,  0.0251, -0.1118, -0.0537, -0.0659, -0.1128,\n",
      "        -0.0271,  0.0446,  0.0593, -0.0719,  0.0629, -0.1024,  0.0493,  0.1090,\n",
      "        -0.0973,  0.0032, -0.0488,  0.1012, -0.0353,  0.0349,  0.0477, -0.0264,\n",
      "         0.0689,  0.0583,  0.0889,  0.1052,  0.0381,  0.0345, -0.1323,  0.0620,\n",
      "         0.0473, -0.0032,  0.1159,  0.0193,  0.0927, -0.0826,  0.0724, -0.0854,\n",
      "         0.0718,  0.0424, -0.0128,  0.0507,  0.0978, -0.0823,  0.0442,  0.0739,\n",
      "        -0.0353,  0.0463,  0.0998, -0.1070, -0.0948, -0.0575, -0.1111,  0.0110,\n",
      "         0.0736,  0.0267, -0.0600, -0.0310,  0.1079,  0.0773,  0.0065, -0.1219,\n",
      "        -0.0742, -0.1446,  0.0319,  0.0152,  0.0495,  0.1041, -0.0862,  0.0214,\n",
      "        -0.0746, -0.1266, -0.1034,  0.1247, -0.0606,  0.0018, -0.0399,  0.0018,\n",
      "        -0.0890,  0.0316, -0.1033, -0.0900,  0.1335, -0.1081, -0.0869, -0.0414,\n",
      "        -0.0704,  0.0913,  0.1407, -0.0554, -0.0091, -0.0104, -0.0230, -0.0841,\n",
      "         0.0064,  0.0210, -0.0696, -0.0554, -0.0493,  0.1718, -0.2617,  0.0885,\n",
      "        -0.0078,  0.0788, -0.0508, -0.0054,  0.0165, -0.1263, -0.0609,  0.1057,\n",
      "        -0.0466, -0.0006, -0.0290,  0.1180,  0.0196, -0.0810,  0.0848, -0.0431,\n",
      "        -0.1369,  0.1310,  0.1934,  0.1010,  0.0383,  0.0008, -0.1234, -0.0197,\n",
      "         0.0006, -0.1284, -0.1287, -0.0056,  0.0162,  0.0585, -0.0667, -0.0188,\n",
      "         0.0377,  0.0743, -0.0149,  0.1171, -0.0577,  0.1050, -0.1382,  0.1531,\n",
      "        -0.0057,  0.0755, -0.1077, -0.1125, -0.0729, -0.0980,  0.1963, -0.0674,\n",
      "         0.0485,  0.0189,  0.1168,  0.1358, -0.1434, -0.1682,  0.0876, -0.0188,\n",
      "         0.0506,  0.0531, -0.0313, -0.0441, -0.1064,  0.0736, -0.0262,  0.0653,\n",
      "        -0.0480, -0.0208, -0.0571, -0.0691,  0.1232, -0.0922, -0.1879,  0.0582,\n",
      "         0.0816, -0.0662, -0.0450,  0.0181,  0.0415, -0.0267, -0.0418, -0.1287,\n",
      "        -0.0643, -0.0552,  0.0613, -0.0363, -0.0651, -0.0459,  0.0982,  0.0862,\n",
      "        -0.1381, -0.0522, -0.0558, -0.0208,  0.0177, -0.0286,  0.0736, -0.2060,\n",
      "         0.1003,  0.0359, -0.0967, -0.2458, -0.0510,  0.1526, -0.0709, -0.0053,\n",
      "         0.1064,  0.0116, -0.0287,  0.0842,  0.0742, -0.0567,  0.2699,  0.1549,\n",
      "         0.0950,  0.0109,  0.0956,  0.1629, -0.0648,  0.0098, -0.1240, -0.0867,\n",
      "        -0.0449, -0.2614,  0.0702,  0.1194,  0.0102, -0.1147, -0.0364, -0.0616,\n",
      "        -0.0528, -0.0774, -0.0805,  0.0410,  0.0711, -0.0172, -0.0926, -0.1298,\n",
      "         0.1107, -0.0269, -0.1399,  0.0276, -0.1303,  0.0332,  0.0643,  0.0820,\n",
      "        -0.0492,  0.0091,  0.0005, -0.0834, -0.0305,  0.0668, -0.0423, -0.1178,\n",
      "        -0.0192,  0.0728, -0.0296,  0.0389, -0.0009, -0.0085, -0.0145, -0.0967,\n",
      "         0.0672,  0.1149, -0.0232, -0.0721, -0.0190, -0.1131,  0.0555, -0.0107])\n",
      "--------------------\n",
      "name: attention.att_layer.loc_conv.weight\n",
      "values: \n",
      "Parameter containing:\n",
      "tensor([[[-0.1273,  0.0206,  0.0605,  ...,  0.0871,  0.1257,  0.0007]],\n",
      "\n",
      "        [[-0.0559, -0.1022, -0.0703,  ...,  0.0805,  0.1109,  0.0571]],\n",
      "\n",
      "        [[-0.0335, -0.1968,  0.0446,  ...,  0.0165, -0.0519, -0.0593]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0836,  0.1437,  0.0762,  ...,  0.0171,  0.0072,  0.0585]],\n",
      "\n",
      "        [[-0.1161, -0.0443, -0.0820,  ..., -0.0682,  0.0080,  0.0050]],\n",
      "\n",
      "        [[-0.1864,  0.0014, -0.0050,  ..., -0.1691,  0.0033, -0.1717]]])\n",
      "--------------------\n",
      "name: attention.att_layer.loc_proj.weight\n",
      "values: \n",
      "Parameter containing:\n",
      "tensor([[ 0.0853,  0.5242, -0.3959,  ..., -0.2232, -0.0979,  0.4214],\n",
      "        [ 0.2225,  0.3603,  0.2019,  ..., -0.2619,  0.6357, -0.3213],\n",
      "        [-0.0600, -0.3481, -0.2584,  ..., -0.0906,  0.2917, -0.6406],\n",
      "        ...,\n",
      "        [-0.2009, -0.2399,  0.1666,  ..., -0.1122, -0.0903,  0.3472],\n",
      "        [ 0.2685,  0.3867, -0.6841,  ...,  0.4844, -0.1037, -0.1589],\n",
      "        [-0.0485, -0.0477, -0.0185,  ..., -0.2385, -0.4693,  0.1360]])\n",
      "--------------------\n",
      "name: attention.att_layer.gen_energy.weight\n",
      "values: \n",
      "Parameter containing:\n",
      "tensor([[ 7.9681e-02, -1.5499e-01, -1.4712e-01,  1.8452e-02, -1.3074e-01,\n",
      "          1.2268e-01, -1.7042e-01, -4.4236e-02, -1.1076e-01, -2.0028e-01,\n",
      "         -1.6854e-01,  8.4078e-02,  2.0467e-01,  5.4923e-02, -5.0348e-02,\n",
      "         -6.7228e-02,  1.2085e-01,  1.2852e-01,  1.3557e-01, -1.1398e-01,\n",
      "         -1.4472e-01, -1.0707e-01,  2.2692e-01,  1.2781e-01,  1.0245e-01,\n",
      "         -4.6818e-02, -1.4544e-01, -2.1632e-02, -1.1532e-01, -2.6644e-02,\n",
      "         -1.4212e-01,  6.1318e-02,  2.7692e-02,  6.9301e-02,  1.1764e-01,\n",
      "         -1.7862e-01, -6.3129e-03,  1.8269e-02,  7.3688e-02, -8.3618e-02,\n",
      "         -2.4531e-01,  1.0161e-01, -2.2757e-02, -3.9887e-02,  1.7174e-01,\n",
      "          3.4683e-02, -1.2872e-01,  1.0483e-01,  1.9262e-01,  1.0643e-01,\n",
      "          6.1652e-02,  3.1982e-02, -1.7747e-01, -3.8794e-02, -2.2192e-01,\n",
      "          1.5124e-01,  2.7810e-02,  1.2864e-01,  6.8230e-02, -9.5980e-02,\n",
      "         -1.0815e-01, -1.1715e-01, -6.4052e-02, -6.3194e-02,  1.6959e-01,\n",
      "         -1.9591e-02,  1.0970e-01, -8.8591e-02,  6.9225e-02,  9.8420e-02,\n",
      "          6.3980e-02, -1.0157e-01,  9.0028e-02,  1.1364e-01, -8.1156e-02,\n",
      "         -9.8821e-02, -2.8795e-02,  1.5257e-01, -5.9660e-02, -1.2733e-01,\n",
      "          1.4282e-01, -8.1670e-02, -1.2748e-01, -1.6337e-01,  1.2930e-01,\n",
      "          1.2255e-01, -5.9073e-02, -6.3503e-02,  8.6636e-03, -1.1500e-01,\n",
      "          1.1104e-01, -2.9886e-01, -1.6201e-01, -1.5141e-01,  8.4858e-02,\n",
      "          6.0063e-02,  6.3805e-02,  1.6604e-01,  7.0544e-02, -5.9049e-02,\n",
      "         -6.4762e-02, -1.2676e-01, -1.4753e-01,  5.3359e-02,  1.2586e-01,\n",
      "          1.2175e-01,  1.8642e-01, -1.4187e-01,  3.8504e-02,  1.2410e-01,\n",
      "         -4.9598e-02, -8.2599e-02, -1.2394e-01, -9.1461e-02, -4.1048e-02,\n",
      "          2.1887e-02, -9.8719e-02, -1.9059e-01,  9.2688e-02, -9.7625e-02,\n",
      "          1.5745e-01, -1.3333e-01,  1.4949e-02,  1.6549e-01, -4.0159e-02,\n",
      "          1.3685e-01,  1.1525e-01,  1.5033e-01, -1.4222e-01,  1.4088e-01,\n",
      "         -7.3150e-02,  1.2108e-01, -9.4680e-02, -1.3972e-01,  3.6944e-01,\n",
      "          1.3834e-01, -1.1536e-01,  1.3635e-01,  9.7036e-02,  8.3847e-02,\n",
      "          4.3108e-02, -9.7693e-02, -1.1937e-01, -8.5370e-02,  1.0089e-01,\n",
      "          4.9553e-02,  5.9051e-02,  6.9647e-03,  9.8314e-02,  1.2224e-01,\n",
      "          1.1580e-01,  7.7843e-02, -1.5051e-01,  2.3287e-01,  5.2299e-02,\n",
      "          7.0922e-02,  1.6523e-01,  3.3799e-02,  2.7657e-01,  1.0964e-01,\n",
      "          1.1562e-01,  1.0778e-01,  2.6324e-02,  1.4495e-01,  3.1503e-01,\n",
      "          6.8597e-02,  1.9817e-01, -1.9139e-02, -2.4950e-02,  1.1267e-01,\n",
      "         -8.2376e-02, -1.3238e-01, -1.1633e-01,  1.5557e-01, -1.2437e-01,\n",
      "         -2.9652e-02,  2.8893e-02, -4.1688e-02,  1.9362e-01, -9.1301e-02,\n",
      "         -9.7486e-02,  1.3467e-01, -5.8239e-02,  1.7070e-01,  2.3997e-02,\n",
      "          1.0047e-01, -9.3516e-02, -1.6151e-01,  9.2657e-02,  5.4297e-02,\n",
      "         -1.0022e-01, -9.4350e-02,  9.6479e-02,  4.9258e-02, -9.0950e-02,\n",
      "          8.4570e-02, -9.8655e-02, -9.0896e-02,  8.3517e-02,  1.3820e-01,\n",
      "         -2.6382e-01, -8.7642e-02, -1.3360e-01,  9.3598e-02,  1.3548e-01,\n",
      "          1.4833e-01,  3.9871e-01, -1.0415e-01, -1.5397e-02, -9.5692e-02,\n",
      "         -8.7126e-02, -3.6305e-02,  2.1872e-01, -7.9978e-02,  1.8214e-01,\n",
      "          9.8734e-02, -1.4311e-01, -1.2168e-01, -2.8136e-01,  9.9824e-02,\n",
      "         -2.0037e-01,  1.6406e-01,  9.7931e-02, -4.2741e-02,  1.5893e-01,\n",
      "          6.1115e-02,  3.6644e-02,  2.7173e-01,  9.7338e-02,  1.0428e-01,\n",
      "          1.0311e-01, -5.3990e-02, -3.6467e-02, -8.3350e-02,  1.1623e-01,\n",
      "          3.4557e-02,  1.0095e-01,  1.0587e-01, -3.9001e-02,  3.3277e-02,\n",
      "         -9.1075e-02, -8.5759e-02, -7.1255e-02,  4.6295e-02,  1.4779e-01,\n",
      "         -3.2456e-02, -1.1291e-01,  3.3260e-02, -1.5075e-01, -1.2646e-01,\n",
      "          3.8700e-02, -3.8497e-02, -1.1122e-01, -1.8042e-01,  8.1971e-02,\n",
      "          7.4210e-02, -7.8032e-02,  1.1653e-01,  8.1865e-02, -1.7206e-01,\n",
      "         -6.0951e-02, -3.2723e-01,  3.9020e-02,  8.4946e-02, -1.4148e-01,\n",
      "         -1.3265e-01,  1.5249e-01,  7.7787e-02,  5.7437e-02,  9.7494e-02,\n",
      "          1.0718e-01,  5.2618e-02,  7.8335e-02,  2.6463e-01, -1.4676e-01,\n",
      "         -1.6789e-01,  2.5057e-02, -1.5799e-02,  2.4702e-02, -6.1943e-02,\n",
      "          1.8766e-02,  9.2473e-02,  1.0366e-01, -6.6800e-02,  5.8665e-02,\n",
      "         -1.1377e-01, -7.1384e-02,  5.3277e-02, -1.2497e-01, -1.0982e-01,\n",
      "          6.9003e-02, -3.5097e-02,  2.3817e-01, -5.3706e-02,  1.7574e-01,\n",
      "          1.1224e-01,  8.7825e-02, -6.4195e-02, -1.3310e-01, -1.0181e-01,\n",
      "          2.8751e-02, -1.4198e-01, -1.2700e-01, -1.7206e-03, -1.1912e-01,\n",
      "         -1.3903e-01, -1.5368e-01,  9.0279e-02,  3.3603e-02,  1.3001e-01,\n",
      "         -7.1726e-02,  1.1814e-01, -3.5551e-02, -4.0630e-02, -1.4546e-01,\n",
      "         -1.9169e-01,  5.9818e-02, -1.1083e-01,  7.9459e-02, -1.4209e-01,\n",
      "          1.1171e-01,  1.2673e-01,  7.4585e-02, -1.8602e-02, -1.7512e-01,\n",
      "          1.9781e-01, -3.0064e-02,  1.3103e-01,  1.1903e-01,  5.3042e-02,\n",
      "          6.3538e-02, -3.2728e-02,  8.0521e-02,  9.8601e-02,  1.2767e-01,\n",
      "         -2.7460e-02,  1.1136e-01,  1.3469e-01, -9.5448e-02, -6.2042e-02,\n",
      "          9.6050e-02,  1.5679e-01,  3.3298e-01,  1.5243e-02,  2.3193e-01,\n",
      "          7.3115e-02,  3.1515e-01,  1.6034e-01,  9.6729e-02,  1.0650e-01,\n",
      "         -1.1880e-01,  1.7934e-02,  1.2076e-01, -1.3211e-01, -7.8354e-02,\n",
      "          5.3408e-02, -6.2701e-02,  1.5537e-01,  1.5461e-01, -7.2688e-02,\n",
      "         -2.2100e-01,  1.1649e-01,  8.5182e-02, -2.1076e-01, -1.2802e-01,\n",
      "         -6.4073e-02, -3.8692e-02, -1.4653e-01, -2.0330e-01, -1.8320e-01,\n",
      "          1.3141e-01,  1.1952e-01,  7.4138e-02, -4.6700e-04,  9.9265e-02,\n",
      "         -1.0339e-01, -1.7166e-01,  1.3372e-01,  9.3573e-02,  5.6332e-03,\n",
      "         -2.2416e-01, -1.4079e-01, -1.5931e-01,  1.0630e-01,  1.3375e-01,\n",
      "          1.3097e-02, -4.5693e-02, -6.0391e-02, -5.5956e-02, -4.1115e-02,\n",
      "          1.0072e-01, -1.4401e-01,  6.4875e-02,  2.1611e-01, -1.3791e-01,\n",
      "         -1.3706e-01, -1.3026e-01, -1.1547e-01,  1.4525e-01,  1.4312e-01,\n",
      "         -9.1942e-02, -2.2319e-01,  1.2639e-01, -1.0589e-01, -1.4729e-01,\n",
      "          1.1404e-01, -8.5736e-02,  7.9243e-02, -9.2627e-02,  1.3033e-01,\n",
      "          1.6090e-01, -4.1196e-02, -3.0719e-02, -1.3956e-02,  1.1707e-01,\n",
      "          7.4543e-02, -1.2499e-01, -5.6123e-02,  1.5388e-01, -1.0319e-01,\n",
      "          1.3155e-01, -3.1386e-01, -4.4535e-02, -9.9249e-02, -1.9810e-01,\n",
      "          8.9437e-02,  3.7694e-02,  6.3404e-02, -3.0946e-02, -1.0480e-01,\n",
      "          5.6061e-02,  3.5669e-02,  1.1014e-01,  1.7402e-01, -5.7736e-02,\n",
      "          1.3526e-01, -1.2454e-01, -5.1194e-02,  6.5260e-02,  1.7159e-01,\n",
      "          2.7077e-02, -9.3444e-02,  1.9331e-01,  2.1561e-01,  2.8847e-01,\n",
      "          1.5030e-01, -1.7196e-01, -8.8554e-02, -1.4267e-01, -1.7305e-01,\n",
      "         -1.0450e-01,  9.3834e-02,  3.1728e-02, -1.9093e-02, -4.8339e-01,\n",
      "          1.2626e-01,  7.4926e-02,  1.2875e-01,  1.1369e-01, -1.0706e-01,\n",
      "         -4.8679e-02,  2.0603e-01,  1.1994e-01, -2.0292e-02,  1.0499e-01,\n",
      "          3.5645e-01,  6.7500e-02,  2.9670e-02,  1.0028e-01, -1.1456e-01,\n",
      "         -3.1672e-02, -1.0585e-01, -1.4807e-01,  1.3640e-01, -5.4203e-02,\n",
      "         -7.7165e-02, -1.0398e-01, -1.1739e-01,  1.3819e-01,  1.1062e-01,\n",
      "         -7.4489e-02,  1.4620e-01, -1.5017e-01,  1.5341e-01, -1.3425e-01,\n",
      "          9.2877e-02, -8.0612e-02,  1.4671e-01,  1.5734e-01,  1.1417e-01,\n",
      "         -1.1408e-01,  5.3583e-02, -1.6053e-01, -6.2239e-03,  9.5464e-02,\n",
      "          1.2694e-01,  1.4045e-01,  7.0930e-02, -1.1831e-01,  1.2343e-01,\n",
      "          8.0834e-02,  1.0279e-01,  1.4304e-01, -9.8874e-02,  8.9246e-02,\n",
      "          1.7862e-02, -1.1987e-01,  1.0750e-01, -5.6917e-02, -7.2308e-02,\n",
      "          4.8222e-02, -1.2564e-01]])\n",
      "--------------------\n",
      "name: attention.att_layer.gen_energy.bias\n",
      "values: \n",
      "Parameter containing:\n",
      "tensor([-4.7041e-07])\n",
      "encoder.layers.0.extractor.0.weight\n",
      "encoder.layers.0.extractor.0.bias\n",
      "encoder.layers.0.extractor.2.weight\n",
      "encoder.layers.0.extractor.2.bias\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secondary-sample",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('asd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "sealed-enemy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "============  Result of /home/jupyter-jason3/LAS_Mandarin_PyTorch-master/result/mozillacv11_asr_stm4atthead-test_test_output.csv ============\r\n",
      " -----------------------------------------------------------------------\r\n",
      "| Statics\t\t|  Truth\t|  Prediction\t| Abs. Diff.\t|\r\n",
      " -----------------------------------------------------------------------\r\n",
      "| Avg. # of chars\t|  8.01\t|  8.10\t|  0.16\t\t|\r\n",
      "| Avg. # of words\t|  1.00\t|  1.00\t|  0.00\t\t|\r\n",
      " -----------------------------------------------------------------------\r\n",
      " ---------------------------------------------------------------\r\n",
      "| Error Rate (%)| Mean\t\t| Std.\t\t| Min./Max.\t|\r\n",
      " ---------------------------------------------------------------\r\n",
      "| Character\t| 7.9479\t| 21.68\t\t| 0.00/240.00\t|\r\n",
      "| Word\t\t| 18.1725\t| 38.56\t\t| 0.00/100.00\t|\r\n",
      " ---------------------------------------------------------------\r\n",
      "Note : If the text unit is phoneme, WER = PER and CER is meaningless.\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!python eval.py --file ~/LAS_Mandarin_PyTorch-master/result/mozillacv11_asr_stm4atthead-test_test_output.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naughty-basis",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
