{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "revised-treasury",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sunrise-genealogy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
    "# os.environ['CUDA_VISIBLE_DEVICES']='0,1'\n",
    "os.environ['CUDA_LAUNCH_BLOCKING']='1'\n",
    "import torch\n",
    "# torch.cuda.set_device(0)\n",
    "print(torch.cuda.current_device())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "intimate-dimension",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "biological-remains",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "endless-motel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "extreme-calcium",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cudaSetDevice(0)\n",
    "#dataset transcript要在dataset資好夾調\n",
    "#cuda 在basesolver init調\n",
    "#dataset要在data.py設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "earned-treat",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! python\n",
    "# -*- coding: utf-8 -*-\n",
    "# Author: kun\n",
    "# @Time: 2019-10-29 20:29\n",
    "\n",
    "import yaml\n",
    "import torch\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "class Para(object):\n",
    "    a=1\n",
    "\n",
    "def force_cudnn_initialization():\n",
    "    s = 32\n",
    "    dev = torch.device('cuda:0')\n",
    "    torch.nn.functional.conv2d(torch.zeros(s, s, s, s, device=dev), torch.zeros(s, s, s, s, device=dev))\n",
    "    \n",
    "#force_cudnn_initialization()\n",
    "def main():\n",
    "    # For reproducibility, comment these may speed up training\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    # Arguments\n",
    "#     parser = argparse.ArgumentParser(description='Training E2E asr.')\n",
    "#     parser.add_argument('--config', type=str, help='Path to experiment config.')\n",
    "#     parser.add_argument('--name', default=None, type=str, help='Name for logging.')\n",
    "#     parser.add_argument('--logdir', default='log/', type=str,\n",
    "#                         help='Logging path.', required=False)\n",
    "#     parser.add_argument('--ckpdir', default='ckpt/', type=str,\n",
    "#                         help='Checkpoint path.', required=False)\n",
    "#     parser.add_argument('--outdir', default='result/', type=str,\n",
    "#                         help='Decode output path.', required=False)\n",
    "#     parser.add_argument('--load', default=None, type=str,\n",
    "#                         help='Load pre-trained model (for training only)', required=False)\n",
    "#     parser.add_argument('--seed', default=0, type=int,\n",
    "#                         help='Random seed for reproducable results.', required=False)\n",
    "#     parser.add_argument('--cudnn-ctc', action='store_true',\n",
    "#                         help='Switches CTC backend from torch to cudnn')\n",
    "#     parser.add_argument('--njobs', default=32, type=int,\n",
    "#                         help='Number of threads for dataloader/decoding.', required=False)\n",
    "#     parser.add_argument('--cpu', action='store_true', help='Disable GPU training.')\n",
    "#     parser.add_argument('--no-pin', action='store_true',\n",
    "#                         help='Disable pin-memory for dataloader')\n",
    "#     parser.add_argument('--test', action='store_true', help='Test the model.')\n",
    "#     parser.add_argument('--no-msg', action='store_true', help='Hide all messages.')\n",
    "#     parser.add_argument('--lm', action='store_true',\n",
    "#                         help='Option for training RNNLM.')\n",
    "#     # Following features in development.\n",
    "#     parser.add_argument('--amp', action='store_true', help='Option to enable AMP.')\n",
    "#     parser.add_argument('--reserve-gpu', default=0, type=float,\n",
    "#                         help='Option to reserve GPU ram for training.')\n",
    "#     parser.add_argument('--jit', action='store_true',\n",
    "#                         help='Option for enabling jit in pytorch. (feature in development)')\n",
    "#     ###\n",
    "#     paras = parser.parse_args()\n",
    "    paras = Para()\n",
    "#     paras.config = './config/aishell_asr_example_lstm4atthead1-test.yaml'\n",
    "#     paras.name = None\n",
    "#     paras.logdir = 'log/'\n",
    "#     paras.ckpdir = 'ckpt/'\n",
    "#     paras.outdir = 'result/'\n",
    "#     paras.load = None\n",
    "#     paras.seed = 0\n",
    "#     paras.cudnn_ctc = False\n",
    "#     paras.cpu = False\n",
    "#     paras.no_pin = False\n",
    "#     paras.test = True\n",
    "#     paras.no_msg = False\n",
    "#     paras.lm = False\n",
    "#     paras.amp = False\n",
    "#     paras.reserve_gpu = 0\n",
    "#     paras.jit = False\n",
    "    setattr(paras, 'config', './config/cv11Lu_asr_lstm4atthead_allvocab.yaml')\n",
    "    setattr(paras, 'name', None)\n",
    "    setattr(paras, 'logdir', 'log/')\n",
    "    setattr(paras, 'ckpdir', 'ckpt/')\n",
    "    setattr(paras, 'outdir', 'result/')\n",
    "    setattr(paras, 'load', None)\n",
    "    setattr(paras, 'seed', 0)\n",
    "    setattr(paras, 'cudnn_ctc', False)\n",
    "    setattr(paras, 'njobs',8)\n",
    "    setattr(paras, 'cpu', False)\n",
    "    setattr(paras, 'no_pin', False)\n",
    "    setattr(paras, 'test', False)\n",
    "    setattr(paras, 'no_msg', False)\n",
    "    setattr(paras, 'lm', False)\n",
    "    setattr(paras, 'amp', False)\n",
    "    setattr(paras, 'reserve_gpu', 8)\n",
    "    setattr(paras, 'jit', False)\n",
    "    setattr(paras, 'gpu', not paras.cpu)\n",
    "    setattr(paras, 'pin_memory', not paras.no_pin)\n",
    "    setattr(paras, 'verbose', not paras.no_msg)\n",
    "    force_cudnn_initialization()\n",
    "\n",
    "    config = yaml.load(open(paras.config, 'r'), Loader=yaml.FullLoader)\n",
    "\n",
    "    np.random.seed(paras.seed)\n",
    "    torch.manual_seed(paras.seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(paras.seed)\n",
    "\n",
    "    # Hack to preserve GPU ram just incase OOM later on server\n",
    "    if paras.gpu and paras.reserve_gpu > 0:\n",
    "        buff = torch.randn(int(paras.reserve_gpu * 1e9 // 4)).cuda()\n",
    "        del buff\n",
    "\n",
    "    if paras.lm:\n",
    "        # Train RNNLM\n",
    "        from train_lm import Solver\n",
    "\n",
    "        mode = 'train'\n",
    "    else:\n",
    "        if paras.test:\n",
    "            # Test ASR\n",
    "            assert paras.load is None, 'Load option is mutually exclusive to --test'\n",
    "            from test_asr import Solver\n",
    "\n",
    "            mode = 'test'\n",
    "        else:\n",
    "            # Train ASR\n",
    "            from train_asr import Solver\n",
    "\n",
    "            mode = 'train'\n",
    "\n",
    "    print(\"\\nUsing {} mode\\n\".format(mode))\n",
    "    solver = Solver(config, paras, mode)\n",
    "    solver.load_data()\n",
    "    solver.set_model()\n",
    "    solver.exec()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "meaningful-silver",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using train mode\n",
      "\n",
      "[INFO] Exp. name : cv11Lu_asr_lstm4atthead_allvocab_sd0                                                    \n",
      "[INFO] Loading data... large dataset may took a while.                                                     \n",
      "Load data for training/validation, store tokenizer and input/output shape\n",
      "Prepare dataloader for training/validation\n",
      "Load text encoder : CharacterTextEncoder\n",
      "Interface for creating all kinds of dataset\n",
      "import Mozillacv11Dataset as Dataset\n",
      "[Mozillacv11Dataset] path: /mnt/usb/jason3/cv-corpus-11.0-2022-09-21/zh-TW/wavs, split: ['dev']\n",
      "Mozillacv11Dataset dev found wav data: 14709\n",
      "text len: 14709\n",
      "remove None, then wav data: 14709, text len: 14709\n",
      "[Mozillacv11Dataset] path: /mnt/usb/jason3/cv-corpus-11.0-2022-09-21/zh-TW/wavs, split: ['train']\n",
      "Mozillacv11Dataset train found wav data: 89455\n",
      "text len: 89455\n",
      "remove None, then wav data: 89450, text len: 89450\n",
      "[INFO] Data spec. | Corpus = mozilla_cv11 (from /mnt/usb/jason3/cv-corpus-11.0-2022-09-21/zh-TW/wavs)      \n",
      "[INFO]            | Train sets = ['train']\t| Number of utts = 89450                                        \n",
      "[INFO]            | Dev sets = ['dev']\t| Number of utts = 14709                                            \n",
      "[INFO]            | Batch size = 16\t\t| Bucketing = True                                                    \n",
      "[INFO] I/O spec.  | Audio feature = fbank\t| feature dim = 120\t| Token type = character\t| Vocab size = 3283 \n",
      "Setup ASR model and optimizer \n",
      "[INFO] Model spec.| Encoder's downsampling rate of time axis is 4.                                         \n",
      "[INFO]            | VCC Extractor w/ time downsampling rate = 4 in encoder enabled.                        \n",
      "[INFO]            | loc attention decoder enabled ( lambda = 1.0).                                         \n",
      "# Losses\n",
      "# Note: zero_infinity=False is unstable?\n",
      "Plug-ins\n",
      "# Optimizer\n",
      "[INFO] Optim.spec.| Algo. = Adadelta\t| Lr = 1.0\t (Scheduler = fixed)| Scheduled sampling = False           \n",
      "# Enable AMP if needed\n",
      "Training End-to-end ASR system\n",
      "[INFO] Total training steps 1.0M.                                                                          \n",
      "self.tr_set: 89450\n",
      "[INFO] Saved checkpoint (step = 5.0K, wer = 0.96) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab_sd0/best_att.pth\n",
      "[INFO] Saved checkpoint (step = 10.0K, wer = 0.96) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab_sd0/best_att.pth\n",
      "[INFO] Saved checkpoint (step = 15.0K, wer = 0.95) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab_sd0/best_att.pth\n",
      "[INFO] Saved checkpoint (step = 25.0K, wer = 0.94) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab_sd0/best_att.pth\n",
      "[INFO] Saved checkpoint (step = 30.0K, wer = 0.94) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab_sd0/best_att.pth\n",
      "[INFO] Saved checkpoint (step = 35.0K, wer = 0.90) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab_sd0/best_att.pth\n",
      "[INFO] Saved checkpoint (step = 40.0K, wer = 0.83) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab_sd0/best_att.pth\n",
      "[INFO] Saved checkpoint (step = 45.0K, wer = 0.75) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab_sd0/best_att.pth\n",
      "[INFO] Saved checkpoint (step = 50.0K, wer = 0.65) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab_sd0/best_att.pth\n",
      "[INFO] Saved checkpoint (step = 55.0K, wer = 0.57) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab_sd0/best_att.pth\n",
      "[INFO] Saved checkpoint (step = 60.0K, wer = 0.50) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab_sd0/best_att.pth\n",
      "[INFO] Saved checkpoint (step = 65.0K, wer = 0.43) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab_sd0/best_att.pth\n",
      "[INFO] Saved checkpoint (step = 70.0K, wer = 0.37) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab_sd0/best_att.pth\n",
      "[INFO] Saved checkpoint (step = 75.0K, wer = 0.31) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab_sd0/best_att.pth\n",
      "[INFO] Saved checkpoint (step = 80.0K, wer = 0.29) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab_sd0/best_att.pth\n",
      "[INFO] Saved checkpoint (step = 85.0K, wer = 0.24) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab_sd0/best_att.pth\n",
      "self.tr_set: 89450 | Loss - 0.06 | Grad. Norm - 0.54 | 0.229 sec/step (rd 0.9% | fw 31.2% | bw 68.0%)\n",
      "[INFO] Saved checkpoint (step = 90.0K, wer = 0.22) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab_sd0/best_att.pth\n",
      "[INFO] Saved checkpoint (step = 95.0K, wer = 0.21) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab_sd0/best_att.pth\n",
      "[INFO] Saved checkpoint (step = 100.0K, wer = 0.19) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab_sd0/best_att.pthep - 665/920\n",
      "[INFO] Saved checkpoint (step = 105.0K, wer = 0.17) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab_sd0/best_att.pth\n",
      "[INFO] Saved checkpoint (step = 110.0K, wer = 0.16) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab_sd0/best_att.pth\n",
      "[INFO] Saved checkpoint (step = 115.0K, wer = 0.15) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab_sd0/best_att.pth\n",
      "[INFO] Saved checkpoint (step = 120.0K, wer = 0.14) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab_sd0/best_att.pth\n",
      "[INFO] Saved checkpoint (step = 130.0K, wer = 0.13) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab_sd0/best_att.pth\n",
      "[INFO] Saved checkpoint (step = 140.0K, wer = 0.13) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab_sd0/best_att.pth\n",
      "[INFO] Saved checkpoint (step = 145.0K, wer = 0.13) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab_sd0/best_att.pth\n",
      "[INFO] Saved checkpoint (step = 150.0K, wer = 0.12) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab_sd0/best_att.pth\n",
      "[INFO] Saved checkpoint (step = 155.0K, wer = 0.12) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab_sd0/best_att.pth\n",
      "[INFO] Saved checkpoint (step = 160.0K, wer = 0.12) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab_sd0/best_att.pth\n",
      "[INFO] Saved checkpoint (step = 165.0K, wer = 0.12) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab_sd0/best_att.pth\n",
      "[INFO] Saved checkpoint (step = 175.0K, wer = 0.12) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab_sd0/best_att.pth\n",
      "\u001b[K[177.5K] Tr stat | Loss - 0.00 | Grad. Norm - 0.02 | 0.233 sec/step (rd 0.8% | fw 31.3% | bw 67.8%)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Saved checkpoint (step = 215.0K, wer = 0.12) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab_sd0/best_att.pthep - 390/920[215.0K] Valid step - 17/920\n",
      "[INFO] Saved checkpoint (step = 245.0K, wer = 0.12) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab_sd0/best_att.pth\n",
      "\u001b[K[250.0K] Valid step - 8/920.00 | Grad. Norm - 0.00 | 0.244 sec/step (rd 0.8% | fw 31.5% | bw 67.6%)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Saved checkpoint (step = 340.0K, wer = 0.12) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab_sd0/best_att.pthep - 387/920\n",
      "self.tr_set: 89450t | Loss - 0.00 | Grad. Norm - 0.00 | 0.235 sec/step (rd 0.9% | fw 31.0% | bw 68.1%)\n",
      "[INFO] Saved checkpoint (step = 375.0K, wer = 0.12) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab_sd0/best_att.pth\n",
      "[INFO] Saved checkpoint (step = 380.0K, wer = 0.12) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab_sd0/best_att.pth\n",
      "[INFO] Saved checkpoint (step = 395.0K, wer = 0.12) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab_sd0/best_att.pth\n",
      "[INFO] Saved checkpoint (step = 415.0K, wer = 0.12) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab_sd0/best_att.pth\n",
      "[INFO] Saved checkpoint (step = 420.0K, wer = 0.12) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab_sd0/best_att.pth\n",
      "[INFO] Saved checkpoint (step = 435.0K, wer = 0.12) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab_sd0/best_att.pth\n",
      "self.tr_set: 89450t | Loss - 0.00 | Grad. Norm - 0.00 | 0.233 sec/step (rd 0.9% | fw 31.1% | bw 68.1%)\n",
      "[INFO] Saved checkpoint (step = 490.0K, wer = 0.12) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab_sd0/best_att.pth\n",
      "self.tr_set: 89450t | Loss - 0.00 | Grad. Norm - 0.00 | 0.233 sec/step (rd 0.9% | fw 30.6% | bw 68.5%)[525.0K] Valid step - 379/920\n",
      "[INFO] Saved checkpoint (step = 540.0K, wer = 0.12) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab_sd0/best_att.pth\n",
      "[INFO] Saved checkpoint (step = 545.0K, wer = 0.12) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab_sd0/best_att.pth\n",
      "[INFO] Saved checkpoint (step = 550.0K, wer = 0.12) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab_sd0/best_att.pth\n",
      "[INFO] Saved checkpoint (step = 575.0K, wer = 0.12) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab_sd0/best_att.pth\n",
      "self.tr_set: 89450t | Loss - 0.00 | Grad. Norm - 0.00 | 0.227 sec/step (rd 0.9% | fw 31.0% | bw 68.1%)[600.0K] Valid step - 393/920\n",
      "self.tr_set: 89450t | Loss - 0.00 | Grad. Norm - 0.00 | 0.236 sec/step (rd 0.8% | fw 31.2% | bw 68.0%)[705.0K] Valid step - 425/920\n",
      "[INFO] Saved checkpoint (step = 755.0K, wer = 0.12) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab_sd0/best_att.pth\n",
      "[INFO] Saved checkpoint (step = 795.0K, wer = 0.11) and status @ ckpt/cv11Lu_asr_lstm4atthead_allvocab_sd0/best_att.pthep - 618/920\n",
      "self.tr_set: 89450step - 920/9200 | Grad. Norm - 0.00 | 0.221 sec/step (rd 0.9% | fw 30.8% | bw 68.3%)\n",
      "self.tr_set: 89450t | Loss - 0.00 | Grad. Norm - 0.00 | 0.225 sec/step (rd 0.9% | fw 31.0% | bw 68.2%)[870.0K] Valid step - 616/920\n",
      "\u001b[K[927.4K] Tr stat | Loss - 0.00 | Grad. Norm - 0.00 | 0.224 sec/step (rd 0.9% | fw 30.9% | bw 68.2%)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rocky-custom",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('asd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "expired-budget",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "============  Result of /home/jupyter-jason3/LAS_Mandarin_PyTorch-master/result/mozillacv11_asr_stm4atthead-test_test_output.csv ============\r\n",
      " -----------------------------------------------------------------------\r\n",
      "| Statics\t\t|  Truth\t|  Prediction\t| Abs. Diff.\t|\r\n",
      " -----------------------------------------------------------------------\r\n",
      "| Avg. # of chars\t|  8.01\t|  8.10\t|  0.16\t\t|\r\n",
      "| Avg. # of words\t|  1.00\t|  1.00\t|  0.00\t\t|\r\n",
      " -----------------------------------------------------------------------\r\n",
      " ---------------------------------------------------------------\r\n",
      "| Error Rate (%)| Mean\t\t| Std.\t\t| Min./Max.\t|\r\n",
      " ---------------------------------------------------------------\r\n",
      "| Character\t| 7.9479\t| 21.68\t\t| 0.00/240.00\t|\r\n",
      "| Word\t\t| 18.1725\t| 38.56\t\t| 0.00/100.00\t|\r\n",
      " ---------------------------------------------------------------\r\n",
      "Note : If the text unit is phoneme, WER = PER and CER is meaningless.\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!python eval.py --file ~/LAS_Mandarin_PyTorch-master/result/mozillacv11_asr_stm4atthead-test_test_output.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "historical-timeline",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
